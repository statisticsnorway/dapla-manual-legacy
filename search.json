[
  {
    "objectID": "bakke-til-sky.html",
    "href": "bakke-til-sky.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Fra bakke til sky"
  },
  {
    "objectID": "pyspark-venv.html",
    "href": "pyspark-venv.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "For √• kunne benytte det virtuelle milj√∏et i en notebook m√• man sette opp en kernel. Dette er beskrevet her. Denne kernelen er imidlertid ikke satt opp til √• bruke pyspark som standard, og for √• f√• til det m√• man gj√∏re noen manuelle steg.\n\n\nDenne kommandoen legger til pakken pyspark i prosjektet (med samme versjon som p√• jupyterlab).\npoetry add pyspark==$(pip show pyspark | grep Version | egrep -o \"([0-9]{1,}\\.)+[0-9]{1,}\")\n\n\n\nPyspark kan kj√∏res enten p√• lokal maskin eller p√• flere maskiner samtidig i en s√•kalt klynge (cluster). Sistnevnte kan v√¶re mer effektivt √• bruke n√•r man har st√∏rre mengder data, men det krever ogs√• mer konfigurasjon.\n\n\nOppsettet for Pyspark p√• lokal maskin er det enkleste √• sette opp siden Pyspark vil ha direkte tilgang til det lokale filsystemet. Man kan bruke milj√∏variabelen PYSPARK_PYTHON til √• peke p√• det virtuelle milj√∏et, og dermed vil Pyspark ogs√• ha tilgang til alle pakkene som er installert der. I en notebook vil dette kunne settes opp slik:\nimport os\nimport subprocess\n\n# Finner filstien til det virtuelle milj√∏et\npython_path = subprocess.run(['poetry', 'run', 'which', 'python'],\n                             capture_output=True, text=True).stdout.rstrip('\\n')\n\nos.environ[\"PYSPARK_PYTHON\"] = python_path\nos.environ[\"PYSPARK_SUBMIT_ARGS\"] = os.environ[\"PYSPARK_LOCAL_SUBMIT_ARGS\"]\nTil slutt m√• man kj√∏re et script for √• initialisere pyspark for lokal maskin:\n%run /usr/local/share/jupyter/kernels/pyspark_local/init.py\nDette scriptet vil sette et spark objekt som brukes for √• kalle API‚Äôet til pyspark.\n\n\n\nHvis man vil kj√∏re Pyspark i et cluster (dvs. p√• flere maskiner) s√• vil databehandlingen foreg√• p√• andre maskiner som ikke har tilgang til det lokale filsystemet. Man m√• dermed lage en ‚Äúpakke‚Äù av det virtuelle milj√∏et p√• lokal maskin og tilgjengeliggj√∏re dette for alle maskinene i clusteret. For √• lage en slik ‚Äúpakke‚Äù kan man bruke et bibliotek som heter venv-pack. Dette kan kj√∏res fra et terminalvindu slik:\nvenv-pack -p .venv -o pyspark_venv.tar.gz\nMerk at kommandoen over m√• kj√∏res fra rot-mappen i prosjektet ditt. Her er pyspark_venv.tar.gz et tilfeldig valgt filnavn, men dette filnavnet skal brukes videre i notebooken.\nimport os\nimport subprocess\n\n# Milj√∏variabel som peker p√• en utpakket versjon av det virtuelle milj√∏et\nos.environ[\"PYSPARK_PYTHON\"] = \"./environment/bin/python\"\n\n# Legg til et flagg, --archives, som peker p√• \"pakken\" med det virtuelle milj√∏et\nconf = os.environ[\"PYSPARK_K8S_SUBMIT_ARGS\"].split(' ')\nlast_index = conf.index('pyspark-shell')\nconf[last_index:last_index] = ['--archives', 'pyspark_venv.tar.gz#environment']\nos.environ[\"PYSPARK_SUBMIT_ARGS\"] = ' '.join(conf)\nTil slutt m√• man kj√∏re et script for √• initialisere pyspark cluster:\n%run /usr/local/share/jupyter/kernels/pyspark_k8s/init.py\nDette scriptet vil sette et spark objekt som brukes for √• kalle API‚Äôet til pyspark."
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Forord\nDenne boken tar sikte p√• √• gi SSB-ansatte mulighet til √• ta i bruk grunnleggende funksjonalitet p√• DAPLA uten hjelp fra eksperter. Boken er bygget opp som den reisen vi mener en statistikker skal gjennom n√•r de flytter sin produksjon fra bakke til sky1. F√∏rste del inneholder en del grunnleggende kunnskap som vi mener er viktig √• ha f√∏r man skal starte √• jobbe i skyen. Andre del forklarer hvordan man s√∏ker om √• opprette et Dapla-team, en forutsetning for √• drive databehandling p√• plattformen. Det vil ofte v√¶re f√∏rste steget i ta i bruk plattformen, siden det er slik man f√•r et sted √• lagre data. Her forklarer vi hvilke tjenester som inkluderes i et statistikkteam og hvordan man bruker og administerer dem. Den tredje delen tar utgangspunkt i at man skal starte √• kode opp sin statistikkproduksjon eller kj√∏re eksisterende kode. ssb-project er et verkt√∏y som er utviklet i SSB for √• gj√∏re denne prosessen s√• enkel som mulig. Da kan brukerne implementere det som anses som god praksis i SSB med noen f√• tastetrykk, samtidig som vi ogs√• forklarer mer detaljert hva som skjer under panseret.\nDet er tilrettelagt for en treningsarena i bakkemilj√∏et. Dette milj√∏et er nesten identisk med det som m√∏ter deg p√• Dapla, med unntak av at du her har tilgang til mange av de gamle systemene og mye mindre hestekrefter i maskinene. Ideen er at SSB-ere ofte vil √∏nske √• l√¶re seg de nye verkt√∏yene2 i kjente og kj√¶re omgivelser f√∏rst, og deretter flytte et ferdig skrevet produksjonsl√∏p til Dapla. Del 4 av denne boken beskriver mer utfyllende hvordan dette milj√∏et skiller seg fra Dapla, og hvordan man gj√∏r en del vanlige operasjoner mot de gamle bakkesystemene.\nSiste delen av boken kaller vi Avansert og tar for seg ulike emner som mer avanserte brukere typisk trenger informasjon om. Her finner man blant annet informasjon om hvilke databaser man kan bruke og hvilke form√•l de er egnet for. Her beskrives ogs√• hvordan man kan bruke andre IDE-er enn Jupyterlab hvis man √∏nsker det. Tjenester for schedulerte kj√∏ringer av Notebooks blir ogs√• diskutert.\nForh√•pentligvis senker denne boken terskelen for √• ta i bruk Dapla. Kommentarer og √∏nsker vedr√∏rende boken tas imot med √•pne armer.\nGod forn√∏yelseüòÅ\n\n\n\n\n\nFotnoter\n\n\nI denne boken omtaler vi den gamle produksjonssonen, ofte kalt prodsonen, som bakke, og det nye skymilj√∏et Google Cloud som sky. Det er ikke helt presist men duger for form√•lene i denne boken.‚Ü©Ô∏é\nDet som omtales som nye verkt√∏y er vil som regel bety R, Python, Git, GitHub og Jupyterlab.‚Ü©Ô∏é"
  },
  {
    "objectID": "hva-er-dapla-team.html",
    "href": "hva-er-dapla-team.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Hva er Dapla-team?\nEt Dapla-team fokuserer p√• statistikkproduksjon innen et eller flere emneomr√•der p√• Dapla. Teamet er egentlig et arbeidsomr√•de p√• Dapla, som gir medlemmene av teamet tilgang p√• teamet sine felles datalagre, roller og bakke-sky synkroniseringsomr√•der.\nHvert Dapla-team f√•r opprettet et prosjektomr√•de i Google Cloud Platform (GCP), som er SSBs leverand√∏r av skytjenester."
  },
  {
    "objectID": "git-github.html",
    "href": "git-github.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "I SSB anbefales det man versjonh√•ndterer koden sin med Git og deler koden via GitHub. For √• l√¶re seg √• bruke disse verkt√∏yene p√• en god m√•te er det derfor viktig √• forst√• forskjellen mellom Git og Github. Helt overordnet er forskjellen f√∏lgende:\n\nGit er programvare som er installert p√• maskinen du jobber p√• og som sporer endringer i koden din.\nGitHub er et slags felles mappesystem p√• internett som lar deg dele og samarbeide med andre om kode.\n\nAv definisjonene over s√• skj√∏nner vi at det er Git som gir oss all funksjonalitet for √• lagre versjoner av koden v√•r. GitHub er mer som et valg av mappesystem. Men m√•ten kodemilj√∏ene v√•re er satt opp p√• Dapla s√• har vi ingen fellesmappe som alle kan kj√∏re koden fra. Man utvikler kode i sin egen hjemmemappe, som bare du har tilgang til, og n√•r du skal samarbeide med andre, s√• m√• du sende koden til GitHub. De du samarbeider med m√• deretter hente ned denne koden f√∏r de kan kj√∏re den.\nI dette kapittelet ser vi n√¶rmere p√• Git og Github og hvordan de er implementert i SSB. Selv om SSB har laget programmet ssb-project for √• gj√∏re det lettere √• bl.a. forholde seg til Git og GitHub, s√• vil vi dette kapittelet forklare n√¶rmere hvordan det funker uten dette hjelpemiddelet. Forh√•pentligvis vil det gj√∏re det lettere √• h√•ndtere mer kompliserte situasjoner som oppst√•r i arbeidshverdagen som statistikker.\n\n\nGit er terminalprogram som installert p√• maskinen du jobber. Hvis man ikke liker √• bruke terminalen finnes det mange pek-og-klikk versjoner av Git, blant annet i Jupyterlab, SAS EG og RStudio. Men typisk vil det en eller annen gang oppst√• situasjoner der det ikke finnes l√∏sninger i pek-og-klikk versjonen, og man m√• ordne opp i terminalen. Av den grunn velger vi her √• fokusere p√• hvordan Git fungerer fra terminalen. Vi vil ogs√• fokusere p√• hvordan Git fungerer fra terminalen i Jupyterlab p√• Dapla.\n\n\nKommer snart. Kort forklaring med lenke til mer utfyllende svar.\n\n\n\nMer kommer.\n\n\nFor √• brukt Git er det strengt tatt to ting som m√• konfigurere:\n\nBrukernavn\nE-post\n\nDenne informasjonen brukes av Git hver gang du sjekker inn en endring i koden slik at man kan vite hvem som gjorde endringen senere. Dette m√• settes √©n gang per milj√∏ hvor du skal jobbe med Git. Hvis du f.eks. jobber i Jupyterlab p√• Dapla s√• kan du √•pne en terminal og skrive f√∏lgende for √• lagre ditt brukernavn:\ngit config --global user.name \"Ola Nordmann\"\nFor √• sette e-post gj√∏r du veldig lignende:\ngit config --global user.email olanordamnn@ssb.no\nN√•r du har kj√∏rt disse to kommandoene s√• kan du bruke Git. Informasjonen du la til over brukes ikke til noe annet enn √• fortelle de du samarbeider med om at du har gjort endringer p√• koden. Den er verken knyttet opp mot din SSB-bruker eller din GitHub-bruker.\n\n\n\n\nKommer snart. Jupytext og nbsripout. json.\n\n\n\nKommer snart. clone, add, commit, push, pull, merge, revert, etc.\n\n\n\n\nGitHub er et nettsted som fungerer som v√•rt felles mappesystem for deling av kode. SSB har sin egen organisasjonskonto med navn statisticsnorway\n\n\nDette kapittelet er bare relevant hvis man ikke har en GitHub-brukerkonto fra f√∏r. For √• bruke ssb-project-programmet til √• generere et remote repo p√• GitHub m√• du ha en konto. Derfor starter vi med √• gj√∏re dette. Det er en engangsjobb og du trenger aldri gj√∏re det igjen.\n\n\n\n\n\n\nSSB har valgt √• ikke sette opp SSB-brukerne til de ansatte som GitHub-brukere. En viktig √•rsak er at er en GitHub-konto ofte regnes som en del av den ansattes CV. For de som aldri har brukt GitHub f√∏r kan det virke fremmed, men det er nok en fordel p√• sikt n√•r alle blir godt kjent med denne arbeidsformen.\n\n\n\nSlik gj√∏r du det:\n\nG√• til https://github.com/\nTrykk Sign up √∏verst i h√∏yre hj√∏rne\nI dialogboksen som √•pnes, se Figur¬†1, skriver du inn din e-postkonto og lager et passord. Dette trenger ikke v√¶re din SSB-bruker og e-post. Vi anbefaler at du bruker en personlig e-postkonto og velger ditt eget passord. Det samme gjelder brukernavn ogs√•.\n\n\n\n\nFigur¬†1: Dialogboks for opprettelse av GitHub-bruker.\n\n\nDu har n√• laget en egen GitHub-bruker. I neste steg skal vi knytte denne kontoen til din SSB-bruker.\n\n\n\nHvis du har fullf√∏rt forrige steg s√• har du n√• en GitHub-konto. Hvis du st√•r p√• din profil-side s√• ser den ut som i Figur¬†2.\n\n\n\nFigur¬†2: Et eksempel p√• hjemmeomr√•det til en GitHub-bruker\n\n\nDet neste vi m√• gj√∏re er √• aktivere 2-faktor autentisering, siden det er dette som benyttes i SSB. Hvis du st√•r p√• siden i bildet over, s√• gj√∏r du f√∏lgende for √• aktivere 2-faktor autentisering mot GitHub:\n\n\n\nTrykk p√• den lille pilen √∏verst til h√∏yre og velg Settings(se Figur¬†3).\nDeretter velger du Password and authentification i menyen til venstre.\nUnder Two-factor authentication trykker du p√• Enable.\n\n\n\n\n\n\nFigur¬†3: √Öpne settings for din GitHub-bruker.\n\n\n\n\n\nFigur¬†4 viser dialogboksen som vises. Velg Enable two-factor authentification.\n\n\n\n\nFigur¬†4: Dialogboks som √•pnes n√•r 2FA skrus p√• f√∏rste gang.\n\n\n\nFigur¬†5 viser dialogboksen som vises for √• velge hvordan man skal autentisere seg. Her anbefales det √• velge Set up using an app, slik at du kan bruke Microsoft Authenticator-appen p√• din mobil.\n\n\n\n\nFigur¬†5: Dialogboks for √• velge hvordan man skal autentisere seg med 2FA.\n\n\nFigur¬†6 viser QR-koden som vises. Denne skal vi bruke i neste steg.\n\n\n\nFigur¬†6: QR-kode som skannes av Microsoft Authenticator.\n\n\n\n\n\nStrekkoden over skal skannes i din Microsoft Authenticator-app p√• mobilen, som vist i Figur¬†7. √Öpne appen, trykk p√• Bekreftede ID-er, og til slutt trykk p√• Skann QR-kode. Deretter skanner du QR-koden fra punkt 5.\nN√•r koden er skannet har du f√•tt opp f√∏lgende bilde p√• appens hovedside (se bilde til h√∏yre). Skriv inn den 6-siffer koden p√• GitHub-siden med QR-koden.\nTil slutt lagrer du Recovery-codes et trygt sted som bare du har tilgang til.\n\n\n\n\n\n\nFigur¬†7: Mobilappen Microsoft authenticator\n\n\n\n\nN√• har vi aktivert 2-faktor autentisering for GitHub og er klare til √• knytte v√•r personlige konto til v√•r SSB-bruker p√• SSBs ‚ÄúGithub organisation‚Äù statisticsnorway.\n\n\n\nI forrige steg aktiverte vi 2-faktor autentisering for GitHub. Det neste vi m√• gj√∏re er √• koble oss til Single Sign On (SSO) for SSB sin organisasjon p√• GitHub:\n\nTrykk p√• lenken https://github.com/orgs/statisticsnorway/sso\nI dialogboksen som dukker opp trykker du p√• Continue, slik som vist i Figur¬†8.\n\n\n\n\nFigur¬†8: Single Sign on (SSO) for SSB sin organisasjon p√• GitHub\n\n\nN√•r du har gjennomf√∏rt dette s√• har du tilgang til statisticsnorway p√• GitHub. G√•r du inn p√• denne lenken s√• skal du n√• kunne lese b√•de Public, Private og Internal repoer, slik som vist i Figur¬†9.\n\n\n\nFigur¬†9: Medlemsvisning for SSB sin GitHub-organisasjon.\n\n\n\n\n\nN√•r vi skal jobbe med SSB-kode som ligger lagret hos statistcsnorway p√• GitHub, s√• m√• vi autentisere oss. M√•ten vi gj√∏re det p√• er ved √• generere et Personal Access Token (ofte forkortet PAT) som vi oppgir n√•r vi vil hente eller oppdatere kode p√• GitHub. Da sender vi med PAT for √• autentisere oss for GitHub.\n\n\nFor √• lage en PAT som er godkjent mot statisticsnorway s√• gj√∏r man f√∏lgende:\n\nG√• til din profilside p√• GitHub og √•pne Settings slik som ble vist Seksjon¬†1.2.2.\nVelg Developer Settings i menyen til venstre.\nI menyen til venstre velger du Personal Access Token, og deretter Tokens (classic).\nUnder Note kan du gi PAT‚Äôen et navn. Velg et navn som er intuitivt for deg. Hvis du skal bruke PAT til √• jobbe mot Dapla, s√• ville jeg ganske enkelt kalt den dapla. Hvis du skal bruke den mot bakkemilj√∏et ville jeg kalt den prodsone eller noe annet som gj√∏r det lett for det skj√∏nne innholdet i ettertid.\nUnder Expiration velger du hvor lang tid som skal g√• f√∏r PAT blir ugyldig. Dette er en avvening mellom sikkerhet og hva som er praktisk. Det anbefales at du velger 365 dager. N√•r PAT utl√∏per m√• du gjenta stegene i dette kapittelet.\nUnder Select scopes velger du Repo slik som vist i Figur¬†10.\n\n\n\n\nFigur¬†10: Gi token et kort og beskrivende navn\n\n\n\nTrykk p√• Generate token nederst p√• siden og du f√•r noe lignende det du ser i Figur¬†11.\n\n\n\n\nFigur¬†11: Token som ble generert.\n\n\n\nKopier deretter PAT til en midlertidig fil. Grunnen er at du aldri vil se det igjen her etter at vi har gjennomf√∏rt neste steg.\nDeretter trykker du p√• Configure SSO og velger Authorize ved siden statisticsnorway, slik som vist i Figur¬†12. Svar deretter p√• sp√∏rsm√•lene som dukker opp.\n\n\n\n\nFigur¬†12: Autorisering av Token mot SSBs GiHub-organisasjon.\n\n\nVi har n√• opprettet en PAT som er godkjent for bruk mot SSB sin kode p√• GitHub. Det betyr at hvis vi vil jobbe med Git p√• SSB sine maskiner i sky eller p√• bakken, s√• m√• vi sendte med dette tokenet for √• f√• lov til √• jobbe med koden som ligger p√• statisticsnorway p√• GitHub.\n\n\n\nDet er ganske upraktisk √• m√•tte sende med tokenet hver gang vi skal jobbe med GitHub. Vi b√∏r derfor lagre det lokalt der vi jobber, slik at Git automatisk finner det. Det finnes mange m√•ter √• gj√∏re dette p√• og det er ikke bestemt hva som skal v√¶re beste-praksis i SSB. Men en m√•te √• gj√∏re det er via en .netrc-fil. Vi oppretter da en fil som heter .netrc p√• v√•rt hjemmeomr√•de, og legger f√∏lgende informasjon p√• en (hvilken som helst) linje i filen:\nmachine github.com login <github-bruker> password <Personal Access Token>\nGitHub-bruker er da din personlige bruker og IKKE brukernavnet ditt i SSB. Personal Access Token er det vi lagde i forrige kapittelet.\nEn veldig enkel m√•te √• lagre dette er som f√∏lger. Anta at min personlige GitHub-bruker er SSB-Chad og at min Personal Access Token er blablabla. Da kan jeg gj√∏re f√∏lgende for √• lagre det i .netrc:\n\nG√• inn i Jupyterlab og √•pne en Python-notebook.\nI den f√∏rste kodecellen skriver du:\n\n!echo \"machine github.com login SSB-Chad password blablabla\" >> ~/.netrc\nAlternativt kan du droppe det utropstegnet og kj√∏re det direkte i en terminal. Det vil gi samme resultat. Koden over legger til en linje med teksten\nmachine github.com login SSB-Chad password blablabla\ni en .netrc-fil p√• din hjemmeomr√•det, uanvhengig av om du har en fra f√∏r eller ikke. Hvis du har en fil fra f√∏r som allerede har et token fra GitHub, ville jeg nok slettet det f√∏r jeg legger en et nytt token.\nHver gang du jobber mot GitHub vil Git sjekke om informasjon om autentisering ligger i denne filen, og bruke den hvis den ligger der.\n\n\n\nI eksempelet over lagde vi en PAT som var gyldig i 90 dager. Dermed vil du ikke kunne jobbe mot GitHub med dette tokenet etter 90 dager. For √• oppdatere tokenet gj√∏r du f√∏lgende:\n\nLag et nytt PAT ved √• repetere Seksjon¬†1.2.4.1.\nI milj√∏et der du skal jobbe med Git og GitHub g√•r du inn i din .netrc og bytter ut token med det nye.\n\nOg med det er du klar til √• jobbe mot statisticsnorway p√• GitHub."
  },
  {
    "objectID": "jupyter-pa-bakken.html",
    "href": "jupyter-pa-bakken.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Jupyterlab p√• bakken"
  },
  {
    "objectID": "avansert.html",
    "href": "avansert.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Avansert"
  },
  {
    "objectID": "slette-data.html",
    "href": "slette-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Slette data fra b√∏tter\nSletting av filer og mapper fra b√∏tter kan gj√∏res fra Google Cloud Console. S√∏k opp ‚ÄúCloud Storage‚Äù i s√∏kefeltet og klikk p√• den b√∏tten hvor filen er lagret under ‚ÄúBuckets‚Äù.\nKryss av filen/katalogen som du √∏nsker √• slette og trykk ‚ÄúDelete‚Äù (Figur¬†1)\n\n\n\nFigur¬†1: Sletting av en fil\n\n\nSiden b√∏tter p√• Dapla har versjonering f√•r man opp en dialogboks som informerer om at objektet (dvs. filen) er versjonert (Figur¬†2). Trykk p√• ‚ÄúDelete‚Äù.\n\n\n\nFigur¬†2: Bekreft sletting av fil\n\n\nSlettingen kan ta noe tid. N√•r denne er ferdig vil filen v√¶re slettet, men den kan fortsatt gjenopprettes. Hvis du √∏nsker at filen skal slettes permanent, gj√∏r f√∏lgende:\n\nSkru p√• visning av slettede filer med √• bruke radioknappen ‚ÄúShow deleted data‚Äù (Figur¬†3)\n\n\n\n\nFigur¬†3: Skru p√• visning av slettede filer\n\n\n\nFinn frem til den slettede filen og trykk p√• linken ‚Äú1 noncurrent version‚Äù eller tilsvarende (Figur¬†4). Dette vil ta deg direkte til en side som viser filens versjonshistorikk.\n\n\n\n\nFigur¬†4: Velg versjonshistorikk\n\n\n\nVelg alle versjoner som vist p√• Figur¬†5 og trykk ‚ÄúDelete‚Äù\n\n\n\n\nFigur¬†5: Slett alle versioner\n\n\n\nTil slutt m√• man bekrefte at man √∏nsker √• slette alle versioner (Figur¬†6) med √• skrive inn DELETE og trykke p√• den bl√• ‚ÄúDelete‚Äù-knappen:\n\n\n\n\nFigur¬†6: Bekreft sletting av alle versjoner"
  },
  {
    "objectID": "introduksjon.html",
    "href": "introduksjon.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Introduksjon\nM√•let med dette kapittelet er √• gi en grunnleggende innf√∏ring i hva som legges i ordet Dapla. I tillegg gis en forklaring p√• hvorfor disse valgene er tatt."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Denne boken er ment som enkel-√•-bruke manual for √• ta i bruk SSBs nye dataplattform Dapla. Plattformen fors√∏ker √• gj√∏re statistikkprodusenter og forskere s√• selvhjulpne som mulig. M√•lsetningen er at tjenestene som tilbys skal kunne tas i bruk p√• en enkel og intuitiv m√•te. Men uansett hvor lett tilgjengelig tjenester er, og hvor mye arbeid som er lagt √• gj√∏re l√∏sninger brukervennlige, s√• trenger de fleste i SSB en klar og tydelig veiledning for hvordan de skal brukes og i hvilken st√∏rre sammenheng tjenestene inng√•r. Dapla-manualen er ment √• v√¶re en s√•nn st√∏tte i statistikkernes hverdag. Uansett om man lurer p√• hvordan man logger seg inn p√• plattformen, eller om man √∏nsker informasjon om kj√∏remilj√∏et for mer kompliserte maskinl√¶ringsmodeller, s√• skal man finne veiledning i denne manualen. M√•lgruppen er b√•de nybegynneren og den mer erfarne.\n\n\n\n\n\n\nDenne boken er skrevet med Quarto og er publisert p√• https://manual.dapla.ssb.no. Alle ansatte i SSB kan bidra til boken ved klone dette repoet, gj√∏re endringer i en branch, og sende en pull request til administratorene av repoet (Team Statistikktjenester).\n\n\n\n\n\nDapla-manualen er initiert og skrevet av Team Statistikktjenester i SSB. Bidragsytere er √òyvind Bruer-Skarsb√∏, Miles Winther, Bj√∏rn Andre Skaar, Anders Lunde og Damir Medakovic. Ved behov for oppdateringer og nytt innhold h√•per vi at alle i SSB kan bidra."
  },
  {
    "objectID": "lese-data.html",
    "href": "lese-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Skal man lese fra en b√∏tte m√• man autentisere seg. For √• gj√∏re dette kan man benytte pakken dapla-toolbelt.\n\n\n\n\n\n\n\n\n‚Äúnavn-boette‚Äù eksisterer ikke og m√• byttes med en reel b√∏tte.\n\n\n\nLes json fil fra b√∏tte:\nimport dapla as dp\n\ndata_frame = dp.read_pandas(\"gs://ssb-staging-navn-boette/schema.json\",\n file_format=\"json\")\nList ut mapper i b√∏tta:\nfrom dapla import FileClient\n\nFileClient.ls(\"gs://ssb-staging-navn-boette/\")\n\n\n\n\n\nEn vanlig √•rsak til feil er at man fors√∏ker √• lese data fra et annet milj√∏ enn det man befinner seg i. Sjekk at url feltet i nettleseren stemmer overens med b√∏ttene man fors√∏ker √• aksessere.\nStagingb√∏tter starter med: gs://ssb-staging-\nProduksjonsb√∏tter starter med: gs://ssb-prod-\n\n\n\n\n\n\nI https://jupyter.dapla-staging.ssb.no/ kan man ikke lese produksjonsb√∏tter.\n\n\n\n\n\n\n\n\n\nI https://jupyter.dapla.ssb.no/ kan man ikke lese stagingb√∏tter.\n\n\n\n\n\n\nNoen ganger kan en restart av Jupyter l√∏se problemet.\nI Jupyters filmeny velg: fil -> Hub Controll Panel.\nTrykk p√• knappen ‚ÄúStop My Server‚Äù. Etter dette kan man trykke knappen ‚ÄúStart My Server‚Äù.\n\n\n\nStop My Server\n\n\n\n\n\nHvis man fortsatt ikke har tilgang, kan man opprette en TMS sak. For at vi lettes mulig skal kunne hjelpe b√∏r saken inneholde full feilmelding & relevant kode."
  },
  {
    "objectID": "hva-er-dapla.html",
    "href": "hva-er-dapla.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Hva er Dapla?\nDapla st√•r for dataplattform, og er en skybasert l√∏sning for statistikkproduksjon og forskning."
  },
  {
    "objectID": "lese-data-bakken.html",
    "href": "lese-data-bakken.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Mer kommer."
  },
  {
    "objectID": "nytt-ssbproject.html",
    "href": "nytt-ssbproject.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "I dette kapittelet forklarer vi hvordan du oppretter et ssb-project og hva det inneb√¶rer. ssb-project er et CLI1 for √• raskt komme i gang med koding p√• Dapla, hvor en del SSB-spesifikke beste-prakiser er ivaretatt. Kode som naturlig h√∏rer sammen, f.eks. koden til et produksjonsl√∏p for en statistikk, er m√•lgruppen for dette programmet. Kort fortalt kan du kj√∏re denne kommandoen i en terminal\nssb-project create stat-testprod\nog du vil f√• en mappe som heter stat-testprod med f√∏lgende innhold:\n\nStandard mappestruktur En standard mappestruktur gj√∏r det lettere √• dele og samarbeide om kode, som igjen reduserer s√•rbarheten knyttet til at f√• personer kjenner koden.\nVirtuelt milj√∏ Virtuelle milj√∏er isolerer og lagrer informasjon knyttet til kode. For eksempel hvilken versjon av Python du bruker og tilh√∏rende pakkeversjoner. Det er viktig for at publiserte tall skal v√¶re reproduserbare. Verkt√∏yet for √• lage virtuelt milj√∏ er Poetry.\nVersjonsh√•ndtering med Git Initierer versjonsh√•ndtering med Git og legger til SSBs anbefalte .gitignore og .gitattributes. Det sikrer at du ikke versjonh√•ndterer filer/informasjon som ikke skal versjonsh√•ndteres.\n\nI tillegg lar ssb-project deg opprette et GitHub-repo hvis du √∏nsker. Les mer om hvordan du kan ta i bruk dette verkt√∏yet under.\n\n\n\n\n\n\nMerk\n\n\n\nDokumentasjonen for ssb-project finnes her: https://statisticsnorway.github.io/ssb-project-cli/. Det oppdateres hver gang en ny versjon av ssb-project slippes.\n\n\n\n\nF√∏r du kan ta i bruk ssb-project s√• er det et par ting som m√• v√¶re p√• plass:\n\nDu m√• ha opprettet en git-bruker og git-epost lokalt der du skal kalle p√• programmet (les mer om hvordan her).\nHvis du √∏nsker at ssb-project ogs√• skal opprette et GitHub-repo for deg m√• du ogs√• f√∏lgende v√¶re p√• plass:\n\nDu m√• ha en GitHub-bruker (les hvordan her)\nSkru p√• 2-faktor autentifisering for GitHub-brukeren din (les hvordan her)\nV√¶re koblet mot SSBs organisasjon statisticsnorway p√• GitHub (les hvordan her)\nOpprette Personal Access Token (PAT) og godkjenne det for bruk mot statisticsnorway (les hvordan her)\n\n\nDet er ogs√• √• anbefale at du lagrer PAT lokalt slik at du ikke trenger √• forholde deg til det n√•r jobber med Git og GitHub. Hvis du har alt dette p√• plass s√• kan du bare fortsette √• f√∏lge de neste kapitlene.\n\n\n\n\n\n\n\n\n\nHar du Github bruker? Noe funksjonalitet i ssb-project krever det. Finn ut hvordan ved √• lese forrige kapittel.\n\n\n\nssb-project lar deg opprette en prosjekt-mappe med og uten GitHub-repo. La oss ta for oss hver av alternativene.\n\n\nFor √• opprette et nytt ssb-project uten GitHub-repo gj√∏r du f√∏lgende:\n\n√Öpne en terminal. De fleste vil gj√∏re dette i Jupyterlab p√• bakke eller sky og da kan de bare trykke p√• det bl√• ‚ûï-tegnet i Jupyterlab og velge Terminal.\nF√∏r vi kj√∏rer programmet m√• vi v√¶re obs p√• at ssb-project vil opprette en ny mappe der vi st√•r. G√• derfor til den mappen du √∏nsker √• ha den nye prosjektmappen. For √• opprette et prosjekt som heter stat-testprod s√• skriver du f√∏lgende i terminalen:\n\nssb-project create stat-testprod\n\n\nHvis du stod i hjemmemappen din p√• n√•r du skrev inn kommandoen over i terminalen, s√• har du f√•tt mappestrukturen som vises i Figur¬†1. 2. Den inneholder f√∏lgende :\n\n.git-mappe som blir opprettet for √• versjonsh√•ndtere med Git.\nsrc-mappe som skal inneholde all koden som utgj√∏r produksjonsl√∏pet.\ntests-mappe som inneholder tester du skriver for koden din.\nLICENCE-fil som skal benyttes for public-repos i SSB.\npoetry.lock-fil som inneholder alle versjoner av Python-pakker som blir brukt.\nREADME.md-fil som brukes for tekstlig innhold p√• GitHub-siden for prosjektet.\n\n\n\n\n\n\nFigur¬†1: Mappen som ble opprettet av ssb-project.\n\n\n\n\n\n\n\nOver s√• opprettet vi et ssb-project uten √• opprette et GitHub-repo. Hvis du √∏nsker √• opprette et GitHub-repo ogs√• m√• du endre kommandoen over til:\nssb-project create stat-testprod --github --github-token='blablabla'\nKommandoen over oppretter en mappestruktur slik vi s√• tidligere, men ogs√• et ssb-project som heter stat-testprod med et GitHub-repo med samme navn. Som du ser s√• m√• vi da sende med opsjonen --github og PAT med opsjonen --github-token='blablabla'. Repoet i GitHub ser da ut som i Figur¬†2.\n\n\n\nFigur¬†2: GitHub-repo som er opprettet av ssb-project\n\n\n\n\n\n\n\n\nN√•r du har opprettet et nytt ssb-project, eller bygget et eksisterende prosjekt, s√• kan det ta rundt 30 sekunder f√∏r kernelen viser seg i Jupterlab-launcher. V√¶r t√•lmodig!\n\n\n\n\n\n\n\nN√•r du har opprettet et ssb-project s√• kan du installere de python-pakkene du trenger fra PyPI. Hvis du for eksempel √∏nsker √• installere Pandas, et popul√¶rt data wrangling bibliotek, s√• kan du gj√∏re f√∏lgende:\n\n√Öpne en terminal i Jupyterlab.\nG√• inn i prosjektmappen din ved √• skrive\n\ncd <sti til prosjektmappe>\n\nLag en branch/utviklingsgren som f.eks. heter install-pandas:\n\ngit checkout -b install-pandas\n\nInstaller Pandas ved √• skrive f√∏lgende\n\npoetry add pandas\n\n\n\nFigur¬†3: Installasjon av Pandas med ssb-project\n\n\nFigur¬†3 viser hvordan dette vil se ut i en Jupyterlab-terminal. Kommandoen for √• installere noe er poetry add etterfulgt av pakkenavnet. Vi ser ogs√• at den automatisk legger til Pandas-versjonen i filen poetry.lock. Les mer om hvordan man installerer pakker her.\n\n\n\nN√•r du n√• har installert en pakke s√• har filen poetry.lock endret seg. La oss for eksempelets skyld anta at du √∏nsker √• bruke Git til √• dokumentere denne hendelsen, og dele det med en kollega via GitHub. Hvis vi har opprettet et ssb-project med et GitHub-repo s√• kan vi gj√∏re akkurat dette:\n\nVi kan stage alle endringer med f√∏lgende kommando i terminalen n√•r vi st√•r i prosjektmappen:\n\ngit add -A\n\nVidere kan commit en endring, dvs. ta et stillbilde av koden i dette √∏yeblikket, ved √• skrive f√∏lgende:\n\ngit commit -m \"Installert pandas\"\n\nPush det opp til GitHub3. Anta at vi gjorde dette i branchen install-pandas som ble opprettet tidligere. Da kan vi skrive f√∏lgende:\n\ngit push --set-upstream origin install-pandas\nMer kommer her.\n\n\n\nN√•r vi skal samarbeide med andre om kode s√• gj√∏r vi dette via GitHub. N√•r du pusher koden din til GitHub, s√• kan samarbeidspartnere pulle ned koden og jobbe videre med den. Men n√•r de henter ned koden s√• vil de bare hente ned selve koden, ikke pakker og Python-versjonen som ble brukt. De m√• installere alt som du hadde installert. I tillegg trenger de en kernel hvis de skal jobbe i Jupyterlab. ssb-project gj√∏r det sv√¶rt enkelt √• bygge opp det du trenger, siden det virtuelle milj√∏et har all informasjon om hva som trengs.\nFor at samarbeidspartneren din skal kunne bygge milj√∏et p√• nytt, m√• de ha gjort en minimal konfigurering av Git. Les mer om hvordan du frem for √• gj√∏re dette her.\nFor √• bygge opp et eksisterende milj√∏ gj√∏r du f√∏lgende:\n\nF√∏rst m√• du kopiere prosjektet ned lokalt, eller klone repoet med git-terminologi\n\ngit clone https://github.com/statisticsnorway/<prosjektnavn>\n\nG√• inn i mappen du klonet\n\ncd <prosjektnavn>\n\nSkape et virtuelt milj√∏ og installere en tilsvarende Jupyter kernel med\n\nssb-project build\n\n\n\nDet vil v√¶re tilfeller hvor man √∏nsker √• slette et ssb-project, enten fordi man ikke trenger koden lenger eller fordi man bare testet litt.\n\n\nHvis man jobber med flere prosjekter s√• kan det fort bli mange Jupyter kerneler hengende igjen. Derfor er det ogs√• mulighet √• kj√∏re\nssb-project clean stat-testprod\nsom sletter Jupyter-kernelen og de installerte pakkene i prosjektet. Hvis du ogs√• √∏nsker √• slette selve mappen med kode m√• du gj√∏re det manuelt4:\nrm -rf ~/stat-testprod/\nProsjektmappen over l√• direkte i hjemmemappen min og hjemmemappen p√• Linux kan alltid referes til med et tilda-tegn ~.\n\n\n\nGitHub-repoer som er opprettet under SSB sin organinasjons statisticsnorway p√• GitHub kan ikke slettes, bare arkiveres. Grunnen er at hvis man oppdager en s√•rbarhet senere s√• er det viktig √• kunne se repoet for √• forst√• hva som har skjedd.\nHvis du ikke trenger et GitHub-repo lenger kan man arkivere repoet. Det gj√∏r du p√• f√∏lgende m√•te:\n\nGi inn i repoet Settings slik som vist med r√∏d pil i Figur¬†4.\n\n\n\n\nFigur¬†4: Settings for repoet.\n\n\n\nUnder General scroller du deg ned til delen som heter Danger Zone og velger Archive this repository, slik som vist p√• Figur¬†5.\n\n\n\n\nFigur¬†5: Arkivering av et repo.\n\n\n\nI dialogboksen som dukker opp fyller du inn reponavnet som beskrevet og trykker p√• I understand the consequences, archive this repository, som vist i Figur¬†6.\n\n\n\n\nFigur¬†6: Bekreftelse av arkiveringen.\n\n\nN√•r det er gjort s√• er repoet lesbart, men man kan ikke jobbe med det. Men som vi ser av @#fig-github-repo-settings-archive-warning kan man omgj√∏re arkiveringen senere hvis det skulle v√¶re √∏nskelig.\n\n\n\n\nVi har forel√∏pig ikke integret R i ssb-project. Grunnen er at det mest popul√¶re virtuelle milj√∏-verkt√∏et for R, renv, kun tilbyr √• passe p√• versjoner av R-pakker og ikke selve R-installasjonen. Det er en svakhet som trolig gj√∏r det vanskeligere enn n√∏dvendig √• gjenskape tidligere publiserte resultater med ssb-project. I tillegg klarer den ikke √• gjenkjenne pakker som blir brukt i ipynb-filer.\nPlanen er √• finne et annet verkt√∏y enn renv som kan ogs√• reprodusere R-versjonen. Team Statistikktjenester ser n√¶rmere p√• hvilke alternativer som finnes og vil tilby noe i fremtiden.\nI mellomtiden kan man bruke renv slik det er beskrevet her for skymilj√∏et, og med denne modifiseringen for bakkemilj√∏et."
  },
  {
    "objectID": "github-app-integrasjon.html",
    "href": "github-app-integrasjon.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Her kommer en beskrivelse av automatiseringsl√∏sningen.\n\n\nFor at automatiseringsl√∏sningen p√• Dapla skal kunne settes opp automatisk m√• denne ha tilgang til √• lese fra prosjektets IAC-repo1. Dette avsnittet vil beskrive denne prosessen. Merk at dette er en engangsjobb som m√• gj√∏res av prosjektets kildedataansvarlige.\n\n\n\n\n\n\nViktig: Prosjektets kildedataansvarlige ogs√• m√• ha administrator-rettigheter til IAC-repoet i Github.\n\n\n\n\nLogg inn p√• Google Cloud Console og velg det prosjektet som skal konfigureres √∏verst venstre hj√∏rte. S√∏k opp Cloud Build i s√∏kefeltet og trykk p√• det valget som kommer opp.\nDet skal n√• v√¶re en venstremeny tilgjengelig med tittel Cloud Build. Trykk p√• menyvalget som heter Triggers (Figur¬†1)\n\n\n\n\nFigur¬†1: Bilde av venstremeny\n\n\n\nI nedtrekkslisten Region s√∏rg for at europe-north1 er valgt (Figur¬†2)\n\n\n\n\nFigur¬†2: Velg korrekt region\n\n\n\nTrykk deretter p√• en link som heter CONNECT REPOSITORY ca. midt p√• siden.\n\n\n\n\nFigur¬†3: Oversikt over triggers\n\n\n\nN√• vil det dukke opp et vindu p√• h√∏yre side med overskrift Connect repository (Figur¬†4). Velg GitHub (Cloud Build GitHub App) og trykk p√• CONTINUE\n\n\n\n\nFigur¬†4: Vindu for √• velge Cloud Build Github App\n\n\n\nEt pop-up vindu tilsvarende Figur¬†5 vil komme opp. Trykk p√• Authorize. Vinduet vil etter hvert lukke seg og man kommer videre til et steg som heter Select repository (Figur¬†6)\n\n\n\n\nFigur¬†5: Pop-up vindu for Github\n\n\n\n\n\nFigur¬†6: Valg av Github repository\n\n\n\nTrykk p√• nedtrekkslisten Repository. Her vil det kunne listes ut flere Github-repoer som allerede er konfigurert. For √• legge til et nytt repo skal man trykke p√• EDIT REPOSITORIES ON GITHUB (Figur¬†7)\n\n\n\n\nFigur¬†7: Valg av Github repository\n\n\n\nEt nytt pop-up vindu vil dukke opp. F√∏rst m√• man autentisere seg p√• nytt mot Github, se Figur¬†8:\n\n\n\n\nFigur¬†8: Tofaktor-autentisering mot Github\n\n\n\nDeretter m√• man velge √• gi Google Cloud Build tilgang til √• lese fra utvalgte Github prosjekter (Figur¬†9). Trykk p√• nedtrekkslisten Select repositories og s√∏k deg frem til prosjektets IAC-repo. Trykk til slutt p√• Update access.\n\n\n\n\nFigur¬†9: Gi Google Build tilgang til Github repository\n\n\n\nN√• vil du komme tilbake til skjermbildet Connect repository. Kryss av i sjekkboksen og trykk CONNECT (Figur¬†10)\n\n\n\n\nFigur¬†10: Bekreft nytt Github repository\n\n\n\nTil slutt vil skjermbildet se ut som vist i Figur¬†11. Det siste steget Create a trigger kan du hoppe over. Dette vil bli satt opp av automatiseringsl√∏sningen senere. Trykk p√• knappen DONE\n\n\n\n\nFigur¬†11: Siste steg - Create a trigger"
  },
  {
    "objectID": "schedulering.html",
    "href": "schedulering.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Schedulering"
  },
  {
    "objectID": "remote.html",
    "href": "remote.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Forklare situasjonen n√•. Kun Jupyterlab. Kan kj√∏re remote session med Rstudio, Pycharm og VSCode."
  },
  {
    "objectID": "gjenopprette-data.html",
    "href": "gjenopprette-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Alle b√∏tter har automatisk versjonering. Dette gj√∏r det mulig √• tilbakef√∏re filer til en tidligere versjon eller gjenopprette filer som er slettet ved et uhell.\nLogg inn p√• Google Cloud Console og s√∏k opp ‚ÄúCloud Storage‚Äù i s√∏kefeltet. Klikk p√• den b√∏tten hvor filen er lagret under ‚ÄúBuckets‚Äù.\n\n\nFra Cloud Storage skjermbildet kan man navigere seg frem til den mappen hvor filen tidligere er lagret og skru p√• radioknappen ‚ÄúShow deleted data‚Äù (Figur¬†1)\n\n\n\nFigur¬†1: Skru p√• visning av slettede filer\n\n\nN√• vil man kunne se slettede filer i kursiv med teksten (Deleted) p√• slutten. Kolonnen ‚ÄúVersion history‚Äù vil ogs√• vise hvor mange tidligere versjoner som finnes av denne filen. Trykk p√• filnavnet du √∏nsker √• gjenopprette og velg deretter fanen ‚ÄúVersion history‚Äù. I listen av versjoner til denne filen har man mulighet til √• gjenopprette til en tidligere versjon ved √• klikke p√• ‚ÄúRestore‚Äù (Figur¬†2).\n\n\n\nFigur¬†2: Gjenoppretting av en slettet fil\n\n\n\n\n\nFra Cloud Storage skjermbildet kan man navigere seg frem til den mappen hvor filen er lagret, og trykke p√• filnavnet. Velg deretter fanen ‚ÄúVersion history‚Äù. I listen av versjoner til denne filen har man mulighet til √• gjenopprette til en tidligere versjon ved √• klikke p√• ‚ÄúRestore‚Äù (Figur¬†3).\n\n\n\nFigur¬†3: Versjonshistorikk til en fil"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Referanser"
  },
  {
    "objectID": "administrasjon.html",
    "href": "administrasjon.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "I dette kapitlet viser vi hvordan du kan gj√∏re endringer i et eksisterende team. Typiske endringer er √•:\n\nLegge til eller fjerne medlemmer i et team\nListe ut medlemmer og tilgangsgrupper i et team\n\nMer kommer snart.\n\n\nFor √• legge til eller fjerne medlemmer i et team m√• du forel√∏pig opprette en Kundeservice-sak. Oppgi navnet p√• teamet du √∏nsker √• endre p√• og hvilke medlemmer du √∏nsker √• legge til eller fjerne. Oppgi ogs√• hvilken tilgangsgruppe medlemmene skal ha (data-admins, developers eller consumers).\nEndringer i team m√• godkjennes av seksjonsleder f√∏r de blir gjort.\n\n\n\n\n\n\nMidlertidig l√∏sning\n\n\n\nAt endringer i team m√• gj√∏res via Kundeservice er midlertidig. Det jobbes med √• lage et eget verkt√∏y for dette.\n\n\n\n\n\nFor √• se hvem som har hvilke tilganger i et Dapla-team s√• kan du g√• inn p√• Azure Active directory. Her f√•r du se en oversikt over alle Dapla-team, hvem som er medlemmer, og hvilken tilgangsrolle de har.\nAnta at vi √∏nsker √• se hvilke SSB-ansatte som har tilgang til teamet skatt-person. Da kan vi gj√∏re f√∏lgende:\n\nG√• inn p√• nettsiden til Azure Active directory.\nSkriv inn skatt-person i s√∏kefeltet slik som vist i Figur¬†1.\n\n\n\n\nFigur¬†1: Nettsiden til Azure Active directory.\n\n\nFigur¬†1 viser at det finnes 5 tilgangsroller knyttet til et Dapla-team:\n1. managers (benyttes ikke enda)\n2. support (benyttes ikke enda)\n3. developers\n4. consumers\n5. data-admins\nI realiteten er det bare data-admin og developer som er aktuelle tilgangsroller for √• produsere statistikk i Dapla-teamet. consumers-rollen innehas av folk fra andre Dapla-team som skal ha tilgang til data i din delt-b√∏tte.\n\nHvis jeg √∏nsker √• se hvem som er data-admins i teamet skatt-person, s√• kan jeg trykke p√• skatt-person-data-admins, og derettes trykke p√• Members i menyen til venstre. Da f√•r jeg opp en liste over alle som har tilgang til data-admins i Dapla-teamet skatt-person."
  },
  {
    "objectID": "pakke-install.html",
    "href": "pakke-install.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Installering av pakker er kun er mulig I et virtuelt milj√∏. Det er anbefalt √• benytte poetry til dette. Eksemplene videre tar derfor utgangspunkt i et poetry prosjekt.\nDet er mulig √• installere pakker med pip. Pakker kan installeres som normalt, hvis man har satt opp og aktivert et virtuelt milj√∏.\n\n\nDette eksemplet viser hvordan man setter oppe et enkelt poetry prosjekt kalt test, hvis man √∏nsker √• benytte et annet prosjektnavn m√• man endre dette i hver av kommandoene.\nSett opp prosjektet:\npoetry new test\nNaviger inn i prosjektmappen:\ncd test\nBruk poetry install for √• bygge prosjektet:\npoetry install\nHvis man f√•r en tilbakemelding som denne er prosjektet satt opp korrekt:\nCreating virtualenv test-EojoH6Zm-py3.10 in /home/jovyan/.cache/pypoetry/virtualenvs \nUpdating dependencies \nResolving dependencies... (0.1s) \n\nWriting lock file \n\n\n\nFor √• legge til pakker i et prosjekt benyttes kommandoen poetry add.\nSkal man legge til pakken ‚Äúpendulum‚Äù vil det se slik ut:\npoetry add pendulum\nPoetry tilbyr m√•ter √• sette versjonsbegrensninger for pakker som legges til i et prosjekt, dette kan man lese mer om her.\n\n\n\nFor √• fjerne pakker fra et prosjekt benytter man poetry remove.\nHvis man √∏nsker √• fjerne ‚Äúpendulum‚Äù fra et prosjekt vil kommandoen se slik ut:\npoetry remove pendulum\n\n\n\nFor √• oppdatere pakker i et prosjekt benytter man kommandoen poetry update.\nSkal man oppdatere pakken ‚Äúpendulum‚Äù bruker man:\npoetry update pendulum\nSkal man oppdatre alle pakken i et prosjekt benytter man:\npoetry update \n\n\n\nN√•r man installerer pakker s√• vil det etter hvert utvikle seg et sett av potensielt kompliserte avhengigheter mellom disse pakkene. Dette skyldes at en pakke kan benytte seg av funksjonalitet i andre pakker, som igjen benytter seg av funksjonalitet i andre pakker, osv.. Hvis noen finner en sikkerhetss√•rbarhet i en pakke s√• kan det fikses ved at en ny versjon av den pakken slippes, som igjen kan f√• konsekvenser for pakker som er avhengig av denne.\nI SSB er det tilrettelagt for at alle som versjonsh√•ndterer koden sin p√• GitHub kan skanne pakkene sine for s√•rbarheter og nye versjoner av pakker med Dependabot. Dependabot hjelper oss med √• finne og fikse s√•rbarheter og gamle pakkeversjoner. Dette er spesielt viktig n√•r man installerer sine egne pakker.\nDet er anbefalt at alle som installerer sine egne pakker i SSB skrur p√• Dependabot i sine GitHub-repoer. Du kan skru p√• ved √• gj√∏re f√∏lgende:\n\nG√• inn repoet\nTrykk p√• Settings for det repoet som vist p√• Figur¬†1.\n\n\n\n\nFigur¬†1: √Öpne Settings for et GitHub-repo.\n\n\n\nI menyen til venstre velger du Code security and analysis\nUnder seksjonen Dependabot velger Enable p√• minst Dependabot alerts og Dependabot security updates, slik som vist i Figur¬†2.\n\n\n\n\nFigur¬†2: Skru p√• Dependabot i GitHub.\n\n\nN√•r du har gjort dette vil GitHub varsle deg hvis det finnes en kjent s√•rbarhet i pakkene som benyttes.\n\n\n\nFor √• kunne benytte det virtuelle milj√∏et i en notebook m√• man sette opp en kernel. Kernel burde gis samme navn som prosjektet.\nF√∏rst legger man til ipykernel:\npoetry add ipykernel\nS√• opprettes kernel med:\npoetry run python -m ipykernel install --user --name test\nEtter dette er kernelen test opprettet og kan velges for √• benytte milj√∏et i en notebook.\n\n\n\nFor √• fjerne en kernel med navn test bruker man:\njupyter kernelspec remove test\nDu vil bli spurt om √• bekrefte, trykk y hvis man √∏nsker √• slette:\nKernel specs to remove:\n  test                    /home/jovyan/.local/share/jupyter/kernels/test\nRemove 1 kernel specs [y/N]: y\nEtter dette er kernelen fjernet.\n\n\n\nHvem som helst kan legge til pakker p√• PyPi, det betyr at de i verstefall, kan inneholde skadelig kode. Her er en list med viktige tiltak som minimere risikoen:\n\nF√∏r man installerer pakker b√∏r man alltid s√∏ke de opp p√• https://pypi.org. Det er anbefalt √• klippe og lime inn pakkenavnet n√•r man skal legge det til i et prosjekt.\nEr det et popul√¶rt/velkjent prosjekt? Hvor mange stjerner og forks har repoet?\n\n\n\n\n\nInstallering av pakker for R-milj√∏et i Jupyterlab er forel√∏pig ikke en del av ssb-project. Men vi kan bruke renv. Mer kommer.\n\n\nFor √• installere dine egne R-pakker m√• du opprette et virtuelt milj√∏ med renv. G√• inn i Jupyterlab og √•pne R-notebook. Deretter skriver du inn f√∏lgende i kodecelle:\nrenv::init()\nDenne kommandoer aktiverer et virtuelt milj√∏ i mappen du st√•r i. Rent praktisk vil det si at du fikk f√∏lgende filer/mapper i mappen din:\nrenv.lock\nEn fil som inneholder versjoner av alle pakker du benytter i koden din.\n.Rprofile En fil som inneholder informasjon om oppsetting av milj√∏ og alternative.\nrenv\nMappe som inneholder alle pakkene du installerer.\nrenv/activate.R En fil som aktivere renv milj√∏ for et prosjekt.\nHvis prosjektet ligger p√• GitHub, skal filene renv.lock, .Rprofile og renv/activate.R v√¶re p√• GitHub\nN√• som vi har et virtuelle milj√∏et p√• plass kan vi installere en R-pakke. Du kan gj√∏re dette fra b√•de terminalen og fra en Notebook. Vi anbefaler p√• gj√∏re det fra terminalen fordi du da f√•r tilbakemelding p√• om installeringen gikk bra heller ikke. For √• installere i terminalen gj√∏r du f√∏lgende:\n\n√Öpne en terminal i Jupyterlab\nSt√• i mappen der du aktiverte det virtuelle milj√∏et\nSkriv in R og trykk enter.\n\nDet vi n√• har gjort er √• √•pne R fra terminalen slik at vi kan skrive R-kode direkte i terminalen. Det omtales ofte som en R Console. N√• kan du skrive inn en vanlig kommando for √• installere R-pakker:\nrenv::install(\"PxWebApiData\")\nOver installerte vi pakken PxWebApiData fra den R sentral repository CRAN. Dette er en pakke skrevet i SSB for √• hente ut data fra v√•r statistikkbank. Det er ogs√• mulig √• installere pakker som ligger p√• SSBs GitHub. Da m√• vi spesifisere at pakke ligger p√• ‚Äòstatisticsnorway‚Äô omr√•de. For eksempel:\nrenv::install(\"statisticsnorway/klassR\")\nPakken klassR er skrevet for √• hente ut klassifikasjoner fra SSBs KLASS. Det er en public repository p√• Github og √•pen for alle √• laste ned. For pakker som er p√• et lukket omr√•de p√• ‚Äòstatsitcsnorway‚Äô m√• vi bruke Personal Authentication Token for √• installere. Vi kan gj√∏re dette ved hjelp av funksjonen install_github() i devtools pakken. For eksempel:\n```{r}\nrenv::install(\"devtools\")\nrenv::install(\"getPass\")\ndevtools::install_github(\"statisticsnorway/fellesr\", \n                        auth_token = getPass::getPass())\n\n```\nLa oss bruke pakken PxWebApiData i koden v√•r med ved √• skrive f√∏lgende i kodecelle i Notebooken v√•r:\nlibrary(PxWebApiData)\nApiData(\"https://data.ssb.no/api/v0/en/table/04861\", \n        Region = c(\"1103\", \"0301\"), ContentsCode = \"Bosatte\", Tid = c(1, 2, -2, -1))\nN√•r vi n√• har brukt PxWebApiData i koden v√•r s√• kan vi kj√∏re en kommando som legger til den pakken i renv.lock. Men f√∏r vi kan gj√∏re det m√• vi v√¶re obs p√• at renv ikke klarer √• gjenkjenne pakker som er i bruk Notebooks (ipynb-filer). Det er veldig upraktisk, men noe vi m√• forholde oss til n√•r vi jobber med renv i Jupyterlab. En mulig l√∏sning for dette er √• bruke Jupytext til √• synkronisere en ipynb-fil med en Rmd-fil. renv kjenner igjen b√•de R- og Rmd-filer. For √• synkronisere filene gj√∏r du f√∏lgende:\n\nTrykk Ctrl+Shift C\nSkriv inn Pair i s√∏kefeltet som dukker opp\nVelg Pair Notebook with R Markdown\n\nHvis du n√• endrer en av filene s√• vil den andre oppdatere seg, og renv vil kunne oppdage om du bruker en pakke i koden din. Men for √• trigge renv til √• lete etter pakker som er i bruk s√• m√• du skrive f√∏lgende kode i Notebooken eller R Console:\nrenv::snapshot()\nKikker du n√• inne i renv.lock-filen s√• ser du n√• at verjsonen av PxWebApiData er lagt til. I bildet under ser du hvordan et arbeidsmilj√∏ typisk kan se ut n√•r man installerer sine egne pakker.\n\nFor √• installere alle pakker som ligger i renv.lock-filen med riktig versjon kan du skriver\nrenv:restore()\nDette er nyttig om det er nye medlemmer i gruppen som skal kj√∏re en produksjonsl√∏p utviklet av andre.\n\n\n\nIndivide pakker kan fjernes fra library ved remove() funksjonen. For eksempel:\nrenv::remove(\"PxWebApiData\")\nFor √• fjerne fra renv.lock-filen ogs√• m√• du ta en snapshot() etterp√•.\nrenv::snapshot()\nEn annen nyttig funksjon er renv::clean(). Dette fjerner alle pakker fra library som ikke er i bruk\nrenv::clean()\nIgjen m√• du ta en snapshot() for at endringer skal lagres p√• renv.lock-filen\n\n\n\nFor √• oppgradere en pakke kan du bruke renv::update(). For eksempel √• oppgradere PxWebApiData skriv:\nrenv::update(\"PxWebApiData\")\nFor √• installere et spesifikk versjon av en pakke kan du spesifisere dette med installering med @ og versjonsnummer. For eksempel √• installere PxWEbApiData versjon 0.4.0:\nrenv::install(\"PxWebApiData@0.4.0\")\nHusk √• ta en snapshot() etterp√• for √• lagre endringer til renv.lock-filen. Det betyr at du og andre kan gjenskape milj√∏ p√• nytt.\nrenv::snapshot()"
  },
  {
    "objectID": "virtual-env.html",
    "href": "virtual-env.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Et python virtuelt milj√∏ inneholder en spesifikk versjon av python og et sett med pakker. Pakkene er kun tilgjengelige n√•r det virtuelle milj√∏et er aktivert. Dette gj√∏r at man ung√•r avhengighetskonflikter p√• tvers av prosjekter.\nSe her for mer informasjon om virtuelle milj√∏er.\n\n\nDet er anbefalt √• benytte verkt√∏yet poetry for √• administrere prosjekter og deres virtuelle milj√∏.\nPoetry setter opp virtuelt milj√∏, gj√∏r det enkelt √• oppdatere avhengigheter, sette versjonsbegrensninger og reprodusere prosjektet.\nPoetry gj√∏r dette ved √• lagre avhengigheters eksakte versjon i prosjektets ‚Äúpoetry.lock‚Äù. Og eventuelle begrensninger i ‚Äúpyproject.toml‚Äù. Dette gj√∏r det enkelt for andre √• bygge prosjektet med akkurat de samme pakkene og begrensningene."
  },
  {
    "objectID": "overf√∏re-data.html",
    "href": "overf√∏re-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "For √• overf√∏re data mellom bakke og sky brukes Data Transfer, som er en tjeneste i Google Cloud Console. Denne tjenesten kan brukes til √• flytte data b√•de til og fra Linuxstammen og Dapla, og er tilgjengelig for teamets kildedataansvarlige.\nFor √• f√• tilgang til √• overf√∏re filer m√• man be om dette ved opprettelsen av teamet. Ber man om det skjer f√∏lgende:\n\nEn mappe blir opprettet p√• Linux i prodsonen under /ssb/cloud_sync/\nEt Google Project blir opprettet med navn <team navn>-ts.\n\nDette Google-prosjektet er ikke det samme som der du lagrer annen data. Det har navnet <team navn>-ts, og filstiene p√• bakken og sky vises i Figur¬†1.\n\n\n\nFigur¬†1: Hvordan Transfer Service kan flytte filer mellom bakke og sky.\n\n\nTeamets kildedataansvarlige vil v√¶re spesifisert som en del av √• opprette et Dapla-team.\n\n\nEnten man skal overf√∏re filer opp til sky eller ned til bakken s√• bruker man den samme Data Transfer tjenesten. For √• f√• tilgang til denne m√• man f√∏rst logge seg inn i Google Cloud Console. Sjekk at du er logget inn med din SSB-konto (xxx@ssb.no).\n√òverst p√• siden, til h√∏yre for teksten Google Cloud finnes det en prosjektvelger, og her er det viktig √• velge korrekt Google prosjekt. Hvis du trykker p√• prosjektvelgeren vil det √•pnes opp et nytt vindu. Sjekk at det st√•r SSB.NO √∏verst i dette vinduet. Trykk deretter p√• fanen ALL for √• f√• opp alle tilgjengelige Google-prosjekter under organisasjonen ssb.no (Figur¬†2)\n\n\n\nFigur¬†2: Prosjektvelgeren i Google Cloud Console\n\n\nUnder ssb.no vil det ligge flere mapper. √Öpne mappen som heter production og let frem en undermappe som har navnet p√• ditt Dapla-team. Strukturen skal se slik ut:\n    ssb.no\n    ‚îú‚îÄ‚îÄ production\n        ‚îî‚îÄ‚îÄ <teamnavn>\n            ‚îú‚îÄ‚îÄ prod-<teamnavn>\n            ‚îî‚îÄ‚îÄ <teamnavn>-ts\nDet underste niv√•et (prod-<teamnavn> og <teamnavn>-ts) viser prosjektene, niv√•et i mellom er mapper, og toppniv√•et er organisasjonen (ssb.no). Prosjektet <teamnavn>-ts er et separat prosjekt som bare teamets kildedataansvarlige har tilgang til, og det er her tjenesten Data Transfer skal settes opp.\n\nVelg derfor prosjektet <teamnavn>-ts.\nI s√∏kefeltet til Google Cloud Console, skriv Data transfer og trykk p√• det valget som kommer opp.\nF√∏rste gang man kommer inn p√• siden til Transfer Services vil man bli vist en bl√• knapp med teksten Set Up Connection. N√•r du trykker p√• denne vil det dukke opp et nytt felt hvor du f√•r valget Create Pub-Sub Resources. Dette er noe som bare trengs √• gj√∏re √©n gang. Trykk p√• den bl√• CREATE knappen, og deretter trykk p√• Close lenger nede.\nI navigasjonsmenyen til venstre trykk Transfer jobs, og deretter trykk p√• + Create transfer job √∏verst p√• siden for √• opprette en ny overf√∏ringsjobb.\n\n\n\nF√∏lgende oppskrift tar utgangspunkt i siden Create a transfer job (Figur¬†3):\n\n\n\nFigur¬†3: Opprett overf√∏ringsjobb i Google Cloud Console\n\n\n\nVelg POSIX filesystem under ‚ÄúSource type‚Äù og Google cloud storage under ‚ÄúDestination type‚Äù (eller motsatt hvis overf√∏ringsjobben skal g√• fra Dapla til Linuxstammen). Trykk Next step\nNedtrekkslisten ‚ÄúAgent pool‚Äù skal normalt bare ha ett valg: transfer_service_default. Velg denne.\nI feltet ‚ÄúSource directory path‚Äù skal man kun skrive data/tilsky siden overf√∏ringsagenten kun har tilgang til mapper som ligger relativt plassert under /ssb/cloud_sync/<teamnavn>/. Trykk Next step\nVelg en destinasjon for overf√∏ringsjobben. Trykk p√• Browse og velg b√∏tten med navn som passer til ssb-prod-<teamnavn>-data-synk-opp. Vi anbefaler at du ogs√• oppretter en mappe inne i denne b√∏tten. Det gj√∏res ved √• trykke p√• mappeikonet med et +-tegn foran. Skriv inn et passende mappenavn og trykk Select i bunnen av siden. Trykk deretter Next step\nNeste steg ‚ÄúChoose how and when to run this job‚Äù er opp til brukeren √• bestemme. Hvis man f.eks. velger at Data Transfer skal overf√∏re data en gang i uken, vil den kun starte en overf√∏ring hvis det finnes nye data. Trykk Next step\nBeskriv overf√∏ringsjobben, f.eks: ‚ÄúFlytter data for  til sky.‚Äù. Resten av feltene er opp til brukeren √• bestemme. Standardverdiene er OK.\n\nTrykk til slutt p√• den bl√• Create-knappen. Du vil kunne se kj√∏rende jobber under menyen Transfer jobs.\nFor √• sjekke om data har blitt overf√∏rt, skriv inn cloud storage i s√∏kefeltet √∏verst p√• siden og trykk p√• det f√∏rste valget som kommer opp. Her vil du finne en oversikt over alle teamets b√∏tter, deriblant en med navn ssb-prod-<team-name>-data-synk-opp. N√•r overf√∏ringsjobben er ferdig vil du kunne finne igjen dataene i den mappen som ble definert i stegene overnfor.\n\n\n\nOverf√∏ringsjobben settes opp nesten identisk med Overf√∏ring fra Linuxstammen til Dapla med unntak av f√∏lgende:\n\nSteg 1: Velg Google cloud storage under ‚ÄúSource type‚Äù og POSIX filesystem under ‚ÄúDestination type‚Äù\nSteg 2: Velg b√∏tten ssb-prod-<team-name>-data-synk-ned\nStep 3: Velg transfer_service_default som ‚ÄúAgent pool‚Äù og skriv data/frasky inn i feltet for ‚ÄúDestination directory path‚Äù.\n\nFor √• se om data har blitt overf√∏rt til Linuxstammen m√• du n√• g√• til mappen /ssb/cloud_sync/<team-name>/data/frasky fra FileZilla.\nHusk: Du kan alltids g√• tilbake og se p√• tidligere fullf√∏rte jobber, og starte en overf√∏ringsjobb manuelt fra menyen Transfer jobs.\n\n\n\n\nN√•r du har satt opp en, enten for √• overf√∏re fra sky eller til sky, kan du skrive ut data til mappen eller b√∏tten som du har bedt Transfer Service om √• overf√∏re data fra.\nHvis du skal overf√∏re data fra bakken/prodsonen til sky, s√• m√• teamets kildedataansvarlige skrive ut data til Linux-mappen /ssb/cloud_sync/<team navn>/data/tilsky, og det vil ende opp i Dapla-b√∏tta gs://ssb-prod-<team navn>-data-synk-opp Dette kan du gj√∏re med alle programmeringsverkt√∏y som har en kobling til Linux-stammene der dataene ligger. For eksempel:\n\nSAS EG\nSAS-installasjon p√• Linux\nJupyterlab i prodsonen\nRstudio p√• sl-stata-03\n\nSkal du flytte data fra Dapla til bakken/prodsonen, s√• m√• teamets kildedataansvarlige skrive ut data til gs://ssb-prod-<team navn>-data-synk-opp-b√∏tta p√• Dapla. Det er noe man typisk gj√∏r fra Jupyterlab p√• Dapla."
  },
  {
    "objectID": "datadoc.html",
    "href": "datadoc.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "For √• kunne gjenfinne data i SSB er man helt avhengig av at det finnes et enhetlig system for metadata knyttet til dataene. DataDoc er SSBs system for √• dokumentere datasett p√• den nye dataplattformen Dapla.\nDet er bygget et grensesnitt i Python for √• gj√∏re det enklest mulig √• dokumentere et datasett. Forel√∏pig st√∏tter l√∏sningen f√∏lgende filformater:\n\nparquet\nsas7bdat\n\nUnder finner du beskrivelse av hvordan du kan begynne √• bruke l√∏sningen til √• dokumentere datasett.\n\n\n\n\n\n\nAdvarsel\n\n\n\nVi √∏nsker at du skal teste DataDoc-applikasjonen. Den viktigste funksjonaliteten skal v√¶re tilgjengelig, og det er fullt mulig √• benytte DataDoc i SSBs Jupyter-milj√∏er. Det er imidlertid viktig √• v√¶re klar over at applikasjonen fortsatt er i en utviklings- og testfase (beta-l√∏sning) og kan inneholde feil og mangler.\nHar du sp√∏rsm√•l, eventuelt vil rapporterer om feil og mangler, s√• setter vi pris p√• om du gj√∏r dette i Yammer-gruppa Dapla.\n\n\n\n\nF√∏r du tar i bruk DataDoc-applikasjonen er det viktig √• forst√• hvilken informasjon som skal til for √• dokumentere et datasett. I DataDoc-applikasjonen skal du fylle ut flere felter om b√•de datasettet og variablene som inng√•r i datasettet, eksempelvis\n\nkortnavn\nnavn\ndatatilstand\npopulasjonsbeskrivelse\n++\n\nDet er utarbeidet en detaljert beskrivelse hva hvert felt betyr, og hvordan de skal fylles ut b√•de for datasett og variabler: - DataDoc - hvordan dokumentere et datasett - DataDoc - hvordan dokumentere variablene (variabelforekomstene) som inng√•r i datasettet\nDataDoc skal v√¶re installert i alle Jupyter-milj√∏ene i SSB, s√• du trenger ikke installere pakken selv.\n\n\n\n\n\n\nViktig informasjon\n\n\n\nDataDoc kan forel√∏pig ikke kj√∏res i Jupyter notebook med virtuelle milj√∏er (f.eks. et ssb-project), men m√• startes i den vanlige kernelen i en notebook.\n\n\n\n\n\nLa oss lage et test-datasett slik at vi kan leke oss litt med DataDoc:\nimport pandas as pd\nfrom datadoc import main\n  \n# Create fake data\ndata = {'id': ['9999999999', '8888888888', '7777777777', '6666666666'],\n        'fylke': [\"01\", \"02\", \"03\", \"03\"],\n        'inntekt': [500000, 250000, 400000, 440000],\n        'rente': [3.2, 4.1, 3.3, 3.4]}\n  \n# Creates a Pandas dataframe\ndf = pd.DataFrame(data)\n\n# Write a Parquet-file to current folder\ndf.to_parquet(\"./test.parquet\")\nN√• har vi en fil som heter test.parquet i mappen vi st√•r. Da kan vi √•pne DataDoc-grensesnittet for √• legge inn metadataene:\nmain(\"./test.parquet\")\nFigur¬†1 viser hvordan DataDoc-grensesnittet ser ut.\n\n\n\nFigur¬†1: Gif som viser hvordan DataDoc-grensesnittet ser ut.\n\n\n\n\n\nN√•r du trykker p√• Lagre-knappen i DataDoc s√• skrives alle metadata til en fil i samme mappe (katalog) som datafilen. Dette er en JSON-fil med nesten samme navn som datafilen. Navnekonvensjonen for metadatafilen er\n<navn p√• datafil uten endelse>__DOC.json\nEksempelvis hvis datafilen har navnet skattedata_p2022_v1.parquet, s√• vil DataDoc lagre metadata i filen skattedata_p2022_v1__DOC.json.\nFordelen med √• benytte en JSON-fil til √• lagre metadata er at denne filen kan kopieres og flyttes like enkelt som selve datafilen. JSON-filer er strukturerte tekstfiler som kan leses av b√•de maskiner (Python/R) og av mennesker (√•pnes i en tekst-editor).\nSe et eksempel p√• JSON metadata-fil lagret av DataDoc.\n\n\n\n\n\n\nInformasjon\n\n\n\nI Dapla skal det bygges en felles datakatalog for SSB. Tanken er at alle metadata, eksempelvis datasett-dokumentasjon fra DataDoc (JSON-filene), skal inng√• i SSBs datakatalog. Datakatalogen gj√∏r det mulig √• finne (s√∏ke etter), forst√•r og gjenbruke data b√•de internt og ekstern."
  },
  {
    "objectID": "hvorfor-dapla.html",
    "href": "hvorfor-dapla.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Hvorfor Dapla?\nSom dataplattform skal Dapla stimulerere til √∏kt kvalitet p√• statistikk og forskning, samtidig som den gj√∏r organisasjonen mer tilpasningsdyktig i m√∏te med fremtiden.\n\n\nDen nye skybaserte dataplattformen (Dapla) skal bli viktig for √• effektivisere arbeids-og produksjonsprosesser, den skal sikre effektiv lagring og gjenfinning av data og metadata, og st√∏tte opp under deling av data p√• tvers av statistikkomr√•der.\n\nKilde: Langtidsplan for SSB (2022-2024)\n\n\n\nM√•let med Dapla er √• tilby tjenester og verkt√∏y som lar statistikkprodusenter og forskere produsere resultater p√• en sikker og effektiv m√•te."
  },
  {
    "objectID": "jobbe-med-data.html",
    "href": "jobbe-med-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "N√•r vi oppretter et dapla-team s√• f√•r vi tildelt et eget omr√•det for lagring av data. For √• kunne lese og skrive data fra Jupyter til disse omr√•dene m√• vi autentisere oss, siden Jupyter og lagringsomr√•det er to separate sikkerhetsoner.\nFigur¬†1 viser dette klarer skillet mellom hvor vi koder og hvor dataene ligger p√• Dapla1. I dette kapitlet beskriver vi n√¶rmere hvordan du kan jobbe med dataene dine p√• Dapla.\n\n\n\nFigur¬†1: Tydelig skille mellom kodemilj√∏ og datalagring p√• Dapla.\n\n\n\n\nFor √• gj√∏re det enklere √• jobbe data p√• tvers av Jupyter og lagringsomr√•det er det laget noen egne SSB-utviklede biblioteker for √• gj√∏re vanlige operasjoner mot lagringsomr√•det. Siden b√•de R og Python skal brukes p√• Dapla, s√• er det laget to biblioteker, en for hver av disse spr√•kene. fellesr er biblioteket for R, og dapla-toolbelt er biblioteket for Python.\n\n\ndapla-toolbelt er en en pakke som lar deg enkelt lese og skrive til lagringsomr√•det uten √• m√•tte autentifisere deg manuelt. Den har en Pandas-aktig syntaks som forh√•pentlig er gjenkjennbar for de fleste. Pakken er installert i alle Python-kernels p√• Dapla, s√• du trenger ikke √• installere den selv hvis du √•pner en notebook med Python3 for eksempel. For √• importere hele biblioteket i en notebook skriver du bare\nimport dapla as dp\ndapla-toolbelt bruker en pakke som heter gcsfs for √• kommunisere med lagringsomr√•det. gcsfs er en pakke som lar deg bruke Google Cloud Storage (GCS) som om det var en filsystem. Det betyr at du kan bruke samme syntaks som du bruker for √• lese og skrive til filer p√• din egen maskin. Du kan lese mulighetene i gcsfs her. Et eksempel p√• hvordan de to pakkene kan brukes sammen ser du her:\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Example of how you can use gcsfs and dapla-toolbelt together\nfs.mkdir(\"gs://my-bucket/my-folder\")\nI koden over brukte jeg kommandoen mkdir fra gcsfs og FileClient fra dapla-toolbelt for √• opprette en mappe i lagringsomr√•det.\nI kapitlene under finner du konkrete eksempler p√• hvordan du kan bruke dapla-toolbelt til √• jobbe med data i SSBs lagringsomr√•det.\n\n\n\nR-pakken fellesr er under utvikling og gir mye av den samme funksjonaliteten som dapla-toolbelt gir for Python. I tillegg til √• kunne lese og skrive til lagringsomr√•det p√• Dapla, s√• har fellesr ogs√• funksjoner for √• jobbe med metadata p√• Dapla.\nfellesr er forel√∏pig ikke tilgjengeliggjort som en pakke som kan installeres. For √• bruke pakken kan du gj√∏re f√∏lgende:\n\nKopiere scriptet DAPLA_funcs.R og legg den i en fil sammen med Notebooken din\nI en R-notebook som ligger i samme mappe som filen DAPLA_funcs.R starter du med √• skrive\n\nsource(\"DAPLA_funcs.R\")\nDa er alle funksjonene tilgjengelig for deg i Notebooken din.\n\n\n\n\n\n\n\n\n\n\nEksempeldata\n\n\n\nDet finnes et omr√•de som alle SSB-ansatte har lese- og skrivetilgang til. Det er\ngs://ssb-prod-dapla-felles-data-delt/ i prod-milj√∏et p√• Dapla, og\ngs://ssb-staging-dapla-felles-data-delt/ i staging-milj√∏et. Eksemplene under bruker f√∏rstnevnte i koden, slik at alle kan kj√∏re koden selv.\nKode-eksemplene finnes for b√•de R og Python, og du kan velge hvilken du skal se ved √• trykke p√• den arkfanen du er interessert i.\n\n\n√Ö liste ut innhold i et gitt mappe p√• Dapla er ganske enkelt. Under ser du hvordan du kan liste ut innholdet i f√∏lgende mappe:\ngs://ssb-prod-dapla-felles-data-delt/felles/veiledning/python/eksempler/purchases\n\nPython \n\n\nVi bruker modulen FileClient fra dapla-toolbelt for √• liste ut innholdet i en mappe.\nfrom dapla import FileClient\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\nFileClient.ls(f\"{bucket}/{folder}\")\nMed kommandoen over f√•r du listet ut alle filnavn i mappen. Hvis du vil ha mer informasjon om filene s√• kan du bruke ls-kommandoen med detail = True, som under:\nFileClient.ls(f\"{bucket}/{folder}\", detail = True)\nSyntaksen med ls er veldig lik det man kjenner fra en Linux-terminal. Men n√•r vi bruker detail = True blir metadata om filene returnert som en Python-liste med dictionaries. Det kan v√¶re sv√¶rt nyttig n√•r du f.eks. trenger √• vite dato og tidspunkt for n√•r en fil ble opprettet, eller n√•r den sist ble oppdatert.\n\n\n# Loading functions into notebook\nsource(\"DAPLA_funcs.R\")\n\n# Path to folder\nbucket <- \"ssb-prod-dapla-felles-data-delt/\"\nfolder <- \"felles/veiledning/python/eksempler/purchases\"\n\n# List files in folder \nlist.files(paste0(bucket, folder))\n\n\n\n\n\n\n√Ö skrive filer til et lagringsomr√•de p√• Dapla er ogs√• ganske enkelt. Det ligner mye p√• den syntaksen vi er kjent med fra vanlige R- og Python-pakker, med noen sm√• unntak.\n\n\nUnder lager vi en dataframe i en notebook og skriver den ut til en parquet-fil. Stien vi skriver til er\ngs://ssb-prod-dapla-felles-data-delt/felles/veiledning/python/eksempler/purchases:\n\nPython \n\n\nN√•r vi leser en Parquet-fil med dapla-toolbelt s√• bruker den pyarrow i bakgrunnen. Dette er en av de raskeste m√•tene √• lese og skrive Parquet-filer p√•.\n\nimport dapla as dp\nimport pandas as pd\nimport numpy as np\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Create pandas dataframe\npurchases = pd.DataFrame(np.random.randn(10, 5),\n                        columns=[\"A\", \"B\", \"C\", \"D\", \"E\"])\n\n# Write pandas dataframe as parquet to GCS bucket\ndp.write_pandas(df = purchases,\n                gcs_path = f\"{bucket}/{folder}/data.parquet\",\n                file_format = \"parquet\",)\nN√•r vi kalte write_pandas over s√• spesifiserte vi at filformatet skulle v√¶re parquet. Dette er default, s√• vi kunne ogs√• ha skrevet det slik:\ndp.write_pandas(df = purchases,\n                gcs_path = f\"{bucket}/{folder}/data.parquet\")\nMen for de andre filformatene m√• vi alts√• spesifisere dette.\n\n\nKommer snart\n\n\n\n\n\n\nKommer snart eksempler p√• hvordan man kan skrive ut tekstfiler som CSV, JSON og XML.\n\nPython \n\n\ndapla-toolbelt kan skrive ut json, csv og posisjonsfiler (fixed-width-files/fwf) til lagringsomr√•det. M√•ten den gj√∏r det p√• er √• bruke Pandas sine funksjoner read_json, read_csv, read_fwf under panseret. Dette kan v√¶re nyttig √• vite for skj√∏nne hvordan dapla-toolbelt h√•ndterer ulike strukturer i (spesielt hierarkiske) tekstfiler. Under ser du hvordan du kan skrive ut en dataframe til en json-fil.\nimport numpy as np\nimport pandas as pd\nfrom dapla import FileClient\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Create a dataframe with Pandas\ndf = pd.DataFrame(np.random.randn(10, 5), columns=[\"A\", \"B\", \"C\", \"D\", \"E\"])\n\n# Save dataframe as json with dapla-toolbelt\ndp.write_pandas(df = df,\n                gcs_path = f\"{bucket}/{folder}/test.json\",\n                file_format = \"json\")\nSom vi ser at syntaksen over s√• kunne vi skrevet ut til noe annet enn json ved √• endre verdien i argumentet file_format.\n\n\nKommer snart.\n\n\n\n\n\n\nDet er ikke anbefalt √• bruke xlsx-formatet, men her ser du hvordan det kan skrives ut. Mer kommer.\n\nPython \n\n\nimport pandas as pd\nfrom dapla import AuthClient\n\n# Henter token for √• kunne lese fra Dapla\ntoken = AuthClient.fetch_google_credentials()\n\n# Filsti\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\ndf.to_excel(f\"{bucket}/{folder}/test.xlsx\",\n           storage_options={\"token\": token})\n\n\nKommer snart\n\n\n\n\n\n\n\n√Ö lese inn filer p√• med dapla-toolbelt er nesten like rett frem som med Pandas. Under finner du eksempler p√• hvordan du kan lese inn data til en Jupyter Notebooks p√• Dapla.\n\n\n\nPython \n\n\nimport dapla as dp\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Read path into pandas dataframe \ndp.read_pandas(gcs_path= f\"{bucket}/{folder}/data.parquet\",\n               file_format = \"parquet\",\n               columns = None,)\nSom vi s√• med write_pandas s√• er file_format default satt til parquet, og default for columns = None, s√• vi kunne ogs√• ha skrevet det slik:\ndp.read_pandas(gcs_path= f\"{bucket}/{folder}/data.parquet\")\ncolumns-argumentet er en liste med kolonnenavn som vi √∏nsker √• lese inn. Hvis vi ikke spesifiserer noen kolonner s√• vil alle kolonnene leses inn.\n\n\nKommer snart\n\n\n\n\n\n\nKommer mer snart. Python-koden under bygger p√• eksempelet over.\n\nPython \n\n\nimport dapla as dp\n\n# Path to write to\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Read in json-file from dapla-storage\ndf = dp.read_pandas(gcs_path = f\"{bucket}/{folder}/test3.json\",\n               file_format = \"json\")\n\n\nKommer snart\n\n\n\n\n\n\n\nPython \n\n\nimport pandas as pd\nfrom dapla import AuthClient\n\n# Hent token\ntoken = AuthClient.fetch_google_credentials()\n\n# Les inn fil\ndf = pd.read_excel(\"gs://ssb-prod-arbmark-skjema-data-produkt/test_gcp.xlsx\",\n    storage_options={\"token\": token})\n\n\nKommer snart\n\n\n\n\n\n\n\n√Ö slette filer fra lagringsomr√•det kan gj√∏res p√• flere m√•ter. I kapitlet om sletting av data viste vi hvordan man gj√∏r det med pek-og-klikk i Google Cloud Console. Under ser du hvordan du kan slette filer med dapla-toolbelt og gcsfs.\n\nPython \n\n\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\nfs.rm(f\"{bucket}/{from_folder}/df.json\")\n\n\nKommer snart\n\n\n\n\n\n\n√Ö kopiere filer mellom mapper p√• et Linux-filsystem inneb√¶rer som regel bruke cp-kommandoen. P√• Dapla er det ikke s√• mye forskjell. Vi bruker en ligende tiln√¶rming n√• vi skal kopiere mellom b√∏tter eller mapper p√• lagringsomr√•det til SSB. Under ser du hvordan du kan kopiere en fil fra en mappe til en annen.\n\nPython \n\n\nLa oss begynne med et eksempel der vi kopierer en fil fra en mappe til en annen i samme b√∏tte.\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Path to folders\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfrom_folder = \"felles/veiledning/python/eksempler/purchases\"\nto_folder = \"felles/veiledning/python/eksempler\"\n\n# Copy file\nfs.cp(f\"{bucket}/{from_folder}/data.parquet\",\n      f\"{bucket}/{to_folder}/data_copy.parquet\")\nDet ogs√• fungere for √• kopiere filer mellom b√∏tter.\nEt annet scenario vi ofte vil st√∏te p√• er at vi √∏nsker √• kopiere en fil fra v√•r Jupyter-filsystem til en mappe p√• lagringsomr√•det. Her kan vi bruke fs.put-metoden.\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Create a new file in your home directory called test.txt\nwith open('/home/jovyan/test.txt', 'w') as f:\n    f.write('Create a new text file!')\n\n#Path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler\"\n\n# Copy file from local to remote file system\nfs.put(lpath=f\"/home/jovyan/test.txt\", rpath=f\"{bucket}/{folder}/test.txt\")\n√ònsker vi √• kopiere en hel mappe fra lagringsomr√•det til Jupyter-filsystemet, kan vi bruke fs.get-metoden, med opsjonen recursive=True.\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Copy file\nfs.get(<from_bucket>,\n      \"/home/jovyan/sesongjustering/\",\n      recursive=True)\n\n\nKommer snart\n\n\n\n\n\n\n\nPython \n\n\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfrom_folder = \"felles/veiledning/python/eksempler/purchases\"\nto_folder = \"felles/veiledning/python/eksempler\"\n\nfs.mv(f\"{bucket}/{from_folder}/data.parquet\", f\"{bucket}/{to_folder}/data.parquet\")\n\n\nKommer snart\n\n\n\n\n\n\n\nPython \n\n\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n#Path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler\"\n\n# Create folder\nfs.mkdir(f\"{bucket}/{folder}/testmappe/\")\n\n\nKommer snart"
  },
  {
    "objectID": "bakke-sky.html",
    "href": "bakke-sky.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Bakke vs.¬†sky"
  },
  {
    "objectID": "dapla-team.html",
    "href": "dapla-team.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Opprette Dapla-team\nI forrige del beskrev vi noen grunnleggende ting rundt Dapla. I denne delen tar vi for oss hvordan du kan begynne √• jobbe med skarpe data p√• plattformen.\nKapittelet som beskriver hvordan man logger seg inn p√• Dapla vil fungere uten at du m√• gj√∏re noen forberedelser. Er man koblet p√• SSB sitt nettverk s√• vil alle SSB-ansatte kunne g√• inn p√• plattformen og kode i Python og R. Men du har ikke tilgang til SSBs omr√•de for datalagring p√• plattformen. I praksis vil det si at man generere data med kode, men man ikke jobbe med skarpe data.\nFor √• f√• muligheten til √• jobbe skarpe data M√Ö du f√∏rst opprette et dapla-team. Dette er det f√∏rste naturlige steget √• ta n√•r man skal begynne √• jobbe med statistikkproduksjon p√• dapla. I dette kapittelet vil vi forklare det du trenger √• vite om det √• opprette og jobbe innenfor et team."
  },
  {
    "objectID": "pakke-install-bakken.html",
    "href": "pakke-install-bakken.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Installering av pakker i Jupyter milj√∏er p√• bakken (f.eks https://sl-jupyter-p.ssb.no) foreg√•r stort sett helt lik som p√• Dapla. Det er √©n viktig forskjell, og det er at installasjon skjer via en proxy som heter Nexus.\n\n\nPip er ferdig konfigurert for bruk av Nexus og kan kj√∏res som beskrevet for Dapla\n\n\n\nHvis man bruker Poetry for h√•ndtering av pakker i et prosjekt, s√• m√• man kj√∏re f√∏lgende kommando i prosjekt-mappe etter prosjektet er opprettet.\npoetry source add --default nexus `echo $PIP_INDEX_URL`\nDa f√•r man installere pakker som vanlig f.eks\npoetry add matplotlib\n\n\n\n\n\n\nHvis man fors√∏ker √• installere prosjektet i et annet milj√∏ (f.eks Dapla), s√• m√• man fjerner nexus kilden ved √• kj√∏re\npoetry source remove nexus\n\n\n\n\n\n\n\nProsessen med √• installere pakker for R p√• bakken er det samme som p√• Dapla. Noen pakker (for eksempel arrow og devtools) kan forel√∏pig ikke installeres p√• bakken p√• egenh√•nd pga 3. parti avhengigheter. Vi jobber med √• finne en l√∏sning til dette."
  },
  {
    "objectID": "b√∏tter.html",
    "href": "b√∏tter.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Hvert statistikkteam har sitt eget datalager som heter Google Cloud Storage (GCS). Disse er delt inn i flere datalagringsomr√•der som kalles b√∏tter. Dette kan sees p√• som et filsystem som kan organiseres med flere undermapper og filer. Navnet p√• b√∏ttene m√• v√¶re unikt p√• tvers av alle Dapla-team. Derfor blir disse opprettet etter en navnekonvensjon basert p√• kj√∏remilj√∏, teamnavn og hvilke data b√∏tta skal inneholde.\n\n\n\nssb-prod-teamnavn-data-kilde: Inneholder pseudonymiserte r√•data fra datakildene\nssb-prod-teamnavn-data-produkt: Inneholder data knyttet til statistikkproduktet, med f√∏lgende underkataloger:\n\ninndata\nklargjorte-data\nstatistikk\nutdata\n\nssb-prod-teamnavn-data-delt: Inneholder data knyttet til statistikkproduktet som kan deles med andre statistikkteam. Disse vil ha f√∏lgende underkataloger:\n\ninndata\nklargjorte-data\nstatistikk\nutdata\n\n\n\n\n\n\n\n\nUnderkatalogene inndata, klargjorte-data, statistikk og utdata gjenspeiler SSBs datatilstander. Se Datatilstander i SSB for mer informasjon.\n\n\n\n\n\n\nP√• samme m√•te som i produksjonsmilj√∏et finnes det b√∏tter for utviklings- og testform√•l:\n\nssb-staging-teamnavn-data-kilde\nssb-staging-teamnavn-data-produkt\nssb-staging-teamnavn-data-delt\n\n\n\n\nI tillegg til disse finnes det noen b√∏tter med data som kan deles med alle i SSB og og som kan brukes til kurs og oppl√¶ring (bl.a. denne manualen). Disse b√∏ttene er:\n\nssb-prod-dapla-data-delt\nssb-staging-dapla-data-delt"
  },
  {
    "objectID": "gcc.html",
    "href": "gcc.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Google Cloud Console\nGoogle Cloud er SSBs leverand√∏r av skytjenester som Dapla er bygget p√•.\nGoogle Cloud Console er et web-basert grensesnitt for √• administrere ressurser og tjenester p√• Google Cloud. For √• bruke denne m√• man ha en Google-konto. Alle i SSB har en konto knyttet opp mot Google.\n\n\n\n\n\n\nG√• til Google Cloud Console og logg p√• med din SSB-bruker."
  },
  {
    "objectID": "ssbproject.html",
    "href": "ssbproject.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "SSB-project\nI forrige del forklarte vi hvordan man jobber med skarpe data p√• Dapla. Det neste steget vil ofte v√¶re √• begynne √• utvikle kode i Python og/eller R. Dette inneb√¶rer at man helst skal:\n\nversjonsh√•ndtere med Git\nopprette et GitHub-repo\nopprette et virtuelt milj√∏ som husker hvilke versjoner av pakker og programmeringsspr√•k du brukte\n\nI tillegg m√• alt dette konfigureres for hvordan SSB sine systemer er satt opp. Dette har vist seg √• v√¶re un√∏dvendig krevende for mange. Team Statistikktjenester har derfor utviklet et program som gj√∏r alt dette for deg p√• en enkel m√•te som heter ssb-project.\nVi mener at ssb-project er et naturlig sted √• starte n√•r man skal bygge opp koden i Python eller R. Det gjelder b√•de p√• bakken og p√• sky. I denne delen av boken forklarer vi f√∏rst hvordan du bruker ssb-project i det f√∏rste kapittelet. Siden programmet skjuler mye av kompleksiteten rundt dette, s√• bruker vi de andre kapitlene til √• forklare hvordan man ville satt opp dette uten hjelp av programmet. Dermed vil det v√¶re lett for SSB-ansatte √• skj√∏nne hva som gj√∏res og hvorfor det er n√∏dvendig."
  },
  {
    "objectID": "innlogging.html",
    "href": "innlogging.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Innlogging p√• Dapla er veldig enkelt. Dapla er en nettadresse som alle SSB-ere kan g√• inn p√• hvis de er logget p√• SSB sitt nettverk. √Ö v√¶re logget p√• SSB sitt nettverk betyr i denne sammenhengen at man er logget p√• med VPN, enten man er p√• kontoret eller p√• hjemmekontor. For √• gj√∏re det enda enklere har vi laget en fast snarvei til denne nettadressen p√• v√•rt intranett/Byr√•nettet(se Figur¬†1).\n\n\n\nFigur¬†1: Snarvei til Dapla fra intranett\n\n\nMen samtidig som det er lett √• logge seg p√•, s√• er det noen kompliserende ting som fortjener en forklaring. Noe skyldes at vi mangler et klart spr√•k for √• definere bakkemilj√∏et og skymilj√∏et slik at alle skj√∏nner hva man snakker om. I denne boken definerer bakkemilj√∏et som stedet der man har drevet med statistikkproduksjon de siste ti√•rene. Skymilj√∏et er den nye dataplattformen Dapla p√• Google Cloud.\nDet som gj√∏r ting litt komplisert er at vi har 2 Jupyter-milj√∏er p√• b√•de bakke og sky. √Örsaken er at vi har ett test- og ett prod-omr√•de for hver, og det blir i alt 4 Jupyter-milj√∏er. Figur¬†2 viser dette.\n\n\n\nFigur¬†2: De 4 Jupyter-milj√∏ene i SSB. Et test-milj√∏ og et prod-milj√∏ p√• bakke og sky/Dapla\n\n\nHver av disse milj√∏ene har sin egen nettadresse og sitt eget bruksomr√•de.\n\n\nI de fleste tilfeller vil en statistikker eller forsker √∏nske √• logge seg inn i prod-milj√∏et. Det er her man skal kj√∏re koden sin i et produksjonsl√∏p som skal publiseres eller utvikles. I noen tilfeller hvor man ber om √• f√• tilgjengliggjort en ny tjeneste s√• vil denne f√∏rst rulles ut i testomr√•det som vi kaller staging-omr√•det. √Örsaken er at vi √∏nsker √• beskytte prod-milj√∏et fra software som potensielt √∏delegger for eksisterende funksjonalitet. Derfor ruller vi ut nye ting i staging f√∏rst. Av den grunn vil de fleste oppleve √• bli bedt om √• logge seg inn der for testing en eller annen gang. Under forklarer vi hvordan man g√•r frem for √• logge seg p√• de to ulike milj√∏ene p√• Dapla.\n\n\nFor √• logge seg inn inn i prod-milj√∏et p√• Dapla kan man gj√∏re f√∏lgende:\n\nG√• inn p√• lenken https://jupyter.dapla.ssb.no/ i en Chrome-nettleser eller klikk p√• lenken p√• Byr√•nettet som vist i Figur¬†1.\nAlle i SSB har en Google Cloud-konto som m√• brukes n√•r man logger seg p√• Dapla. Brukernavnet i Google er det samme som din korte epost-adresse (f.eks. cth@ssb.no). Hvis du ikke allerede er logget inn i Google vil du f√• sp√∏rsm√•l om √• velge hvilken Google-konto som skal brukes (Figur¬†3). Logg inn med din Google-konto (ssb.no) og ditt AD-passord.\n\n\n\n\nFigur¬†3: Velg en Google-konto\n\n\n\nDeretter blir man spurt om man godtar at ssb.no (alts√• Dapla) kan bruke din Google Cloud-konto (Figur¬†4). Trykk Allow.\n\n\n\n\nFigur¬†4: Tillat at ssb.no f√•r bruke din Google Cloud-konto\n\n\n\nDeretter lander man p√• en side som lar deg avgj√∏re hvor mye maskinkraft som skal holdes av til deg (Figur¬†5). Det √∏verste alternativet er valgt som standard, og er tilstrekkelig for de fleste.\n\n\n\n\nFigur¬†5: Velg hvor mye maskinkraft du trenger\n\n\n\nVent til maskinen din starter opp (Figur¬†6). Oppstartstiden kan variere.\n\n\n\n\nFigur¬†6: Starter opp Jupyter\n\n\nEtter dette er man logget inn i et Jupyter-milj√∏ som kj√∏rer p√• en minimal Ubuntu-maskin. Hvis man er del av et Dapla-team f√•r man ogs√• tilgang til alt teamet har tilgang til.\n\n\n\nInnlogging til staging-milj√∏et er identisk med innloggingen til prod-milj√∏et, med ett viktig unntak: nettadressen er n√• https://jupyter.dapla-staging.ssb.no/.\nLitt mer om hva som er tilgjenglig her kommer.\n\n\n\n\nJupyter-milj√∏et p√• bakken bruker samme base-image1 for √• installere Jupyterlab, og er derfor identisk p√• mange m√•ter. Men innloggingen er ganske forskjellig.\n\n\n\n\n\n\nMerk\n\n\n\nFom. 5. desember 2022 har vi byttet ut Jupyter-milj√∏et p√• bakken. Beskrivelsene under gjelder derfor det nye milj√∏et. Fram til 15. januar vil du kunne bruke det gamle milj√∏et ved √• g√• inn p√• lenken https://jupyter-prod.ssb.no/ manuelt i Google Chrome. Etter 15. januar blir det gamle Jupyter-milj√∏et avviklet.\n\n\n\n\nDu logger deg inn p√• prod i bakkemilj√∏et p√• f√∏lgende m√•te:\n\nLogg deg inn p√• Citrix-Windows i bakkemilj√∏et. Det kan gj√∏res ved √• bruke lenken Citrix p√• Byr√•nettet, som ogs√• vises i Figur¬†1.\nTrykk p√• Jupyterlab-ikonet, som vist p√• (jupyter-icon?), og logg deg inn med vanlig brukernavn og passord.\n\n\n\n\nJupyterlab-ikon p√• Skrivebordet i Citrix-Windows.\n\n\nN√•r du trykker p√• ikonet blir du tatt til nettadressen https://sl-jupyter-p.ssb.no/. Du kunne ogs√• √•pnet Jupyterlab ved √•pne Chrome-nettleseren og skrive inn adressen manuelt.\n\n\n\nInnlogging til staging-milj√∏et har ingen snarvei p√• Skrivebordet, og du m√• gj√∏re f√∏lgende for √• √•pne milj√∏et:\n\n√Öpne Chrome-nettleseren i Citrix-Windows.\nSkriv inn url-en https://sl-jupyter-t.ssb.no/"
  },
  {
    "objectID": "opprette-dapla-team.html",
    "href": "opprette-dapla-team.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Opprette Dapla-team\nFor √• komme i gang med √• opprette et Dapla-team trengs det en oversikt over teamets medlemmer og hvilke tilgangsgrupper medlemmene skal v√¶re med i. Det trengs ogs√• informasjon om hvilke Dapla-tjenester som er aktuelle for teamet √• ta i bruk. Derfor har det blitt opprettet en egen veileder for dette kalt Dapla Start.\n\n\n\n\n\n\nG√• til Dapla Start for starte bestilling av et nytt Dapla-team.\n\n\n\nN√•r teamet er opprettet f√•r alle medlemmene tilgang til sitt eget prosjekt i Google Cloud Platform (GCP), som er SSBs leverand√∏r av skytjenester. Videre f√•r hvert prosjekt et sett med tjenester og tilganger som knyttes til teamet. Det opprettes ogs√• datalagringsomr√•der (kalt b√∏tter) som bare kan aksesseres av brukere som er med i teamets tilgangsgrupper.\nDapla-teamet vil ogs√• f√• sin egen gruppe i SSBs Active Directory slik at medlemskapet i gruppen kan administreres av Kundeservice."
  },
  {
    "objectID": "arkitektur.html",
    "href": "arkitektur.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Arkitektur\nHvilke komponenter er plattformen bygd opp p√•? Forklart p√• lettest mulig m√•te."
  },
  {
    "objectID": "ordforklaringer.html",
    "href": "ordforklaringer.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Ordforklaringer\n\nbip\nbip er det tidligere navnet p√• den underliggende plattformen som SSB bygger i GCP, hovedsakelig ment for utviklere som bygger tjenester p√• Dapla. Plattformen skulle v√¶re selvbetjent for utviklere og basert p√• DevOps-prinsipper. bip eksisterer fortsatt, men er n√• blitt en del av det st√∏rre begrepet dapla.\n\n\nbucket\nbucket (eller b√∏tte p√• norsk) er en lagringsenhet p√• Dapla. Det ligner litt p√• en klassisk diskstasjon, for eksempel X-disken eller C-disken p√• en lokal maskin. I en b√∏tte kan det ligge undermapper slik som i et klassisk filsystem.\n\n\nconsumer\nconsumer er en AD-gruppe som gir tilgang til et Dapla-team sin delt-b√∏tte. En SSB-ansatt som skal bruke data fra et Dapla-team m√• v√¶re medlem av consumer-gruppen til det aktuelle Dapla-teamet.\n\n\ndapla\nDapla er et akronym for den nye dataplattformen til SSB, der Da st√•r for Data og pla st√•r for Plattform. Dapla er en plattform for lagring, prosessering og deling av SSB sine data. Den best√•r b√•de av Jupyter-milj√∏et, som er et verkt√∏y for √• utf√∏re beregninger og analysere data, og et eget omr√•de for lagre data. I tillegg inkluderer begrepet Dapla ogs√• en rekke andre verkt√∏y som er n√∏dvendige for √• kunne bruke plattformen.\n\n\ndapla-team\nKommer snart.\n\n\ndapla-toolbelt\nKommer snart.\n\n\ndata-admin\ndata-admin er en AD-gruppe som gir de videste tilgangene i et dapla-team. En SSB-ansatt som har data-admin-rollen i et Dapla-team har tilgang til alle b√∏tter for det teamet, inkludert kilde-b√∏tta som kan inneha sensitive data.\nKommer snart.\n\n\ndapla-start\n*dapla-start** er et brukergrensesnitt der SSB-ansatte kan s√∏ke om √• f√• opprettet et nytt dapla-team.\n\n\ndelt-b√∏tte\nKommer snart.\n\n\ndeveloper\nKommer snart.\n\n\ngoogle cloud platform (gcp)\nKommer snart.\n\n\ngcp\nForkortelse for Google Cloud Platform. Se forklaring under google cloud platform (GCP).\n\n\nkilde-b√∏tte\nKommer snart.\n\n\nprodukt-b√∏tte\nKommer snart.\n\n\nssb-project\nKommer snart.\n\n\ntransfer service\nKommer snart."
  },
  {
    "objectID": "jupyterlab.html",
    "href": "jupyterlab.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Mer kommer.\n\n\n\nM√• nevne operativsystemet og at noe programvare ligger installert her (git, jwsacruncher, quarto, ++)\n\n\n\nNoe er i base-image, noe b√∏r gj√∏res i virtuelle mil√∏er. Hvordan liste ut pakker som er pre-installert?\n\n\n\nJupyterlab er en samling extension. Kan bare installeres av admin. Sikkerhet. Hvilke extension har vi tilgjengeliggjort?\n\n\n\nSane defaults for Jupyterlab."
  },
  {
    "objectID": "vedlikehold.html",
    "href": "vedlikehold.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Vedlikehold\nKommer snart."
  },
  {
    "objectID": "samarbeid.html",
    "href": "samarbeid.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Samarbeid\nNoen har opprettet et ssb-project og pushet til Github. Hvordan skal kollegaer g√• frem for √• bidra inn i koden?"
  },
  {
    "objectID": "jupyter-kernel.html",
    "href": "jupyter-kernel.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Jupyter-kernels"
  }
]