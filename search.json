[
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Forord\nDenne boken tar sikte pÃ¥ Ã¥ gi SSB-ansatte mulighet til Ã¥ ta i bruk grunnleggende funksjonalitet pÃ¥ DAPLA uten hjelp fra eksperter. Boken er bygget opp som den reisen vi mener en statistikker skal gjennom nÃ¥r de flytter sin produksjon fra bakke til sky1. FÃ¸rste del inneholder en del grunnleggende kunnskap som vi mener er viktig Ã¥ ha fÃ¸r man skal starte Ã¥ jobbe i skyen. Andre del forklarer hvordan man sÃ¸ker om Ã¥ opprette et Dapla-team, en forutsetning for Ã¥ drive databehandling pÃ¥ plattformen. Det vil ofte vÃ¦re fÃ¸rste steget i ta i bruk plattformen, siden det er slik man fÃ¥r et sted Ã¥ lagre data. Her forklarer vi hvilke tjenester som inkluderes i et statistikkteam og hvordan man bruker og administerer dem. Den tredje delen tar utgangspunkt i at man skal starte Ã¥ kode opp sin statistikkproduksjon eller kjÃ¸re eksisterende kode. ssb-project er et verktÃ¸y som er utviklet i SSB for Ã¥ gjÃ¸re denne prosessen sÃ¥ enkel som mulig. Da kan brukerne implementere det som anses som god praksis i SSB med noen fÃ¥ tastetrykk, samtidig som vi ogsÃ¥ forklarer mer detaljert hva som skjer under panseret.\nDet er tilrettelagt for en treningsarena i bakkemiljÃ¸et. Dette miljÃ¸et er nesten identisk med det som mÃ¸ter deg pÃ¥ Dapla, med unntak av at du her har tilgang til mange av de gamle systemene og mye mindre hestekrefter i maskinene. Ideen er at SSB-ere ofte vil Ã¸nske Ã¥ lÃ¦re seg de nye verktÃ¸yene2 i kjente og kjÃ¦re omgivelser fÃ¸rst, og deretter flytte et ferdig skrevet produksjonslÃ¸p til Dapla. Del 4 av denne boken beskriver mer utfyllende hvordan dette miljÃ¸et skiller seg fra Dapla, og hvordan man gjÃ¸r en del vanlige operasjoner mot de gamle bakkesystemene.\nSiste delen av boken kaller vi Avansert og tar for seg ulike emner som mer avanserte brukere typisk trenger informasjon om. Her finner man blant annet informasjon om hvilke databaser man kan bruke og hvilke formÃ¥l de er egnet for. Her beskrives ogsÃ¥ hvordan man kan bruke andre IDE-er enn Jupyterlab hvis man Ã¸nsker det. Tjenester for schedulerte kjÃ¸ringer av Notebooks blir ogsÃ¥ diskutert.\nForhÃ¥pentligvis senker denne boken terskelen for Ã¥ ta i bruk Dapla. Kommentarer og Ã¸nsker vedrÃ¸rende boken tas imot med Ã¥pne armer.\nGod fornÃ¸yelseğŸ˜\n\n\n\n\n\nFotnoter\n\n\nI denne boken omtaler vi den gamle produksjonssonen, ofte kalt prodsonen, som bakke, og det nye skymiljÃ¸et Google Cloud som sky. Det er ikke helt presist men duger for formÃ¥lene i denne boken.â†©ï¸\nDet som omtales som nye verktÃ¸y er vil som regel bety R, Python, Git, GitHub og Jupyterlab.â†©ï¸"
  },
  {
    "objectID": "github-app-integrasjon.html",
    "href": "github-app-integrasjon.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Koble prosjektet til Github\nFor at automatiseringslÃ¸sningen pÃ¥ Dapla skal kunne settes opp automatisk mÃ¥ denne ha tilgang til Ã¥ lese fra prosjektets IAC-repo1. Dette avsnittet vil beskrive denne prosessen. Merk at dette er en engangsjobb som mÃ¥ gjÃ¸res av prosjektets kildedataansvarlige.\n\n\n\n\n\n\nViktig: Prosjektets kildedataansvarlige ogsÃ¥ mÃ¥ ha administrator-rettigheter til IAC-repoet i Github.\n\n\n\n\nLogg inn pÃ¥ Google Cloud Console og velg det prosjektet som skal konfigureres Ã¸verst venstre hjÃ¸rte. SÃ¸k opp Cloud Build i sÃ¸kefeltet og trykk pÃ¥ det valget som kommer opp.\nDet skal nÃ¥ vÃ¦re en venstremeny tilgjengelig med tittel Cloud Build. Trykk pÃ¥ menyvalget som heter Triggers (FigurÂ 1)\n\n\n\n\nFigurÂ 1: Bilde av venstremeny\n\n\n\nI nedtrekkslisten Region sÃ¸rg for at europe-north1 er valgt (FigurÂ 2)\n\n\n\n\nFigurÂ 2: Velg korrekt region\n\n\n\nTrykk deretter pÃ¥ en link som heter CONNECT REPOSITORY ca. midt pÃ¥ siden.\n\n\n\n\nFigurÂ 3: Oversikt over triggers\n\n\n\nNÃ¥ vil det dukke opp et vindu pÃ¥ hÃ¸yre side med overskrift Connect repository (FigurÂ 4). Velg GitHub (Cloud Build GitHub App) og trykk pÃ¥ CONTINUE\n\n\n\n\nFigurÂ 4: Vindu for Ã¥ velge Cloud Build Github App\n\n\n\nEt pop-up vindu tilsvarende FigurÂ 5 vil komme opp. Trykk pÃ¥ Authorize. Vinduet vil etter hvert lukke seg og man kommer videre til et steg som heter Select repository (FigurÂ 6)\n\n\n\n\nFigurÂ 5: Pop-up vindu for Github\n\n\n\n\n\nFigurÂ 6: Valg av Github repository\n\n\n\nTrykk pÃ¥ nedtrekkslisten Repository og skriv inn teamets navn. Huk av boksen ved teamets IAC-repo og trykk OK.\n\n\n\n\nFigurÂ 7: Gi Google Build tilgang til Github repository\n\n\n\nKryss sÃ¥ av i sjekkboksen som i (FigurÂ 8) og trykk CONNECT.\n\n\n\n\nFigurÂ 8: Bekreft nytt Github repository\n\n\n\nTil slutt vil skjermbildet se ut som vist i FigurÂ 9. Det siste steget Create a trigger kan du hoppe over. Dette vil bli satt opp av automatiseringslÃ¸sningen senere. Trykk pÃ¥ knappen DONE\n\n\n\n\nFigurÂ 9: Siste steg - Create a trigger\n\n\n\n\n\n\n\nFotnoter\n\n\nIAC-repo er et en kodebase i Github pÃ¥ formen https://github.com/statisticsnorway/team-navn-iac.â†©ï¸"
  },
  {
    "objectID": "samarbeid.html",
    "href": "samarbeid.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Samarbeid\nNoen har opprettet et ssb-project og pushet til Github. Hvordan skal kollegaer gÃ¥ frem for Ã¥ bidra inn i koden?"
  },
  {
    "objectID": "overfÃ¸re-data.html",
    "href": "overfÃ¸re-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "For Ã¥ overfÃ¸re data mellom bakke og sky brukes Data Transfer, som er en tjeneste i Google Cloud Console. Denne tjenesten kan brukes til Ã¥ flytte data bÃ¥de til og fra Linuxstammen og Dapla, og er tilgjengelig for teamets kildedataansvarlige.\nFor Ã¥ fÃ¥ tilgang til Ã¥ overfÃ¸re filer mÃ¥ man be om dette ved opprettelsen av teamet. Ber man om det skjer fÃ¸lgende:\n\nEn mappe blir opprettet pÃ¥ Linux i prodsonen under /ssb/cloud_sync/\nEt Google Project blir opprettet med navn <team navn>-ts.\n\nDette Google-prosjektet er ikke det samme som der du lagrer annen data. Det har navnet <team navn>-ts, og filstiene pÃ¥ bakken og sky vises i FigurÂ 1.\n\n\n\nFigurÂ 1: Hvordan Transfer Service kan flytte filer mellom bakke og sky.\n\n\nTeamets kildedataansvarlige vil vÃ¦re spesifisert som en del av Ã¥ opprette et Dapla-team.\n\n\nEnten man skal overfÃ¸re filer opp til sky eller ned til bakken sÃ¥ bruker man den samme Data Transfer tjenesten. For Ã¥ fÃ¥ tilgang til denne mÃ¥ man fÃ¸rst logge seg inn i Google Cloud Console. Sjekk at du er logget inn med din SSB-konto (xxx@ssb.no).\nÃ˜verst pÃ¥ siden, til hÃ¸yre for teksten Google Cloud finnes det en prosjektvelger, og her er det viktig Ã¥ velge korrekt Google prosjekt. Hvis du trykker pÃ¥ prosjektvelgeren vil det Ã¥pnes opp et nytt vindu. Sjekk at det stÃ¥r SSB.NO Ã¸verst i dette vinduet. Trykk deretter pÃ¥ fanen ALL for Ã¥ fÃ¥ opp alle tilgjengelige Google-prosjekter under organisasjonen ssb.no (FigurÂ 2)\n\n\n\nFigurÂ 2: Prosjektvelgeren i Google Cloud Console\n\n\nUnder ssb.no vil det ligge flere mapper. Ã…pne mappen som heter production og let frem en undermappe som har navnet pÃ¥ ditt Dapla-team. Strukturen skal se slik ut:\n    ssb.no\n    â”œâ”€â”€ production\n        â””â”€â”€ <teamnavn>\n            â”œâ”€â”€ prod-<teamnavn>\n            â””â”€â”€ <teamnavn>-ts\nDet underste nivÃ¥et (prod-<teamnavn> og <teamnavn>-ts) viser prosjektene, nivÃ¥et i mellom er mapper, og toppnivÃ¥et er organisasjonen (ssb.no). Prosjektet <teamnavn>-ts er et separat prosjekt som bare teamets kildedataansvarlige har tilgang til, og det er her tjenesten Data Transfer skal settes opp.\n\nVelg derfor prosjektet <teamnavn>-ts.\nI sÃ¸kefeltet til Google Cloud Console, skriv Data transfer og trykk pÃ¥ det valget som kommer opp.\nFÃ¸rste gang man kommer inn pÃ¥ siden til Transfer Services vil man bli vist en blÃ¥ knapp med teksten Set Up Connection. NÃ¥r du trykker pÃ¥ denne vil det dukke opp et nytt felt hvor du fÃ¥r valget Create Pub-Sub Resources. Dette er noe som bare trengs Ã¥ gjÃ¸re Ã©n gang. Trykk pÃ¥ den blÃ¥ CREATE knappen, og deretter trykk pÃ¥ Close lenger nede.\nI navigasjonsmenyen til venstre trykk Transfer jobs, og deretter trykk pÃ¥ + Create transfer job Ã¸verst pÃ¥ siden for Ã¥ opprette en ny overfÃ¸ringsjobb.\n\n\n\nFÃ¸lgende oppskrift tar utgangspunkt i siden Create a transfer job (FigurÂ 3):\n\n\n\nFigurÂ 3: Opprett overfÃ¸ringsjobb i Google Cloud Console\n\n\n\nVelg POSIX filesystem under â€œSource typeâ€ og Google cloud storage under â€œDestination typeâ€ (eller motsatt hvis overfÃ¸ringsjobben skal gÃ¥ fra Dapla til Linuxstammen). Trykk Next step\nNedtrekkslisten â€œAgent poolâ€ skal normalt bare ha ett valg: transfer_service_default. Velg denne.\nI feltet â€œSource directory pathâ€ skal man kun skrive data/tilsky siden overfÃ¸ringsagenten kun har tilgang til mapper som ligger relativt plassert under /ssb/cloud_sync/<teamnavn>/. Trykk Next step\nVelg en destinasjon for overfÃ¸ringsjobben. Trykk pÃ¥ Browse og velg bÃ¸tten med navn som passer til ssb-prod-<teamnavn>-data-synk-opp. Vi anbefaler at du ogsÃ¥ oppretter en mappe inne i denne bÃ¸tten. Det gjÃ¸res ved Ã¥ trykke pÃ¥ mappeikonet med et +-tegn foran. Skriv inn et passende mappenavn og trykk Select i bunnen av siden. Trykk deretter Next step\nNeste steg â€œChoose how and when to run this jobâ€ er opp til brukeren Ã¥ bestemme. Hvis man f.eks. velger at Data Transfer skal overfÃ¸re data en gang i uken, vil den kun starte en overfÃ¸ring hvis det finnes nye data. Trykk Next step\nBeskriv overfÃ¸ringsjobben, f.eks: â€œFlytter data for  til sky.â€. Resten av feltene er opp til brukeren Ã¥ bestemme. Standardverdiene er OK.\n\nTrykk til slutt pÃ¥ den blÃ¥ Create-knappen. Du vil kunne se kjÃ¸rende jobber under menyen Transfer jobs.\nFor Ã¥ sjekke om data har blitt overfÃ¸rt, skriv inn cloud storage i sÃ¸kefeltet Ã¸verst pÃ¥ siden og trykk pÃ¥ det fÃ¸rste valget som kommer opp. Her vil du finne en oversikt over alle teamets bÃ¸tter, deriblant en med navn ssb-prod-<team-name>-data-synk-opp. NÃ¥r overfÃ¸ringsjobben er ferdig vil du kunne finne igjen dataene i den mappen som ble definert i stegene overnfor.\n\n\n\nOverfÃ¸ringsjobben settes opp nesten identisk med OverfÃ¸ring fra Linuxstammen til Dapla med unntak av fÃ¸lgende:\n\nSteg 1: Velg Google cloud storage under â€œSource typeâ€ og POSIX filesystem under â€œDestination typeâ€\nSteg 2: Velg bÃ¸tten ssb-prod-<team-name>-data-synk-ned\nStep 3: Velg transfer_service_default som â€œAgent poolâ€ og skriv data/frasky inn i feltet for â€œDestination directory pathâ€.\n\nFor Ã¥ se om data har blitt overfÃ¸rt til Linuxstammen mÃ¥ du nÃ¥ gÃ¥ til mappen /ssb/cloud_sync/<team-name>/data/frasky fra FileZilla.\nHusk: Du kan alltids gÃ¥ tilbake og se pÃ¥ tidligere fullfÃ¸rte jobber, og starte en overfÃ¸ringsjobb manuelt fra menyen Transfer jobs.\n\n\n\n\nNÃ¥r du har satt opp en, enten for Ã¥ overfÃ¸re fra sky eller til sky, kan du skrive ut data til mappen eller bÃ¸tten som du har bedt Transfer Service om Ã¥ overfÃ¸re data fra.\nHvis du skal overfÃ¸re data fra bakken/prodsonen til sky, sÃ¥ mÃ¥ teamets kildedataansvarlige skrive ut data til Linux-mappen /ssb/cloud_sync/<team navn>/data/tilsky, og det vil ende opp i Dapla-bÃ¸tta gs://ssb-prod-<team navn>-data-synk-opp Dette kan du gjÃ¸re med alle programmeringsverktÃ¸y som har en kobling til Linux-stammene der dataene ligger. For eksempel:\n\nSAS EG\nSAS-installasjon pÃ¥ Linux\nJupyterlab i prodsonen\nRstudio pÃ¥ sl-stata-03\n\nSkal du flytte data fra Dapla til bakken/prodsonen, sÃ¥ mÃ¥ teamets kildedataansvarlige skrive ut data til gs://ssb-prod-<team navn>-data-synk-opp-bÃ¸tta pÃ¥ Dapla. Det er noe man typisk gjÃ¸r fra Jupyterlab pÃ¥ Dapla."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Data\nKommer snart."
  },
  {
    "objectID": "hva-er-dapla-team.html",
    "href": "hva-er-dapla-team.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "For Ã¥ kunne jobbe med skarpe/ekte data pÃ¥ Dapla mÃ¥ man opprette et et Dapla-team. Et dapla-team er en gruppe personer som jobber med ett eller flere emneomrÃ¥der pÃ¥ SSBs dataplattform/Dapla. NÃ¥r man oppretter et Dapla-team i SSB fÃ¥r man fÃ¸lgende:\n\nLagringsomrÃ¥de for data i Google Cloud Storage (GCS)1\nTilgangskontroll til lagringsomrÃ¥det\nTjeneste for synkronisering av data mellom bakke og sky (Transfer Service)\n\nEt Dapla-team er ikke bare et sett med Google-tjenester knyttet til en gruppe ansatte. Det er ogsÃ¥ knyttet arbeidsprosesser og rutiner til et Dapla-team som er bestemt av SSB selv. I det fÃ¸lgende forklarer vi begge deler.\n\n\nNÃ¥r man oppretter et Dapla-team sÃ¥ fÃ¥r man tilgang til et sett med ferdig konfigurerte ressurser og tjenester i GCP. For Ã¥ fÃ¥ en god forstÃ¥else for hvordan disse ressursene og tjenestene fungerer sammen med andre Dapla-team, er det viktig Ã¥ skjÃ¸nne hvordan den felles stukturen pÃ¥ GCP er bygd opp.\nAnta at noen oppretter et Dapla-team som heter Arbmark skjema. De vil da fÃ¥ tildelt et teknisk navn som er arbmark-skjema. Sistnevnte navn vil bli brukt i alle ressursene som blir opprettet for teamet.\nSSB har sin egen organisasjon pÃ¥ GCP. Derfor heter toppnivÃ¥et ssb. Under SSB ligger det 3 Folders2: development, production og staging, som vist i FigurÂ 1.\nUnder hver Folder ligger det ett eller to Google-prosjekter. Det som brukes til statistikkproduksjon ligger under production, mens det som brukes til utvikling og testing ligger under henholdsvis development og staging. I det fÃ¸lgende vil vi kun fokusere pÃ¥ production, som er det som brukes til statistikkproduksjon.\n\nFoldersProjectsBuckets\n\n\n\n\n\nFigurÂ 1: Folders under SSB sin organisasjon pÃ¥ GCP\n\n\n\n\n\n\n\nFigurÂ 2: Prosjektene som opprettes i et Dapla-team.\n\n\n\n\n\n\n\nFigurÂ 3: BÃ¸ttene som opprettes i et Dapla-team.\n\n\n\n\n\nI FigurÂ 2 ser vi hvilke prosjekter som blir opprettet for Dapla-teamet arbmark-skjema. Under production ligger prosjektene arbmark-skjema-ts og prod-arbmark-skjema. Det fÃ¸rste prosjektet brukes til Ã¥ synkronisere data mellom bakke og sky. prod-arbmark-skjema er det som brukes til i Ã¥ lagre data i en statistikkproduksjon.\nI FigurÂ 3 ser vi hvordan lagringsbÃ¸ttene plasserer seg under prosjektene. I neste kapittel forklarer vi hva de ulike lagringsbÃ¸ttene skal brukes til.\n\n\n\n\n\n\nHva er en bÃ¸tte?\n\n\n\nVi kommer til Ã¥ bruke ordet bÃ¸tte mye i denne delen, og det er derfor ryddig Ã¥ forklare hva det er.\nEn bÃ¸tte er et lagringsomrÃ¥de for data i GCP. En bÃ¸tte inneholder objekter av data og metadata som kan organiseres pÃ¥ en slik mÃ¥te at det likner pÃ¥ filer organisert i mapper og undermapper. Objektene i bÃ¸tter er lagret â€œdistribuertâ€, det vil si at de ligger lagret pÃ¥ ulike maskiner ute i â€œskyenâ€, og kan nÃ¥s via en tjeneste i GCP som heter Cloud Storage (GCS). BÃ¸tter er noe annet enn mapper, og har derfor fÃ¥tt et eget ord pÃ¥ engelsk (buckets).\nHvis vi skulle sammenlignet det med vÃ¥re systemer pÃ¥ bakken vil det ligne mye pÃ¥ en diskstasjon, for eksempel X- og S-disken.\n\n\n\n\nLagringsomrÃ¥dene for Dapla-team bestÃ¥r av Google Cloud Storage (GCS) buckets. Disse bÃ¸ttene fÃ¸lger en navnestandard som henger sammen med SSBs datatilstander og tilgangsroller. I det fÃ¸lgende forklarer vi hvordan de ulike bÃ¸ttene er tenkt strukturert.\n\n\nUnder prosjektet prod-arbmark-skjema ligger det 3 bÃ¸tter som er tilgjengelig for alle i Dapla-teamet. Disse bÃ¸ttene er:\n\nssb-prod-arbmark-skjema-data-delt\nLagring av data som skal deles med andre i SSB. Kan innholde inndata, klargjorte data, statistikkdata og utdata.\nssb-prod-arbmark-skjema-data-kilde\nLangtidslagring av kildedata (se definisjon). Kan kun inneholde kildedata.\nssb-prod-arbmark-skjema-data-produkt\nLagring av data i statistikkproduksjon. Kan innholde inndata, klargjorte data, statistikkdata og utdata.\n\nDisse lagringsomrÃ¥dene er nÃ¦rt knyttet til de ulike datatilstandene som blir beskrevet senere.\n\n\n\nUnder prosjektet arbmark-skjema-ts ligger det 2 bÃ¸tter som kun er tilgjengelig for kildedata-ansvarlig (data-admins) i Dapla-teamet. Disse bÃ¸ttene er:\n\nssb-arbmark-skjema-ts-data-synk-opp\nHer ligger data som er blitt synkronisert opp fra bakke til sky.\nssb-arbmark-skjema-ts-data-synk-ned\nHer ligger data som skal synkroniseres ned fra sky til bakke.\n/ssb/cloud_sync/arbmark-skjema/\nLagringsomrÃ¥det pÃ¥ bakken for synkronisering av data mellom bakke og sky.\n\nKun kildedata-ansvarlig har lese- og skrivetilgang til disse bÃ¸ttene. Det er ogsÃ¥ kildedata-ansvarlig som kan sette opp jobber med Transfer Service for Ã¥ synkronisere data mellom bakke og sky.\n\n\n\n\nVed opprettelsen av et Dapla-team sÃ¥ blir du bedt om Ã¥ plassere medlemmene i teamet i en av tre ulike tilgangsroller. Disse er:\n\ndata-admins\nHar lese- og skrivetilgang i alle lagringsomrÃ¥dene i Dapla-teamet. Siden dette er en priveligert rolle med potensiell tilgang til sensitiv data, sÃ¥ er det kun noen fÃ¥ personer som skal ha denne rollen i et Dapla-team.\ndevelopers\nHar lese- og skrivetilgang i alle lagringsomrÃ¥dene i Dapla-teamet, med unntak av ssb-prod-arbmark-skjema-data-kilde, og bÃ¸ttene i prosjektet arbmark-skjema-ts. Dvs. at alle som jobber med statistikkproduksjon tilknyttet teamets data, og som ikke er data-admin, skal ha denne rollen.\nconsumers\nMedlemmer fra andre Dapla-team som har behov for tilgang til dette teamets data. De fÃ¥r lesetilgang til ssb-prod-arbmark-skjema-data-delt.\n\ndata-admin har i tillegg til lagringsomrÃ¥dene pÃ¥ sky, tilgang til denne mappen pÃ¥ bakken: /ssb/cloud_sync/arbmark-skjema. Her kan de legge filer som de Ã¸nsker Ã¥ flytte til skyen.\nTabellÂ 1 viser hvilke roller som har tilgang til hvilke bÃ¸tter/mapper.\n\n\nTabellÂ 1: Tilgangsroller og lagringsomrÃ¥der\n\n\n\n\n\n\n\n\n\ndata-admin\ndeveloper\nconsumer\n\n\n\n\narbmark-skjema-kilde\nX\n\n\n\n\narbmark-skjema-produkt\nX\nX\n\n\n\narbmark-skjema-delt\nX\nX\nX\n\n\narbmark-skjema-synk-opp\nX\n\n\n\n\narbmark-skjema-synk-ned\nX\n\n\n\n\n/ssb/cloud_sync/arbmark_skjema/\nX\n\n\n\n\n\n\n\n\n\nTeam Statistikktjenester jobber med en tjeneste for Ã¥ automatisere overgangen fra kildedata til inndata. Denne tjenesten vil bli tilgjengelig for alle Dapla-team.\n\n\n\n\nI tillegg til man fÃ¥r tilgang til spesifikke GCP-tjenester ved opprettelse av et Dapla-team, sÃ¥ er det ogsÃ¥ lagt opp til noen spesifikke arbeidsprosesser rundt bÃ¸tter og tilgangsroller. I denne delen forklarer vi hvordan dette forholder seg GCP-tjenestene vi beskrev i forrige del.\n\n\nEt viktig konsept pÃ¥ Dapla er datatilstander. Disse er definert i definert i vÃ¥rt interne dokument Datatilstander av Standardutvalget (2021). I dokumentet presiseres det at tilstandene kildedata, klargjorte data og statistikkdata er obligatoriske for statistikkprodusenter pÃ¥ Dapla.\nI tillegg har DirektÃ¸rmÃ¸tet (2022) konkretisert hvordan klassifisering og tilgangskontroll skal utfÃ¸res pÃ¥ DAPLA. Under beskriver vi hvordan de to dokumentene pÃ¥virker et Dapla-team.\n\n\n\nKildedata er data som er produsert av andre enn SSB. Det kan vÃ¦re data fra andre statlige etater, eller fra private aktÃ¸rer. Kildedata er ofte i form av en fil, eller en mappe med filer. Kildedata skal lagres i bÃ¸tten kilde i GCS.\nKildedata skal lagres i den formen den kom til SSB i kildebÃ¸tta. Det vil ofte forekomme at disse dataene er sensitive og at de kan inneholde informasjon som ikke skal brukes videre i statistikkproduksjon. Derfor er det kun data-admin som skal ha tilgang til denne bÃ¸tten. Og det bÃ¸r vÃ¦re sÃ¥ fÃ¥ som mulig pÃ¥ teamet som har rollen data-admin, spesielt hvis det er sensitive data.\ndata-admin har ansvaret for Ã¥ sÃ¸rge for at kildedata behandles pÃ¥ en mÃ¥te som gjÃ¸r at den tilgjengeliggjÃ¸res for resten av teamet. Typisk vil dette innebÃ¦re3:\n\npseudonymisering\ndataminimering\nkvalitetssikring\nkonvertering til et felles format\n\nDet er ikke tenkt at data-admin skal mÃ¥tte kjÃ¸re dette manuelt, men at det skal vÃ¦re en del av en automatisk prosess som kjÃ¸res hver gang en ny fil kommer inn i kildebÃ¸tta. Det er kun ved mistanke om feil i datafangsten, som gir tjenestlige behov for data-admins til Ã¥ se data i klartekst, at data-admins bruker tilgangen sin til Ã¥ se pÃ¥ data i kildebÃ¸tta.\n\n\n\nNÃ¥r kildedata har blitt transformert og beveget seg over i en av de andre datatilstandene, vil det ligge i produkt-bÃ¸tta og vÃ¦re tilgjengelig for alle med developers-tilgangen.\nI produktbÃ¸tta skal det lagres tre typer data:\n\nInndata\nKlargjorte data\nStatistikkdata\nUtdata\n\nLes mer om det her.\n\n\n\nNÃ¥r andre Dapla-team skal ha tilgang til data fra ditt team, mÃ¥ de sÃ¸ke om Ã¥ fÃ¥ tilgangsrollen consumer i ditt team. Du mÃ¥ dermed tilgjengeliggjÃ¸re dataene som skal deles i din delt-bÃ¸tte.\nMer kommer."
  },
  {
    "objectID": "slette-data.html",
    "href": "slette-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Slette data fra bÃ¸tter\nSletting av filer og mapper fra bÃ¸tter kan gjÃ¸res fra Google Cloud Console. SÃ¸k opp â€œCloud Storageâ€ i sÃ¸kefeltet og klikk pÃ¥ den bÃ¸tten hvor filen er lagret under â€œBucketsâ€.\nKryss av filen/katalogen som du Ã¸nsker Ã¥ slette og trykk â€œDeleteâ€ (FigurÂ 1)\n\n\n\nFigurÂ 1: Sletting av en fil\n\n\nSiden bÃ¸tter pÃ¥ Dapla har versjonering fÃ¥r man opp en dialogboks som informerer om at objektet (dvs. filen) er versjonert (FigurÂ 2). Trykk pÃ¥ â€œDeleteâ€.\n\n\n\nFigurÂ 2: Bekreft sletting av fil\n\n\nSlettingen kan ta noe tid. NÃ¥r denne er ferdig vil filen vÃ¦re slettet, men den kan fortsatt gjenopprettes. Hvis du Ã¸nsker at filen skal slettes permanent, gjÃ¸r fÃ¸lgende:\n\nSkru pÃ¥ visning av slettede filer med Ã¥ bruke radioknappen â€œShow deleted dataâ€ (FigurÂ 3)\n\n\n\n\nFigurÂ 3: Skru pÃ¥ visning av slettede filer\n\n\n\nFinn frem til den slettede filen og trykk pÃ¥ linken â€œ1 noncurrent versionâ€ eller tilsvarende (FigurÂ 4). Dette vil ta deg direkte til en side som viser filens versjonshistorikk.\n\n\n\n\nFigurÂ 4: Velg versjonshistorikk\n\n\n\nVelg alle versjoner som vist pÃ¥ FigurÂ 5 og trykk â€œDeleteâ€\n\n\n\n\nFigurÂ 5: Slett alle versioner\n\n\n\nTil slutt mÃ¥ man bekrefte at man Ã¸nsker Ã¥ slette alle versioner (FigurÂ 6) med Ã¥ skrive inn DELETE og trykke pÃ¥ den blÃ¥ â€œDeleteâ€-knappen:\n\n\n\n\nFigurÂ 6: Bekreft sletting av alle versjoner"
  },
  {
    "objectID": "gcc-avansert.html",
    "href": "gcc-avansert.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Ã˜verst pÃ¥ siden, til hÃ¸yre for teksten Google Cloud finnes det en prosjektvelger. Her er det viktig Ã¥ velge ditt teams Google prosjekt, ettersom teamets ressurser kun er tilgjengelige innenfor prosjektet. Hvis du trykker pÃ¥ prosjektvelgeren vil det Ã¥pnes opp et nytt vindu. Sjekk at det stÃ¥r SSB.NO Ã¸verst i dette vinduet.(FigurÂ 1).\n\n\n\nFigurÂ 1: Prosjektvelgeren i Google Cloud Console\n\n\n\n\nHer vises det hvordan man velger et prosjekt I GCC. Eksempelet benytter Dapla teamet demo stat b og fortsetter fra (FigurÂ 1).\n\nSkrive teamnavn i sÃ¸kefeltet, resultatene burde se ut som i (FigurÂ 2).\nTrykk pÃ¥ lenken prod-demo-stat-b, som markert med rÃ¸d pil i (FigurÂ 2).\n\n\n\n\n\n\n\nI ID kolonnen ser man prosjektet ID (FigurÂ 2).\n\n\n\n\n\n\nFigurÂ 2: SÃ¸k i Prosjektvelgeren\n\n\nHar man gjort alle stegene rett vil det i venstre hjÃ¸rne se ut som i (FigurÂ 3).\n\n\n\nFigurÂ 3: Aktivt prosjekt i GCC"
  },
  {
    "objectID": "kildedata-prosessering-avansert.html",
    "href": "kildedata-prosessering-avansert.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "FigurÂ 1: Infrastruktur\n\n\n\n\n\nSom utgangspunkt, fÃ¥r hver prosesseringsinstans standard ressurstildeling for Cloud Run, dvs. 1 CPU kjerne og 512MB minne. Dette kan vÃ¦re for lite i noen tilfeller, sÃ¦rlig for stÃ¸rre kildedatafiler. Hvis det oppleves at mer minne kreves, ta gjerne kontakt med Dapla Kundeservice for Ã¥ ordne dette.\n\n\n\nEn liste over Python pakker man kan benytte seg av i process_source_data.py finnes her. Ta gjerne kontakt med Dapla Kundeservice hvis man har behov for ytterligere.\n\n\n\nHver kilde kan skalere opp med parallele prosesseringsinstanser. Det gjÃ¸r det kjappere Ã¥ prosessere mange filer. I utgangspunktet er dette begrenset til 5 parallele instanser, men det kan Ã¸kes ved behov.\n\n\n\nFor Ã¥ gi raskt tilbakemelding pÃ¥ noen mulige feilsituasjoner, sÃ¥ kjÃ¸res det enkel validering pÃ¥ kilde config og process_source_data.py nÃ¥r en PR er opprettet.\nHvis valideringen feiler, sÃ¥ mÃ¥ feilen rettes fÃ¸r PRen merges.\nTestene feiler hvis:\n\nKildemappen ikke har et python script kalt process_source_data.py med metodesignaturen, som beskrevet her.\nKildemappen ikke har en yaml fil og en gyldig folder_prefix definert, som i dette eksempelet.\nPython scriptet ikke kan importeres av tjenesten. Tjenesten stÃ¸tter kun disse tredjeparts pakkene.\nHvis Pyflakes finner feil med kildens Python script.\n\n\n\nHvis validerings testene feiler kan det vÃ¦re nyttig Ã¥ se pÃ¥ loggene for Ã¥ finne frem til feilen.\n\nFinn frem til testen som feiler, i bildet feiler valideringstestene for kilde1. Trykk sÃ¥ pÃ¥ lenken â€œDetailsâ€ som vist i bilde under. \nPÃ¥ siden du nÃ¥ har kommet til skal det vÃ¦re en tabell som heter â€œBuild Informationâ€, trykk pÃ¥ lenken i Build kolonnen. \nDu har nÃ¥ kommet frem til loggene, se etter indikasjoner pÃ¥ feil. I eksemplet under ser vi at testen test_main_accepts_expected_number_of_args feiler fordi process_source_data.py mangler en main funksjon. \nFiks feilen og push endingen til samme branch, testen vil da starte pÃ¥ nytt.\n\n\n\n\n\nEndringer til process_source_data.py blir automatisk rullet ut nÃ¥r en PR er merget til main branchen. Utrullingsprosessen tar noe tid, ca. 2-3 minutter fra branchen er merget til tjenesten er oppdatert, for Ã¥ bekrefte at tjenesten er rullet ut kan du fÃ¸lge stegene i neste avsnitt.\n\n\nStegene under viser hvordan man gÃ¥r frem for Ã¥ finne resultat av utrullingen av kilden â€œledstillâ€ for teamet â€œarbmark-skjemaâ€. Og forutsetter at koden er pushet til main branchen.\n\nNaviger til GitHub.\nI sÃ¸kefeltet oppe i venstre hjÃ¸rne skriv arbmark-skjema og klikk â€œJump toâ€ arbmark-skjema-iac. Som i bilde under. \nNÃ¥r utrullingen er ferdig vil en av disse ikonene vises, grÃ¸nn hake betyr at tjeneste er rullet ut med koden som ligger i main og at nye filer blir behandlet med koden som ligger der. . RÃ¸dt kryss indikerer at utrullig har feilet.  Se etter symbolene der hvor den rÃ¸de pilen i bilde under peker. I eksempel er utrulligen vellykket. \n\n\n\n\n\nMan fÃ¥r en oversikt over kildene man har konfigurert prosessering for og statusen pÃ¥ dem ved hjelp av konsollet pÃ¥ GCP. Der navigerer man til siden for Cloud Run (se FigurÂ 2) som er kjÃ¸remiljÃ¸et som kildedata prosessering benyttes av. Eksempel URl er: https://console.cloud.google.com/run?project=<teamets-prosjekt-id>\nHer fÃ¥r man en oversikt av ressursbruk og loggene til prosesseringen.\n\n\n\nFigurÂ 2: Cloud Run dashboard\n\n\n\n\nEtter du har valgt kilden kan du se logger ved Ã¥ velge fanen â€œLOGSâ€. Her ligger alle logger for den spesifikke kilden. For Ã¥ fÃ¥ bedre oversikt over eventulle feil kan man sette severity til error. Dette vil uten ekstra konfigurasjon gi oversikt over alle uhÃ¥ndterte exceptions. \n\n\n\nHvis en fil blir mottatt av tjenesten, men ikke lar seg behandle blir det skrevet til loggen. Man kan fÃ¥ en oversik over hvilke filer som ikke har blitt prosessert ved Ã¥ sÃ¸ke etter: Could not process object. \n\n\n\n\nNoen ganger vil det vÃ¦re nÃ¸dvendig Ã¥ trigge kjÃ¸ring av en kilde uten at de tilhÃ¸rende filene i kildebÃ¸tta er oppdatert f.eks. etter en endring i prosseseringsskriptet. For Ã¥ gjÃ¸re dette kan man benytte seg av dapla toolbelt.\nFor Ã¥ trigge en ny kjÃ¸ring mÃ¥ man vÃ¦re data-admin i teamet og ha denne informasjonen tilgjengelig:\n\nproject_id(prosjekt id) for kilden, den finner man ved Ã¥ fÃ¸lge beskrivelsen her.\nfolder_prefix beskriver stien til filene som skal behandles og fungerer pÃ¥ samme mÃ¥te som i config.yaml\nsource_name finner man ved Ã¥ se pÃ¥ navnet til mappen hvor kilden konfigureres, i eksempelet her ser vi at team smaabakst har to kilder boller og rundstykker.\n\n\n\nDette eksemplet viser hvordan man gÃ¥r frem for Ã¥ manuelt trigge kilden boller for team smaabakst.\nTeam smaabakst Ã¸nsker Ã¥ re-prosessere alle filer i kilden boller. Ved Ã¥ bruke samme folder_prefix som i config.yaml vil alle filer som tilhÃ¸rer kilden bli prosessert pÃ¥ nytt.\nfrom dapla import trigger_source_data_processing\n\nproject_id = \"prod-smaabakst-b69d\"\nsource_name = \"boller\"\nfolder_prefix = \"boller\"\n\ntrigger_source_data_processing(project_id, source_name, folder_prefix)"
  },
  {
    "objectID": "schedulering.html",
    "href": "schedulering.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Schedulering"
  },
  {
    "objectID": "git-github.html",
    "href": "git-github.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "I SSB anbefales det man versjonhÃ¥ndterer koden sin med Git og deler koden via GitHub. For Ã¥ lÃ¦re seg Ã¥ bruke disse verktÃ¸yene pÃ¥ en god mÃ¥te er det derfor viktig Ã¥ forstÃ¥ forskjellen mellom Git og Github. Helt overordnet er forskjellen fÃ¸lgende:\n\nGit er programvare som er installert pÃ¥ maskinen du jobber pÃ¥ og som sporer endringer i koden din.\nGitHub er et slags felles mappesystem pÃ¥ internett som lar deg dele og samarbeide med andre om kode.\n\nAv definisjonene over sÃ¥ skjÃ¸nner vi at det er Git som gir oss all funksjonalitet for Ã¥ lagre versjoner av koden vÃ¥r. GitHub er mer som et valg av mappesystem. Men mÃ¥ten kodemiljÃ¸ene vÃ¥re er satt opp pÃ¥ Dapla sÃ¥ har vi ingen fellesmappe som alle kan kjÃ¸re koden fra. Man utvikler kode i sin egen hjemmemappe, som bare du har tilgang til, og nÃ¥r du skal samarbeide med andre, sÃ¥ mÃ¥ du sende koden til GitHub. De du samarbeider med mÃ¥ deretter hente ned denne koden fÃ¸r de kan kjÃ¸re den.\nI dette kapittelet ser vi nÃ¦rmere pÃ¥ Git og Github og hvordan de er implementert i SSB. Selv om SSB har laget programmet ssb-project for Ã¥ gjÃ¸re det lettere Ã¥ bl.a. forholde seg til Git og GitHub, sÃ¥ vil vi dette kapittelet forklare nÃ¦rmere hvordan det funker uten dette hjelpemiddelet. ForhÃ¥pentligvis vil det gjÃ¸re det lettere Ã¥ hÃ¥ndtere mer kompliserte situasjoner som oppstÃ¥r i arbeidshverdagen som statistikker.\n\n\nGit er terminalprogram som installert pÃ¥ maskinen du jobber. Hvis man ikke liker Ã¥ bruke terminalen finnes det mange pek-og-klikk versjoner av Git, blant annet i Jupyterlab, SAS EG og RStudio. Men typisk vil det en eller annen gang oppstÃ¥ situasjoner der det ikke finnes lÃ¸sninger i pek-og-klikk versjonen, og man mÃ¥ ordne opp i terminalen. Av den grunn velger vi her Ã¥ fokusere pÃ¥ hvordan Git fungerer fra terminalen. Vi vil ogsÃ¥ fokusere pÃ¥ hvordan Git fungerer fra terminalen i Jupyterlab pÃ¥ Dapla.\n\n\nKommer snart. Kort forklaring med lenke til mer utfyllende svar.\n\n\n\nMer kommer.\n\n\nFor Ã¥ brukt Git er det strengt tatt to ting som mÃ¥ konfigurere:\n\nBrukernavn\nE-post\n\nDenne informasjonen brukes av Git hver gang du sjekker inn en endring i koden slik at man kan vite hvem som gjorde endringen senere. Dette mÃ¥ settes Ã©n gang per miljÃ¸ hvor du skal jobbe med Git. Hvis du f.eks. jobber i Jupyterlab pÃ¥ Dapla sÃ¥ kan du Ã¥pne en terminal og skrive fÃ¸lgende for Ã¥ lagre ditt brukernavn:\ngit config --global user.name \"Ola Nordmann\"\nFor Ã¥ sette e-post gjÃ¸r du veldig lignende:\ngit config --global user.email olanordamnn@ssb.no\nNÃ¥r du har kjÃ¸rt disse to kommandoene sÃ¥ kan du bruke Git. Informasjonen du la til over brukes ikke til noe annet enn Ã¥ fortelle de du samarbeider med om at du har gjort endringer pÃ¥ koden. Den er verken knyttet opp mot din SSB-bruker eller din GitHub-bruker.\n\n\n\n\nKommer snart. Jupytext og nbsripout. json.\n\n\n\nKommer snart. clone, add, commit, push, pull, merge, revert, etc.\n\n\n\n\nGitHub er et nettsted som fungerer som vÃ¥rt felles mappesystem for deling av kode. SSB har sin egen organisasjonskonto med navn statisticsnorway\n\n\nDette kapittelet er bare relevant hvis man ikke har en GitHub-brukerkonto fra fÃ¸r. For Ã¥ bruke ssb-project-programmet til Ã¥ generere et remote repo pÃ¥ GitHub mÃ¥ du ha en konto. Derfor starter vi med Ã¥ gjÃ¸re dette. Det er en engangsjobb og du trenger aldri gjÃ¸re det igjen.\n\n\n\n\n\n\nSSB har valgt Ã¥ ikke sette opp SSB-brukerne til de ansatte som GitHub-brukere. En viktig Ã¥rsak er at er en GitHub-konto ofte regnes som en del av den ansattes CV. For de som aldri har brukt GitHub fÃ¸r kan det virke fremmed, men det er nok en fordel pÃ¥ sikt nÃ¥r alle blir godt kjent med denne arbeidsformen.\n\n\n\nSlik gjÃ¸r du det:\n\nGÃ¥ til https://github.com/\nTrykk Sign up Ã¸verst i hÃ¸yre hjÃ¸rne\nI dialogboksen som Ã¥pnes, se FigurÂ 1, skriver du inn din e-postkonto og lager et passord. Dette trenger ikke vÃ¦re din SSB-bruker og e-post. Vi anbefaler at du bruker en personlig e-postkonto og velger ditt eget passord. Det samme gjelder brukernavn ogsÃ¥.\n\n\n\n\nFigurÂ 1: Dialogboks for opprettelse av GitHub-bruker.\n\n\nDu har nÃ¥ laget en egen GitHub-bruker. I neste steg skal vi knytte denne kontoen til din SSB-bruker.\n\n\n\nHvis du har fullfÃ¸rt forrige steg sÃ¥ har du nÃ¥ en GitHub-konto. Hvis du stÃ¥r pÃ¥ din profil-side sÃ¥ ser den ut som i FigurÂ 2.\n\n\n\nFigurÂ 2: Et eksempel pÃ¥ hjemmeomrÃ¥det til en GitHub-bruker\n\n\nDet neste vi mÃ¥ gjÃ¸re er Ã¥ aktivere 2-faktor autentisering, siden det er dette som benyttes i SSB. Hvis du stÃ¥r pÃ¥ siden i bildet over, sÃ¥ gjÃ¸r du fÃ¸lgende for Ã¥ aktivere 2-faktor autentisering mot GitHub:\n\n\n\nTrykk pÃ¥ den lille pilen Ã¸verst til hÃ¸yre og velg Settings(se FigurÂ 3).\nDeretter velger du Password and authentification i menyen til venstre.\nUnder Two-factor authentication trykker du pÃ¥ Enable.\n\n\n\n\n\n\nFigurÂ 3: Ã…pne settings for din GitHub-bruker.\n\n\n\n\n\nFigurÂ 4 viser dialogboksen som vises. Velg Enable two-factor authentification.\n\n\n\n\nFigurÂ 4: Dialogboks som Ã¥pnes nÃ¥r 2FA skrus pÃ¥ fÃ¸rste gang.\n\n\n\nFigurÂ 5 viser dialogboksen som vises for Ã¥ velge hvordan man skal autentisere seg. Her anbefales det Ã¥ velge Set up using an app, slik at du kan bruke Microsoft Authenticator-appen pÃ¥ din mobil.\n\n\n\n\nFigurÂ 5: Dialogboks for Ã¥ velge hvordan man skal autentisere seg med 2FA.\n\n\nFigurÂ 6 viser QR-koden som vises. Denne skal vi bruke i neste steg.\n\n\n\nFigurÂ 6: QR-kode som skannes av Microsoft Authenticator.\n\n\n\n\n\nStrekkoden over skal skannes i din Microsoft Authenticator-app pÃ¥ mobilen, som vist i FigurÂ 7. Ã…pne appen, trykk pÃ¥ Bekreftede ID-er, og til slutt trykk pÃ¥ Skann QR-kode. Deretter skanner du QR-koden fra punkt 5.\nNÃ¥r koden er skannet har du fÃ¥tt opp fÃ¸lgende bilde pÃ¥ appens hovedside (se bilde til hÃ¸yre). Skriv inn den 6-siffer koden pÃ¥ GitHub-siden med QR-koden.\nTil slutt lagrer du Recovery-codes et trygt sted som bare du har tilgang til.\n\n\n\n\n\n\nFigurÂ 7: Mobilappen Microsoft authenticator\n\n\n\n\nNÃ¥ har vi aktivert 2-faktor autentisering for GitHub og er klare til Ã¥ knytte vÃ¥r personlige konto til vÃ¥r SSB-bruker pÃ¥ SSBs â€œGithub organisationâ€ statisticsnorway.\n\n\n\nI forrige steg aktiverte vi 2-faktor autentisering for GitHub. Det neste vi mÃ¥ gjÃ¸re er Ã¥ koble oss til Single Sign On (SSO) for SSB sin organisasjon pÃ¥ GitHub:\n\nTrykk pÃ¥ lenken https://github.com/orgs/statisticsnorway/sso\nI dialogboksen som dukker opp trykker du pÃ¥ Continue, slik som vist i FigurÂ 8.\n\n\n\n\nFigurÂ 8: Single Sign on (SSO) for SSB sin organisasjon pÃ¥ GitHub\n\n\nNÃ¥r du har gjennomfÃ¸rt dette sÃ¥ har du tilgang til statisticsnorway pÃ¥ GitHub. GÃ¥r du inn pÃ¥ denne lenken sÃ¥ skal du nÃ¥ kunne lese bÃ¥de Public, Private og Internal repoer, slik som vist i FigurÂ 9.\n\n\n\nFigurÂ 9: Medlemsvisning for SSB sin GitHub-organisasjon.\n\n\n\n\n\nNÃ¥r vi skal jobbe med SSB-kode som ligger lagret hos statistcsnorway pÃ¥ GitHub, sÃ¥ mÃ¥ vi autentisere oss. MÃ¥ten vi gjÃ¸re det pÃ¥ er ved Ã¥ generere et Personal Access Token (ofte forkortet PAT) som vi oppgir nÃ¥r vi vil hente eller oppdatere kode pÃ¥ GitHub. Da sender vi med PAT for Ã¥ autentisere oss for GitHub.\n\n\nFor Ã¥ lage en PAT som er godkjent mot statisticsnorway sÃ¥ gjÃ¸r man fÃ¸lgende:\n\nGÃ¥ til din profilside pÃ¥ GitHub og Ã¥pne Settings slik som ble vist SeksjonÂ 1.2.2.\nVelg Developer Settings i menyen til venstre.\nI menyen til venstre velger du Personal Access Token, og deretter Tokens (classic).\nUnder Note kan du gi PATâ€™en et navn. Velg et navn som er intuitivt for deg. Hvis du skal bruke PAT til Ã¥ jobbe mot Dapla, sÃ¥ ville jeg ganske enkelt kalt den dapla. Hvis du skal bruke den mot bakkemiljÃ¸et ville jeg kalt den prodsone eller noe annet som gjÃ¸r det lett for det skjÃ¸nne innholdet i ettertid.\nUnder Expiration velger du hvor lang tid som skal gÃ¥ fÃ¸r PAT blir ugyldig. Dette er en avvening mellom sikkerhet og hva som er praktisk. Det anbefales at du velger 365 dager. NÃ¥r PAT utlÃ¸per mÃ¥ du gjenta stegene i dette kapittelet.\nUnder Select scopes velger du Repo slik som vist i FigurÂ 10.\n\n\n\n\nFigurÂ 10: Gi token et kort og beskrivende navn\n\n\n\nTrykk pÃ¥ Generate token nederst pÃ¥ siden og du fÃ¥r noe lignende det du ser i FigurÂ 11.\n\n\n\n\nFigurÂ 11: Token som ble generert.\n\n\n\nKopier deretter PAT til en midlertidig fil. Grunnen er at du aldri vil se det igjen her etter at vi har gjennomfÃ¸rt neste steg.\nDeretter trykker du pÃ¥ Configure SSO og velger Authorize ved siden statisticsnorway, slik som vist i FigurÂ 12. Svar deretter pÃ¥ spÃ¸rsmÃ¥lene som dukker opp.\n\n\n\n\nFigurÂ 12: Autorisering av Token mot SSBs GiHub-organisasjon.\n\n\nVi har nÃ¥ opprettet en PAT som er godkjent for bruk mot SSB sin kode pÃ¥ GitHub. Det betyr at hvis vi vil jobbe med Git pÃ¥ SSB sine maskiner i sky eller pÃ¥ bakken, sÃ¥ mÃ¥ vi sendte med dette tokenet for Ã¥ fÃ¥ lov til Ã¥ jobbe med koden som ligger pÃ¥ statisticsnorway pÃ¥ GitHub.\n\n\n\nDet er ganske upraktisk Ã¥ mÃ¥tte sende med tokenet hver gang vi skal jobbe med GitHub. Vi bÃ¸r derfor lagre det lokalt der vi jobber, slik at Git automatisk finner det. Det finnes mange mÃ¥ter Ã¥ gjÃ¸re dette pÃ¥ og det er ikke bestemt hva som skal vÃ¦re beste-praksis i SSB. Men en mÃ¥te Ã¥ gjÃ¸re det er via en .netrc-fil. Vi oppretter da en fil som heter .netrc pÃ¥ vÃ¥rt hjemmeomrÃ¥de, og legger fÃ¸lgende informasjon pÃ¥ en (hvilken som helst) linje i filen:\nmachine github.com login <github-bruker> password <Personal Access Token>\nGitHub-bruker er da din personlige bruker og IKKE brukernavnet ditt i SSB. Personal Access Token er det vi lagde i forrige kapittelet.\nEn veldig enkel mÃ¥te Ã¥ lagre dette er som fÃ¸lger. Anta at min personlige GitHub-bruker er SSB-Chad og at min Personal Access Token er blablabla. Da kan jeg gjÃ¸re fÃ¸lgende for Ã¥ lagre det i .netrc:\n\nGÃ¥ inn i Jupyterlab og Ã¥pne en Python-notebook.\nI den fÃ¸rste kodecellen skriver du:\n\n!echo \"machine github.com login SSB-Chad password blablabla\" >> ~/.netrc\nAlternativt kan du droppe det utropstegnet og kjÃ¸re det direkte i en terminal. Det vil gi samme resultat. Koden over legger til en linje med teksten\nmachine github.com login SSB-Chad password blablabla\ni en .netrc-fil pÃ¥ din hjemmeomrÃ¥det, uanvhengig av om du har en fra fÃ¸r eller ikke. Hvis du har en fil fra fÃ¸r som allerede har et token fra GitHub, ville jeg nok slettet det fÃ¸r jeg legger en et nytt token.\nHver gang du jobber mot GitHub vil Git sjekke om informasjon om autentisering ligger i denne filen, og bruke den hvis den ligger der.\n\n\n\nI eksempelet over lagde vi en PAT som var gyldig i 90 dager. Dermed vil du ikke kunne jobbe mot GitHub med dette tokenet etter 90 dager. For Ã¥ oppdatere tokenet gjÃ¸r du fÃ¸lgende:\n\nLag et nytt PAT ved Ã¥ repetere SeksjonÂ 1.2.4.1.\nI miljÃ¸et der du skal jobbe med Git og GitHub gÃ¥r du inn i din .netrc og bytter ut token med det nye.\n\nOg med det er du klar til Ã¥ jobbe mot statisticsnorway pÃ¥ GitHub."
  },
  {
    "objectID": "hvorfor-dapla.html",
    "href": "hvorfor-dapla.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Hvorfor Dapla?\nSom dataplattform skal Dapla stimulerere til Ã¸kt kvalitet pÃ¥ statistikk og forskning, samtidig som den gjÃ¸r organisasjonen mer tilpasningsdyktig i mÃ¸te med fremtiden.\n\n\nDen nye skybaserte dataplattformen (Dapla) skal bli viktig for Ã¥ effektivisere arbeids-og produksjonsprosesser, den skal sikre effektiv lagring og gjenfinning av data og metadata, og stÃ¸tte opp under deling av data pÃ¥ tvers av statistikkomrÃ¥der.\n\nKilde: Langtidsplan for SSB (2022-2024)\n\n\n\nMÃ¥let med Dapla er Ã¥ tilby tjenester og verktÃ¸y som lar statistikkprodusenter og forskere produsere resultater pÃ¥ en sikker og effektiv mÃ¥te."
  },
  {
    "objectID": "avansert.html",
    "href": "avansert.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Avansert"
  },
  {
    "objectID": "nytt-ssbproject.html",
    "href": "nytt-ssbproject.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "I dette kapittelet forklarer vi hvordan du oppretter et ssb-project og hva det innebÃ¦rer. ssb-project er et CLI1 for Ã¥ raskt komme i gang med koding pÃ¥ Dapla, hvor en del SSB-spesifikke beste-prakiser er ivaretatt. Kode som naturlig hÃ¸rer sammen, f.eks. koden til et produksjonslÃ¸p for en statistikk, er mÃ¥lgruppen for dette programmet. Kort fortalt kan du kjÃ¸re denne kommandoen i en terminal\nssb-project create stat-testprod\nog du vil fÃ¥ en mappe som heter stat-testprod med fÃ¸lgende innhold:\n\nStandard mappestruktur En standard mappestruktur gjÃ¸r det lettere Ã¥ dele og samarbeide om kode, som igjen reduserer sÃ¥rbarheten knyttet til at fÃ¥ personer kjenner koden.\nVirtuelt miljÃ¸ Virtuelle miljÃ¸er isolerer og lagrer informasjon knyttet til kode. For eksempel hvilken versjon av Python du bruker og tilhÃ¸rende pakkeversjoner. Det er viktig for at publiserte tall skal vÃ¦re reproduserbare. VerktÃ¸yet for Ã¥ lage virtuelt miljÃ¸ er Poetry.\nVersjonshÃ¥ndtering med Git Initierer versjonshÃ¥ndtering med Git og legger til SSBs anbefalte .gitignore og .gitattributes. Det sikrer at du ikke versjonhÃ¥ndterer filer/informasjon som ikke skal versjonshÃ¥ndteres.\n\nI tillegg lar ssb-project deg opprette et GitHub-repo hvis du Ã¸nsker. Les mer om hvordan du kan ta i bruk dette verktÃ¸yet under.\n\n\n\n\n\n\nMerk\n\n\n\nDokumentasjonen for ssb-project finnes her: https://statisticsnorway.github.io/ssb-project-cli/. Det oppdateres hver gang en ny versjon av ssb-project slippes.\n\n\n\n\nFÃ¸r du kan ta i bruk ssb-project sÃ¥ er det et par ting som mÃ¥ vÃ¦re pÃ¥ plass:\n\nDu mÃ¥ ha opprettet en git-bruker og git-epost lokalt der du skal kalle pÃ¥ programmet (les mer om hvordan her).\nHvis du Ã¸nsker at ssb-project ogsÃ¥ skal opprette et GitHub-repo for deg mÃ¥ du ogsÃ¥ fÃ¸lgende vÃ¦re pÃ¥ plass:\n\nDu mÃ¥ ha en GitHub-bruker (les hvordan her)\nSkru pÃ¥ 2-faktor autentifisering for GitHub-brukeren din (les hvordan her)\nVÃ¦re koblet mot SSBs organisasjon statisticsnorway pÃ¥ GitHub (les hvordan her)\nOpprette Personal Access Token (PAT) og godkjenne det for bruk mot statisticsnorway (les hvordan her)\n\n\nDet er ogsÃ¥ Ã¥ anbefale at du lagrer PAT lokalt slik at du ikke trenger Ã¥ forholde deg til det nÃ¥r jobber med Git og GitHub. Hvis du har alt dette pÃ¥ plass sÃ¥ kan du bare fortsette Ã¥ fÃ¸lge de neste kapitlene.\n\n\n\n\n\n\n\n\n\nHar du Github bruker? Noe funksjonalitet i ssb-project krever det. Finn ut hvordan ved Ã¥ lese forrige kapittel.\n\n\n\nssb-project lar deg opprette en prosjekt-mappe med og uten GitHub-repo. La oss ta for oss hver av alternativene.\n\n\nFor Ã¥ opprette et nytt ssb-project uten GitHub-repo gjÃ¸r du fÃ¸lgende:\n\nÃ…pne en terminal. De fleste vil gjÃ¸re dette i Jupyterlab pÃ¥ bakke eller sky og da kan de bare trykke pÃ¥ det blÃ¥ â•-tegnet i Jupyterlab og velge Terminal.\nFÃ¸r vi kjÃ¸rer programmet mÃ¥ vi vÃ¦re obs pÃ¥ at ssb-project vil opprette en ny mappe der vi stÃ¥r. GÃ¥ derfor til den mappen du Ã¸nsker Ã¥ ha den nye prosjektmappen. For Ã¥ opprette et prosjekt som heter stat-testprod sÃ¥ skriver du fÃ¸lgende i terminalen:\n\nssb-project create stat-testprod\n\n\nHvis du stod i hjemmemappen din pÃ¥ nÃ¥r du skrev inn kommandoen over i terminalen, sÃ¥ har du fÃ¥tt mappestrukturen som vises i FigurÂ 1. 2. Den inneholder fÃ¸lgende :\n\n.git-mappe som blir opprettet for Ã¥ versjonshÃ¥ndtere med Git.\nsrc-mappe som skal inneholde all koden som utgjÃ¸r produksjonslÃ¸pet.\ntests-mappe som inneholder tester du skriver for koden din.\nLICENCE-fil som skal benyttes for public-repos i SSB.\npoetry.lock-fil som inneholder alle versjoner av Python-pakker som blir brukt.\nREADME.md-fil som brukes for tekstlig innhold pÃ¥ GitHub-siden for prosjektet.\n\n\n\n\n\n\nFigurÂ 1: Mappen som ble opprettet av ssb-project.\n\n\n\n\n\n\n\nOver sÃ¥ opprettet vi et ssb-project uten Ã¥ opprette et GitHub-repo. Hvis du Ã¸nsker Ã¥ opprette et GitHub-repo ogsÃ¥ mÃ¥ du endre kommandoen over til:\nssb-project create stat-testprod --github --github-token='blablabla'\nKommandoen over oppretter en mappestruktur slik vi sÃ¥ tidligere, men ogsÃ¥ et ssb-project som heter stat-testprod med et GitHub-repo med samme navn. Som du ser sÃ¥ mÃ¥ vi da sende med opsjonen --github og PAT med opsjonen --github-token='blablabla'. Repoet i GitHub ser da ut som i FigurÂ 2.\n\n\n\nFigurÂ 2: GitHub-repo som er opprettet av ssb-project\n\n\n\n\n\n\n\n\nNÃ¥r du har opprettet et nytt ssb-project, eller bygget et eksisterende prosjekt, sÃ¥ kan det ta rundt 30 sekunder fÃ¸r kernelen viser seg i Jupterlab-launcher. VÃ¦r tÃ¥lmodig!\n\n\n\n\n\n\n\nNÃ¥r du har opprettet et ssb-project sÃ¥ kan du installere de python-pakkene du trenger fra PyPI. Hvis du for eksempel Ã¸nsker Ã¥ installere Pandas, et populÃ¦rt data wrangling bibliotek, sÃ¥ kan du gjÃ¸re fÃ¸lgende:\n\nÃ…pne en terminal i Jupyterlab.\nGÃ¥ inn i prosjektmappen din ved Ã¥ skrive\n\ncd <sti til prosjektmappe>\n\nLag en branch/utviklingsgren som f.eks. heter install-pandas:\n\ngit checkout -b install-pandas\n\nInstaller Pandas ved Ã¥ skrive fÃ¸lgende\n\npoetry add pandas\n\n\n\nFigurÂ 3: Installasjon av Pandas med ssb-project\n\n\nFigurÂ 3 viser hvordan dette vil se ut i en Jupyterlab-terminal. Kommandoen for Ã¥ installere noe er poetry add etterfulgt av pakkenavnet. Vi ser ogsÃ¥ at den automatisk legger til Pandas-versjonen i filen poetry.lock. Les mer om hvordan man installerer pakker her.\n\n\n\nNÃ¥r du nÃ¥ har installert en pakke sÃ¥ har filen poetry.lock endret seg. La oss for eksempelets skyld anta at du Ã¸nsker Ã¥ bruke Git til Ã¥ dokumentere denne hendelsen, og dele det med en kollega via GitHub. Hvis vi har opprettet et ssb-project med et GitHub-repo sÃ¥ kan vi gjÃ¸re akkurat dette:\n\nVi kan stage alle endringer med fÃ¸lgende kommando i terminalen nÃ¥r vi stÃ¥r i prosjektmappen:\n\ngit add -A\n\nVidere kan commit en endring, dvs. ta et stillbilde av koden i dette Ã¸yeblikket, ved Ã¥ skrive fÃ¸lgende:\n\ngit commit -m \"Installert pandas\"\n\nPush det opp til GitHub3. Anta at vi gjorde dette i branchen install-pandas som ble opprettet tidligere. Da kan vi skrive fÃ¸lgende:\n\ngit push --set-upstream origin install-pandas\nMer kommer her.\n\n\n\nNÃ¥r vi skal samarbeide med andre om kode sÃ¥ gjÃ¸r vi dette via GitHub. NÃ¥r du pusher koden din til GitHub, sÃ¥ kan samarbeidspartnere pulle ned koden og jobbe videre med den. Men nÃ¥r de henter ned koden sÃ¥ vil de bare hente ned selve koden, ikke pakker og Python-versjonen som ble brukt. De mÃ¥ installere alt som du hadde installert. I tillegg trenger de en kernel hvis de skal jobbe i Jupyterlab. ssb-project gjÃ¸r det svÃ¦rt enkelt Ã¥ bygge opp det du trenger, siden det virtuelle miljÃ¸et har all informasjon om hva som trengs.\nFor at samarbeidspartneren din skal kunne bygge miljÃ¸et pÃ¥ nytt, mÃ¥ de ha gjort en minimal konfigurering av Git. Les mer om hvordan du frem for Ã¥ gjÃ¸re dette her.\nFor Ã¥ bygge opp et eksisterende miljÃ¸ gjÃ¸r du fÃ¸lgende:\n\nFÃ¸rst mÃ¥ du kopiere prosjektet ned lokalt, eller klone repoet med git-terminologi\n\ngit clone https://github.com/statisticsnorway/<prosjektnavn>\n\nGÃ¥ inn i mappen du klonet\n\ncd <prosjektnavn>\n\nSkape et virtuelt miljÃ¸ og installere en tilsvarende Jupyter kernel med\n\nssb-project build\n\n\n\nDet vil vÃ¦re tilfeller hvor man Ã¸nsker Ã¥ slette et ssb-project, enten fordi man ikke trenger koden lenger eller fordi man bare testet litt.\n\n\nHvis man jobber med flere prosjekter sÃ¥ kan det fort bli mange Jupyter kerneler hengende igjen. Derfor er det ogsÃ¥ mulighet Ã¥ kjÃ¸re\nssb-project clean stat-testprod\nsom sletter Jupyter-kernelen og de installerte pakkene i prosjektet. Hvis du ogsÃ¥ Ã¸nsker Ã¥ slette selve mappen med kode mÃ¥ du gjÃ¸re det manuelt4:\nrm -rf ~/stat-testprod/\nProsjektmappen over lÃ¥ direkte i hjemmemappen min og hjemmemappen pÃ¥ Linux kan alltid referes til med et tilda-tegn ~.\n\n\n\nGitHub-repoer som er opprettet under SSB sin organinasjons statisticsnorway pÃ¥ GitHub kan ikke slettes, bare arkiveres. Grunnen er at hvis man oppdager en sÃ¥rbarhet senere sÃ¥ er det viktig Ã¥ kunne se repoet for Ã¥ forstÃ¥ hva som har skjedd.\nHvis du ikke trenger et GitHub-repo lenger kan man arkivere repoet. Det gjÃ¸r du pÃ¥ fÃ¸lgende mÃ¥te:\n\nGi inn i repoet Settings slik som vist med rÃ¸d pil i FigurÂ 4.\n\n\n\n\nFigurÂ 4: Settings for repoet.\n\n\n\nUnder General scroller du deg ned til delen som heter Danger Zone og velger Archive this repository, slik som vist pÃ¥ FigurÂ 5.\n\n\n\n\nFigurÂ 5: Arkivering av et repo.\n\n\n\nI dialogboksen som dukker opp fyller du inn reponavnet som beskrevet og trykker pÃ¥ I understand the consequences, archive this repository, som vist i FigurÂ 6.\n\n\n\n\nFigurÂ 6: Bekreftelse av arkiveringen.\n\n\nNÃ¥r det er gjort sÃ¥ er repoet lesbart, men man kan ikke jobbe med det. Men som vi ser av @#fig-github-repo-settings-archive-warning kan man omgjÃ¸re arkiveringen senere hvis det skulle vÃ¦re Ã¸nskelig.\n\n\n\n\nVi har forelÃ¸pig ikke integret R i ssb-project. Grunnen er at det mest populÃ¦re virtuelle miljÃ¸-verktÃ¸et for R, renv, kun tilbyr Ã¥ passe pÃ¥ versjoner av R-pakker og ikke selve R-installasjonen. Det er en svakhet som trolig gjÃ¸r det vanskeligere enn nÃ¸dvendig Ã¥ gjenskape tidligere publiserte resultater med ssb-project. I tillegg klarer den ikke Ã¥ gjenkjenne pakker som blir brukt i ipynb-filer.\nPlanen er Ã¥ finne et annet verktÃ¸y enn renv som kan ogsÃ¥ reprodusere R-versjonen. Team Statistikktjenester ser nÃ¦rmere pÃ¥ hvilke alternativer som finnes og vil tilby noe i fremtiden.\nI mellomtiden kan man bruke renv slik det er beskrevet her for skymiljÃ¸et, og med denne modifiseringen for bakkemiljÃ¸et."
  },
  {
    "objectID": "vedlikehold.html",
    "href": "vedlikehold.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Vedlikehold\nKommer snart."
  },
  {
    "objectID": "pakke-install.html",
    "href": "pakke-install.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Installering av pakker er kun er mulig I et virtuelt miljÃ¸. Det er anbefalt Ã¥ benytte poetry til dette. Eksemplene videre tar derfor utgangspunkt i et poetry prosjekt.\nDet er mulig Ã¥ installere pakker med pip. Pakker kan installeres som normalt, hvis man har satt opp og aktivert et virtuelt miljÃ¸.\n\n\nDette eksemplet viser hvordan man setter oppe et enkelt poetry prosjekt kalt test, hvis man Ã¸nsker Ã¥ benytte et annet prosjektnavn mÃ¥ man endre dette i hver av kommandoene.\nSett opp prosjektet:\npoetry new test\nNaviger inn i prosjektmappen:\ncd test\nBruk poetry install for Ã¥ bygge prosjektet:\npoetry install\nHvis man fÃ¥r en tilbakemelding som denne er prosjektet satt opp korrekt:\nCreating virtualenv test-EojoH6Zm-py3.10 in /home/jovyan/.cache/pypoetry/virtualenvs \nUpdating dependencies \nResolving dependencies... (0.1s) \n\nWriting lock file \n\n\n\nFor Ã¥ legge til pakker i et prosjekt benyttes kommandoen poetry add.\nSkal man legge til pakken â€œpendulumâ€ vil det se slik ut:\npoetry add pendulum\nPoetry tilbyr mÃ¥ter Ã¥ sette versjonsbegrensninger for pakker som legges til i et prosjekt, dette kan man lese mer om her.\n\n\n\nFor Ã¥ fjerne pakker fra et prosjekt benytter man poetry remove.\nHvis man Ã¸nsker Ã¥ fjerne â€œpendulumâ€ fra et prosjekt vil kommandoen se slik ut:\npoetry remove pendulum\n\n\n\nFor Ã¥ oppdatere pakker i et prosjekt benytter man kommandoen poetry update.\nSkal man oppdatere pakken â€œpendulumâ€ bruker man:\npoetry update pendulum\nSkal man oppdatre alle pakken i et prosjekt benytter man:\npoetry update \n\n\n\nNÃ¥r man installerer pakker sÃ¥ vil det etter hvert utvikle seg et sett av potensielt kompliserte avhengigheter mellom disse pakkene. Dette skyldes at en pakke kan benytte seg av funksjonalitet i andre pakker, som igjen benytter seg av funksjonalitet i andre pakker, osv.. Hvis noen finner en sikkerhetssÃ¥rbarhet i en pakke sÃ¥ kan det fikses ved at en ny versjon av den pakken slippes, som igjen kan fÃ¥ konsekvenser for pakker som er avhengig av denne.\nI SSB er det tilrettelagt for at alle som versjonshÃ¥ndterer koden sin pÃ¥ GitHub kan skanne pakkene sine for sÃ¥rbarheter og nye versjoner av pakker med Dependabot. Dependabot hjelper oss med Ã¥ finne og fikse sÃ¥rbarheter og gamle pakkeversjoner. Dette er spesielt viktig nÃ¥r man installerer sine egne pakker.\nDet er anbefalt at alle som installerer sine egne pakker i SSB skrur pÃ¥ Dependabot i sine GitHub-repoer. Du kan skru pÃ¥ ved Ã¥ gjÃ¸re fÃ¸lgende:\n\nGÃ¥ inn repoet\nTrykk pÃ¥ Settings for det repoet som vist pÃ¥ FigurÂ 1.\n\n\n\n\nFigurÂ 1: Ã…pne Settings for et GitHub-repo.\n\n\n\nI menyen til venstre velger du Code security and analysis\nUnder seksjonen Dependabot velger Enable pÃ¥ minst Dependabot alerts og Dependabot security updates, slik som vist i FigurÂ 2.\n\n\n\n\nFigurÂ 2: Skru pÃ¥ Dependabot i GitHub.\n\n\nNÃ¥r du har gjort dette vil GitHub varsle deg hvis det finnes en kjent sÃ¥rbarhet i pakkene som benyttes.\n\n\n\nFor Ã¥ kunne benytte det virtuelle miljÃ¸et i en notebook mÃ¥ man sette opp en kernel. Kernel burde gis samme navn som prosjektet.\nFÃ¸rst legger man til ipykernel:\npoetry add ipykernel\nSÃ¥ opprettes kernel med:\npoetry run python -m ipykernel install --user --name test\nEtter dette er kernelen test opprettet og kan velges for Ã¥ benytte miljÃ¸et i en notebook.\n\n\n\nFor Ã¥ fjerne en kernel med navn test bruker man:\njupyter kernelspec remove test\nDu vil bli spurt om Ã¥ bekrefte, trykk y hvis man Ã¸nsker Ã¥ slette:\nKernel specs to remove:\n  test                    /home/jovyan/.local/share/jupyter/kernels/test\nRemove 1 kernel specs [y/N]: y\nEtter dette er kernelen fjernet.\n\n\n\nHvem som helst kan legge til pakker pÃ¥ PyPi, det betyr at de i verstefall, kan inneholde skadelig kode. Her er en list med viktige tiltak som minimere risikoen:\n\nFÃ¸r man installerer pakker bÃ¸r man alltid sÃ¸ke de opp pÃ¥ https://pypi.org. Det er anbefalt Ã¥ klippe og lime inn pakkenavnet nÃ¥r man skal legge det til i et prosjekt.\nEr det et populÃ¦rt/velkjent prosjekt? Hvor mange stjerner og forks har repoet?\n\n\n\n\n\nInstallering av pakker for R-miljÃ¸et i Jupyterlab er forelÃ¸pig ikke en del av ssb-project. Men vi kan bruke renv. Mer kommer.\n\n\nFor Ã¥ installere dine egne R-pakker mÃ¥ du opprette et virtuelt miljÃ¸ med renv. GÃ¥ inn i Jupyterlab og Ã¥pne R-notebook. Deretter skriver du inn fÃ¸lgende i kodecelle:\nrenv::init()\nDenne kommandoer aktiverer et virtuelt miljÃ¸ i mappen du stÃ¥r i. Rent praktisk vil det si at du fikk fÃ¸lgende filer/mapper i mappen din:\nrenv.lock\nEn fil som inneholder versjoner av alle pakker du benytter i koden din.\n.Rprofile En fil som inneholder informasjon om oppsetting av miljÃ¸ og alternative.\nrenv\nMappe som inneholder alle pakkene du installerer.\nrenv/activate.R En fil som aktivere renv miljÃ¸ for et prosjekt.\nHvis prosjektet ligger pÃ¥ GitHub, skal filene renv.lock, .Rprofile og renv/activate.R vÃ¦re pÃ¥ GitHub\nNÃ¥ som vi har et virtuelle miljÃ¸et pÃ¥ plass kan vi installere en R-pakke. Du kan gjÃ¸re dette fra bÃ¥de terminalen og fra en Notebook. Vi anbefaler pÃ¥ gjÃ¸re det fra terminalen fordi du da fÃ¥r tilbakemelding pÃ¥ om installeringen gikk bra heller ikke. For Ã¥ installere i terminalen gjÃ¸r du fÃ¸lgende:\n\nÃ…pne en terminal i Jupyterlab\nStÃ¥ i mappen der du aktiverte det virtuelle miljÃ¸et\nSkriv in R og trykk enter.\n\nDet vi nÃ¥ har gjort er Ã¥ Ã¥pne R fra terminalen slik at vi kan skrive R-kode direkte i terminalen. Det omtales ofte som en R Console. NÃ¥ kan du skrive inn en vanlig kommando for Ã¥ installere R-pakker:\nrenv::install(\"PxWebApiData\")\nOver installerte vi pakken PxWebApiData fra den R sentral repository CRAN. Dette er en pakke skrevet i SSB for Ã¥ hente ut data fra vÃ¥r statistikkbank. Det er ogsÃ¥ mulig Ã¥ installere pakker som ligger pÃ¥ SSBs GitHub. Da mÃ¥ vi spesifisere at pakke ligger pÃ¥ â€˜statisticsnorwayâ€™ omrÃ¥de. For eksempel:\nrenv::install(\"statisticsnorway/klassR\")\nPakken klassR er skrevet for Ã¥ hente ut klassifikasjoner fra SSBs KLASS. Det er en public repository pÃ¥ Github og Ã¥pen for alle Ã¥ laste ned. For pakker som er pÃ¥ et lukket omrÃ¥de pÃ¥ â€˜statsitcsnorwayâ€™ mÃ¥ vi bruke Personal Authentication Token for Ã¥ installere. Vi kan gjÃ¸re dette ved hjelp av funksjonen install_github() i devtools pakken. For eksempel:\n```{r}\nrenv::install(\"devtools\")\nrenv::install(\"getPass\")\ndevtools::install_github(\"statisticsnorway/fellesr\", \n                        auth_token = getPass::getPass())\n\n```\nLa oss bruke pakken PxWebApiData i koden vÃ¥r med ved Ã¥ skrive fÃ¸lgende i kodecelle i Notebooken vÃ¥r:\nlibrary(PxWebApiData)\nApiData(\"https://data.ssb.no/api/v0/en/table/04861\", \n        Region = c(\"1103\", \"0301\"), ContentsCode = \"Bosatte\", Tid = c(1, 2, -2, -1))\nNÃ¥r vi nÃ¥ har brukt PxWebApiData i koden vÃ¥r sÃ¥ kan vi kjÃ¸re en kommando som legger til den pakken i renv.lock. Men fÃ¸r vi kan gjÃ¸re det mÃ¥ vi vÃ¦re obs pÃ¥ at renv ikke klarer Ã¥ gjenkjenne pakker som er i bruk Notebooks (ipynb-filer). Det er veldig upraktisk, men noe vi mÃ¥ forholde oss til nÃ¥r vi jobber med renv i Jupyterlab. En mulig lÃ¸sning for dette er Ã¥ bruke Jupytext til Ã¥ synkronisere en ipynb-fil med en Rmd-fil. renv kjenner igjen bÃ¥de R- og Rmd-filer. For Ã¥ synkronisere filene gjÃ¸r du fÃ¸lgende:\n\nTrykk Ctrl+Shift C\nSkriv inn Pair i sÃ¸kefeltet som dukker opp\nVelg Pair Notebook with R Markdown\n\nHvis du nÃ¥ endrer en av filene sÃ¥ vil den andre oppdatere seg, og renv vil kunne oppdage om du bruker en pakke i koden din. Men for Ã¥ trigge renv til Ã¥ lete etter pakker som er i bruk sÃ¥ mÃ¥ du skrive fÃ¸lgende kode i Notebooken eller R Console:\nrenv::snapshot()\nKikker du nÃ¥ inne i renv.lock-filen sÃ¥ ser du nÃ¥ at verjsonen av PxWebApiData er lagt til. I bildet under ser du hvordan et arbeidsmiljÃ¸ typisk kan se ut nÃ¥r man installerer sine egne pakker.\n\nFor Ã¥ installere alle pakker som ligger i renv.lock-filen med riktig versjon kan du skriver\nrenv:restore()\nDette er nyttig om det er nye medlemmer i gruppen som skal kjÃ¸re en produksjonslÃ¸p utviklet av andre.\n\n\n\nIndivide pakker kan fjernes fra library ved remove() funksjonen. For eksempel:\nrenv::remove(\"PxWebApiData\")\nFor Ã¥ fjerne fra renv.lock-filen ogsÃ¥ mÃ¥ du ta en snapshot() etterpÃ¥.\nrenv::snapshot()\nEn annen nyttig funksjon er renv::clean(). Dette fjerner alle pakker fra library som ikke er i bruk\nrenv::clean()\nIgjen mÃ¥ du ta en snapshot() for at endringer skal lagres pÃ¥ renv.lock-filen\n\n\n\nFor Ã¥ oppgradere en pakke kan du bruke renv::update(). For eksempel Ã¥ oppgradere PxWebApiData skriv:\nrenv::update(\"PxWebApiData\")\nFor Ã¥ installere et spesifikk versjon av en pakke kan du spesifisere dette med installering med @ og versjonsnummer. For eksempel Ã¥ installere PxWEbApiData versjon 0.4.0:\nrenv::install(\"PxWebApiData@0.4.0\")\nHusk Ã¥ ta en snapshot() etterpÃ¥ for Ã¥ lagre endringer til renv.lock-filen. Det betyr at du og andre kan gjenskape miljÃ¸ pÃ¥ nytt.\nrenv::snapshot()"
  },
  {
    "objectID": "lese-data-bakken.html",
    "href": "lese-data-bakken.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Mer kommer."
  },
  {
    "objectID": "arkitektur.html",
    "href": "arkitektur.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Arkitektur\nHvilke komponenter er plattformen bygd opp pÃ¥? Forklart pÃ¥ lettest mulig mÃ¥te."
  },
  {
    "objectID": "automatisering.html",
    "href": "automatisering.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Automatisering"
  },
  {
    "objectID": "bakke-til-sky.html",
    "href": "bakke-til-sky.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Fra bakke til sky"
  },
  {
    "objectID": "datatilstander.html",
    "href": "datatilstander.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Datatilstander\n\nDet er naturlig at hovedfokus i SSBs kvalitetsarbeid er rettet mot statistikkene. Samtidig har bÃ¥deforventninger og krav til SSBs evne til Ã¥ dele data Ã¸kt betydelig de senere Ã¥r. Det betyr at i tillegg til Ã¥ produsere hovedproduktet Â«statistikkÂ», sÃ¥ vil mange statistikkteam ha Ã¸kt fokus pÃ¥ Ã¥ produseregjenbrukbare datasett med hÃ¸y kvalitet. En viktig forutsetning for gjenbruk er at de som vil brukedataene, kan vite hvilke endringer dataene har gjennomgÃ¥tt. Det mÃ¥ ogsÃ¥ vÃ¦re mulig for andre Ã¥ finne og forstÃ¥ dataene. Kvalitetssikret bruk av data i SSB og gjenbruk i og utenfor SSB fordrer godemetadata. Definisjoner av datatilstander og andre statistikkbegreper mÃ¥ derfor i stÃ¸rst mulig gradvÃ¦re avstemt med internasjonale statistiske rammeverk og definisjoner.\nBegrepet Â«etterprÃ¸vbarhetÂ» brukes flere steder i notatet, og det legges til grunn at vi bÃ¸r ha som et ideal Ã¥ produsere statistikk pÃ¥ en slik mÃ¥te at ettertiden eller en uavhengig instans med tilgang til dataene og vÃ¥r dokumentasjon vil komme til samme statistiske resultater som oss selv.\nTilstandene som beskrives er kildedata, inndata, klargjorte data, statistikk og utdata. De tre fÃ¸rste er i hovedsak mikrodata som gir informasjon om enkeltenheter, mens statistikk og utdata i hovedsak er aggregerte data.\n\n(Standardutvalget 2021, 5)\n\n\n\n\n\nReferanser\n\nStandardutvalget. 2021. â€œDatatilstander i SSB.â€ Statistisk sentralbyrÃ¥. https://ssbno.sharepoint.com/sites/Internedokumenter/Delte%20dokumenter/Forms/AllItems.aspx?id=%2Fsites%2FInternedokumenter%2FDelte%20dokumenter%2FInterne%20dokumenter%202021%2F2021%2D17%20Datatilstander%20i%20SSB%20%2Epdf&parent=%2Fsites%2FInternedokumenter%2FDelte%20dokumenter%2FInterne%20dokumenter%202021."
  },
  {
    "objectID": "statbanken.html",
    "href": "statbanken.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Pakken â€œdapla-statbank-clientâ€ kan brukes til Ã¥ overfÃ¸re tabeller til Statistikkbanken fra Jupyterlab i prodsonen og pÃ¥ Dapla. Den henter ogsÃ¥ â€œfilbeskrivelsenâ€ som beskriver formen dataene skal ha nÃ¥r de sendes inn til Statistikkbanken. Og den kan ogsÃ¥ hente publiserte data fra Statistikkbanken. Pakken er en python-pakke som baserer seg pÃ¥ at dataene (deltabellene) lastes inn i en eller flere pandas DataFrames fÃ¸r overfÃ¸ring. Ved Ã¥ hente ned â€œfilbeskrivelsenâ€ kan man validere dataene sine (dataframene) mot denne lokalt, uten Ã¥ sende dataene til Statistikkbanken. Dette kan vÃ¦re til hjelp under setting av formen pÃ¥ dataene. Ã… hente publiserte data fra Statistikkbanken kan gjÃ¸res gjennom lÃ¸se funksjoner, eller via â€œklientenâ€.\nLenker: - Pakken ligger her pÃ¥ Pypi. Og kan installeres via poetry med: poetry add dapla-statbank-client - Kodebasen for pakken ligger her, readme-en gir en teknisk innfÃ¸ring som du kan fÃ¸lge og kopiere kode fra, og om du finner noe du vil rapportere om bruken av pakken sÃ¥ gjÃ¸r det gjerne under â€œissuesâ€ pÃ¥ github-sidene. - Noe demokode ligger i repoet, og kan vÃ¦re ett godt utgangspunkt Ã¥ kopiere og endre fra.\n\n\nStatistikkbanken opererer med ulike databaser for testing og produksjonssetting. Om du vil at tallene faktisk skal oppdateres pÃ¥ nettsidene sÃ¥ mÃ¥ du sende til Statistikkbankens â€œPRODâ€-database. Om du kun vil teste innsending skal du sende til databasen â€œTESTâ€. Disse databasene har de samme lastebrukerne, men passordene er ulike. Om du vil teste innsending mÃ¥ du derfor skaffe deg â€œtest-passordetâ€ til den lastebrukeren som du har tilgjengelig. For Ã¥ gjÃ¸re tester via pakken mÃ¥ du vÃ¦re i staging pÃ¥ dapla: https://jupyter.dapla-staging.ssb.no/ eller staging i prodosonen: https://sl-jupyter-t.ssb.no/ Om du faktisk vil sende inn data til publisering i Statistikkbanken mÃ¥ du vÃ¦re i dapla-prod (den vanlige): https://jupyter.dapla.ssb.no/ eller i prodsonen pÃ¥: https://sl-jupyter-p.ssb.no/ For Ã¥ teste er det fint Ã¥ skaffe seg noe data fra fjorÃ¥rets publisering pÃ¥ et produksjonslÃ¸p man kjenner fra fÃ¸r. Evt. kan man hente data fra Statistikkbanken og sende disse tilbake snudd rett, og med riktig antall prikke-kolonner lagt til.\n\n\n\nSe mer detaljer i readme-en pÃ¥ prosjektets kodebase.\n\n\nFor Ã¥ kunne bruke pakken mÃ¥ du importere klienten:\nfrom statbank import StatbankClient\nSÃ¥ initialiserer du klienten med de innstillingene som oftest er faste pÃ¥ tvers av alle innsendingene fra ett produksjonslÃ¸p:\nstatcli = StatbankClient(loaduser=\"LAST360\", date=\"2050-01-01\", overwrite=True, approve=2)\nHer vil du bli bedt om Ã¥ skrive inn passordet til lastebrukeren.\n\n\n\nOm du har dataene klare er det bare Ã¥ overfÃ¸re, men du mÃ¥ vite navnet pÃ¥ deltabell-dat-filene. (Statistikkbanken lagrer disse ned igjen som dat-filer.)\ndata_07495 = {\"kargrs01fylker1.dat\" : df_07495_fylker,\n              \"kargrs01landet1.dat\" : df_07495_landet,}\nstatcli.transfer(data_07495, tableid=\"07495\")\nEtter innsending kommer det en link til Statistikkbankens GUI for Ã¥ fÃ¸lge med pÃ¥ om innsendingen gikk bra hos dem. Om det var det du Ã¸nsket, sÃ¥ er du nÃ¥ ferdigâ€¦ Men det finnes mer funksjonalitet herâ€¦\n\n\n\nFor Ã¥ hente filbeskrivelsen til en hovedtabell bruker du denne metoden under klienten:\nfilbeskrivelse = statcli.get_description(tableid=\"07495\")\nprint(filbeskrivelse)\nMed filbeskrivelsen kan du lett fÃ¥ en mal pÃ¥ dictionaryet du mÃ¥ plassere dataene i:\nfilbeskrivelse.transferdata_template()\nDu kan ogsÃ¥ validere dataene dine mot filbeskrivelsen:\nfilbeskrivelse.validate(data_07495, tableid=\"07495\")\n\n\n\n\nDet tas noe ekstra ansvar i pakken rundt avrunding av desimaltall, da filbeskrivelsen inneholder informasjon om hvor mange desimaler som blir lagret per kolonne, kan vi runde av til rett antall samtidig som vi tar ett bevisst valg rundt â€œhvilken vei vi skal runde avâ€. PÃ¥ barneskolen lÃ¦rte vi at ved 2,5 avrundet til 0 desimaler, sÃ¥ runder vi opp til 3. Det samme skjer i utgangspunktet i SAS og Excel. Python og R runder derimot â€œmot nÃ¦rmeste partallâ€, sÃ¥ fra 2,5 blir det rundet til 2, men fra 1,5 blir det ogsÃ¥ rundet til 2. Dette er for Ã¥ forhindre bias i en retning. Dvs. om alle tall rundes opp, vil en hel kolonne med tall â€œdras oppoverâ€, ved Ã¥ gjÃ¸re annenhver opp og ned, vil ikke helheten bli â€œdratt en spesifikk veiâ€. Siden â€œround to evenâ€ ikke er det folk er vandte til, gjÃ¸r vi derfor noe annet i denne pakken, enn det som er vanlig oppfÃ¸rsel i Python. Vi runder opp. Om du bruker fÃ¸lgende metoden under filbeskrivelsen pÃ¥ dataene, sÃ¥ vil denne runde oppover, samtidig som den konverterer til en streng for Ã¥ bevare formateringen.\ndata_07495 = filbeskrivelse.round_data(data_07495)  # For Ã¥ ta vare pÃ¥ endringene, sÃ¥ mÃ¥ du skrive tilbake over variabelen\n\n\n\n\nEn date-widget for Ã¥ visuelt endre til en valid dato.\nLagring av overfÃ¸ring og filbeskrivelses-objekter til json-filer\nUthenting av logg fra klienten\nHenting av publisert data fra statbanken\nRotering av tabeller fra statbanken"
  },
  {
    "objectID": "ssbproject.html",
    "href": "ssbproject.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "SSB-project\nI forrige del forklarte vi hvordan man jobber med skarpe data pÃ¥ Dapla. Det neste steget vil ofte vÃ¦re Ã¥ begynne Ã¥ utvikle kode i Python og/eller R. Dette innebÃ¦rer at man helst skal:\n\nversjonshÃ¥ndtere med Git\nopprette et GitHub-repo\nopprette et virtuelt miljÃ¸ som husker hvilke versjoner av pakker og programmeringssprÃ¥k du brukte\n\nI tillegg mÃ¥ alt dette konfigureres for hvordan SSB sine systemer er satt opp. Dette har vist seg Ã¥ vÃ¦re unÃ¸dvendig krevende for mange. Team Statistikktjenester har derfor utviklet et program som gjÃ¸r alt dette for deg pÃ¥ en enkel mÃ¥te som heter ssb-project.\nVi mener at ssb-project er et naturlig sted Ã¥ starte nÃ¥r man skal bygge opp koden i Python eller R. Det gjelder bÃ¥de pÃ¥ bakken og pÃ¥ sky. I denne delen av boken forklarer vi fÃ¸rst hvordan du bruker ssb-project i det fÃ¸rste kapittelet. Siden programmet skjuler mye av kompleksiteten rundt dette, sÃ¥ bruker vi de andre kapitlene til Ã¥ forklare hvordan man ville satt opp dette uten hjelp av programmet. Dermed vil det vÃ¦re lett for SSB-ansatte Ã¥ skjÃ¸nne hva som gjÃ¸res og hvorfor det er nÃ¸dvendig."
  },
  {
    "objectID": "kildedata-prosessering.html",
    "href": "kildedata-prosessering.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Denne tjenesten er under utvikling og kan ikke anses som klar for produksjon.\n\n\n\nFor Ã¥ minske aksessering av PII1, oppfordres alle team pÃ¥ Dapla Ã¥ benytte seg av automatisering av kildedata prosessering. Automatisering av kildedata er en tjeneste som er tilgjengelig for team Ã¥ ta i bruk 100% selv-betjent. Kildedata (Standardutvalget 2021, 5) prosesseres til inndata gjennom et bestemt utvalg av operasjoner. Kildedata prosesseres som individuelle filer for Ã¥ holde oppsettet enkelt og mÃ¥lrettet mot de definerte operasjoner. Mer kompleks operasjoner som gÃ¥r pÃ¥ tvers av flere filer burde utfÃ¸res pÃ¥ inndata eller senere datatilstander.\n\n\n\n\n\n\nDet er kun teamets kildedataansvarlige som skal aksessere kildedata.\n\n\n\n\n\n\n\n\n\nTeamets kildedataansvarlige tar ansvar for Ã¥ prosessere kildedata til inndata pÃ¥ en forsvarlig mÃ¥te.\n\n\n\n\n\n\n\n\nFigurÂ 1: Operasjoner som inngÃ¥r i kildedata prosessering\n\n\n\nInndata er kildedata som er transformert til SSBs standard lagringsformat. Variabelnavn og -innhold er uendret bortsett fra at\n\ndirekte identifiserende variabler (f.eks. fÃ¸dselsnummer) er pseudonymisert\ntegnsett, datoformat, adresse mm er endret til SSBs standardformat\ndet benyttes standard kodeverk (Klass) der det er mulig (f.eks. kjÃ¸nn)\ndataene er minimert slik at kun variablene som er nÃ¸dvendige i den videre produksjonsprosessen, inngÃ¥r.\n\n\n(Standardutvalget 2021, 8)\nDet er ikke anbefalt Ã¥ gjennomfÃ¸re operasjoner som:\n\nGÃ¥r pÃ¥ tvers av flere filer\nLegge til nye felt\nEndre navn pÃ¥ felt\nAggregerer data\nosv.\n\n\n\n\n\n\nFÃ¸lg instruksjonene her for Ã¥ koble prosjektet ditt til Github.\n\n\n\n\n\nKilder konfigureres i et teams Infrastructure as Code (IaC) repo pÃ¥ Github. Det kan finnes basert pÃ¥ fÃ¸lgende formulering: github.com/statisticsnorway/<teamnavn>-iac. Kilder konfigureres under stien automation/source_data pÃ¥ repoet.\n\n\n\nHver kilde konfigureres ved hjelp av to filer:\n\nconfig.yaml som blant annet konfigurer hvilke stier i teamets kildedatabÃ¸tte prosesseres.\nprocess_source_data.py som kjÃ¸res nÃ¥r en kildedatafil prosesseres. Her mÃ¥ man skrive en python funksjon pÃ¥ en viss format.\n\nDisse filene er lagt til en mappe per kilde, under automation/source_data i IaC repoet. Se eksemplet under for en detaljert forklaring.\n\n\n\n\n\n\nMappenavnet for kilder i IaC repoene er brukt som navn for ressurser. Dette i praksis betyr at det enesete tillatte tegnene i mappenavnet er bokstaver, tall og bindestrek. Det er ikke tillatt med mellomrom eller andre spesialtegn. Det ogsÃ¥ mÃ¥ begrenses i lengde.\n\n\n\n\n\n\nDette gÃ¥r ut pÃ¥ om prosesseringsscriptet kan enkelt hÃ¥ndtere variasjonen i filene som samles inn.\nGrunn til Ã¥ opprette en ny kilde kan vÃ¦re: - Kildedatafilen har en annen format (f.eks xml eller json) - Kildedataen har ulike felter - Kildedataen inneholder PII2 eller ikke\n\n\n\n\n\n\n\n\n\nDisse instruksjoner forutsetter at prosjektet ditt er koblet til Github allerede.\n\n\n\n\nSkrive skriptet process_source_data.py som prosesserer kildedatafilen til inndata. Dette kan testes av kildedataansvarlige manuelt pÃ¥ Jupyter for Ã¥ verifisere at dataene blir prosessert som Ã¸nsket.\nI en gren i teamets IaC repo, legge til config.yaml og process_source_data.py i en mappe under automation/source_data. Se eksemplet under for en detaljert forklaring av formatet.\nLag en PR pÃ¥ grenen og fÃ¥ den godkjent av kildedataansvarlige.\nVent til alle tester er ferdige. Det skal stÃ¥ â€œAll checks have passedâ€ fÃ¸r man gÃ¥r videre, hvis testene feiler fÃ¸lg stegene her. \nSkrive atlantis apply i en kommentar pÃ¥ PRen for Ã¥ opprette det nÃ¸dvendige infrastruktur for Ã¥ prosessere kilden.\nMerge PRen.\nSjekk resultatet av det automatiske bygget.\nVerifisere at nye filer lagt i kildedatabÃ¸tten blir prosessert til inndata som forventet.\n\n\n\n\n\nLa oss si at et team (smÃ¥bakst) har to datakilder levert av ulik dataeiere pÃ¥ ulik formater. Den ene er om boller og er pÃ¥ csv format og den andre er om rundstykker og er pÃ¥ json format. Kildedataansvarlige i teamet bestemmer seg for at filene i boller/ er like nok Ã¥ prosesseres som en kilde, og at filene i rundstykker/ kan prosesseres som en annen kilde.\n\n\nssb-prod-smaabakst-data-kilde\nâ”œâ”€â”€ boller\nâ”‚Â Â  â”œâ”€â”€ hvetebolle\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 2018-salg.csv\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 2019-salg.csv\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ ...\nâ”‚Â Â  â”œâ”€â”€ kanelbolle\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 2018-salg.csv\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 2019-salg.csv\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ ...\nâ”‚Â Â  â””â”€â”€ skolebolle\nâ”‚Â Â      â”œâ”€â”€ 2018-salg.csv\nâ”‚Â Â      â”œâ”€â”€ 2019-salg.csv\nâ”‚Â Â      â”œâ”€â”€ ...\nâ””â”€â”€ rundstykker\n    â”œâ”€â”€ haandverker\n    â”‚Â Â  â”œâ”€â”€ apr-2022-resultater.json\n    â”‚Â Â  â”œâ”€â”€ aug-2022-resultater.json\n    â”‚Â Â  â”œâ”€â”€ ...\n    â””â”€â”€ havre\n        â”œâ”€â”€ apr-2022-resultater.json\n        â”œâ”€â”€ aug-2022-resultater.json\n        â”œâ”€â”€ ...\n\n\n\nsmaabakst-iac\nâ””â”€â”€ automation\n    â””â”€â”€ source_data\n        â”œâ”€â”€ boller\n        â”‚Â Â  â”œâ”€â”€ config.yaml\n        â”‚Â Â  â””â”€â”€ process_source_data.py\n        â””â”€â”€ rundstykker\n            â”œâ”€â”€ config.yaml\n            â””â”€â”€ process_source_data.py\n\n\n\nfolder_prefix: boller\nVerdien for folder_prefix tilsvarer en â€œfil stiâ€ i kildedatabÃ¸tte. I dette tilfellet vil nye filer lagt til under boller/ trigge en prosessering.\n\n\n\nfolder_prefix: rundstykker\n\n\n\n\n\nMed prosesseringsscriptet mener vi filen process_source_data.py som ligger i en mappe per kilde under automation/source_data. Dette scriptet vil bli kalt hver gang det blir lagt til en ny fil i kildedatabÃ¸tten. Metodesignaturen ser slik ut:\n def main(file_path):\n     \"\"\"Function is called when a file is added to the source-data bucket.\n     Args:\n         file_path: full file path of the source data file.\n     \"\"\"\nDette betyr at hvis f.eks. 10 filer blir lagt til i kildedatabÃ¸tten samtidig sÃ¥ vil det startes opp 10 individuelle Python-prosesser som kaller denne main-metoden med forskjellig file_path. Parameteren file_path vil inneholde hele filstien inkl. filnavn. SÃ¥ en enkel flytteoperasjon fra kildedatabÃ¸tten til inndatebÃ¸tten (uten noen form for konvertering) vil kunne uttrykkes slik:\nimport dapla as dp\n\n def main(file_path):\n     \"\"\"Function is called when a file is added to the source-data bucket.\n     Args:\n         file_path: full file path of the source data file.\n     \"\"\"\n    source_bucket_name = \"ssb-prod-my-project-data-kilde\"\n    destination_bucket_name = \"ssb-prod-my-project-data-produkt\"\n    destination_path = file_path.replace(source_bucket_name, destination_bucket_name)\n    df = dp.read_pandas(file_path)\n    dp.write_pandas(df, destination_bucket_path)\nAlternativtâ€¦\nfrom dapla import FileClient\n\n def main(file_path):\n     \"\"\"Function is called when a file is added to the source-data bucket.\n     Args:\n         file_path: full file path of the source data file.\n     \"\"\"\n    source_bucket_name = \"ssb-prod-my-project-data-kilde\"\n    destination_bucket_name = \"ssb-prod-my-project-data-produkt\"\n    destination_path = file_path.replace(source_bucket_name, destination_bucket_name)\n    fs = FileClient.get_gcs_file_system()\n    fs.copy(file_path, destination_path)\n\n\nDet anbefales Ã¥ bruke Pythons logging modul for Ã¥ logge, og ikke bruke print eller skrive til stdout/stderr. Det er satt opp en standard logger-konfigurasjon som skriver informasjonsmeldinger (log level info) til stdout og feilmeldinger (log level warning eller error) til stderr. Feil som ikke blir hÃ¥ndtert blir automatisk fanget opp og logget av automatiseringslÃ¸sningen. Eksemplet nedenfor logger en informasjonsmelding, en advarsel og en feilmelding:\nimport logging\nlogging.info('Til info')\nlogging.warning('Advarsel!')\nlogging.error('En feil oppstod!')"
  },
  {
    "objectID": "gcc.html",
    "href": "gcc.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Google Cloud Console\nGoogle Cloud er SSBs leverandÃ¸r av skytjenester som Dapla er bygget pÃ¥.\nGoogle Cloud Console er et web-basert grensesnitt for Ã¥ administrere ressurser og tjenester pÃ¥ Google Cloud. For Ã¥ bruke denne mÃ¥ man ha en Google-konto. Alle i SSB har en konto knyttet opp mot Google.\n\n\n\n\n\n\nGÃ¥ til Google Cloud Console og logg pÃ¥ med din SSB-bruker."
  },
  {
    "objectID": "bÃ¸tter.html",
    "href": "bÃ¸tter.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Hvert statistikkteam har sitt eget datalager som heter Google Cloud Storage (GCS). Disse er delt inn i flere datalagringsomrÃ¥der som kalles bÃ¸tter. Dette kan sees pÃ¥ som et filsystem som kan organiseres med flere undermapper og filer. Navnet pÃ¥ bÃ¸ttene mÃ¥ vÃ¦re unikt pÃ¥ tvers av alle Dapla-team. Derfor blir disse opprettet etter en navnekonvensjon basert pÃ¥ kjÃ¸remiljÃ¸, teamnavn og hvilke data bÃ¸tta skal inneholde.\n\n\n\nssb-prod-teamnavn-data-kilde: Inneholder pseudonymiserte rÃ¥data fra datakildene\nssb-prod-teamnavn-data-produkt: Inneholder data knyttet til statistikkproduktet, med fÃ¸lgende underkataloger:\n\ninndata\nklargjorte-data\nstatistikk\nutdata\n\nssb-prod-teamnavn-data-delt: Inneholder data knyttet til statistikkproduktet som kan deles med andre statistikkteam. Disse vil ha fÃ¸lgende underkataloger:\n\ninndata\nklargjorte-data\nstatistikk\nutdata\n\n\n\n\n\n\n\n\nUnderkatalogene inndata, klargjorte-data, statistikk og utdata gjenspeiler SSBs datatilstander. Se Datatilstander i SSB for mer informasjon.\n\n\n\n\n\n\nPÃ¥ samme mÃ¥te som i produksjonsmiljÃ¸et finnes det bÃ¸tter for utviklings- og testformÃ¥l:\n\nssb-staging-teamnavn-data-kilde\nssb-staging-teamnavn-data-produkt\nssb-staging-teamnavn-data-delt\n\n\n\n\nI tillegg til disse finnes det noen bÃ¸tter med data som kan deles med alle i SSB og og som kan brukes til kurs og opplÃ¦ring (bl.a. denne manualen). Disse bÃ¸ttene er:\n\nssb-prod-dapla-data-delt\nssb-staging-dapla-data-delt"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Denne boken er ment som enkel-Ã¥-bruke manual for Ã¥ ta i bruk SSBs nye dataplattform Dapla. Plattformen forsÃ¸ker Ã¥ gjÃ¸re statistikkprodusenter og forskere sÃ¥ selvhjulpne som mulig. MÃ¥lsetningen er at tjenestene som tilbys skal kunne tas i bruk pÃ¥ en enkel og intuitiv mÃ¥te. Men uansett hvor lett tilgjengelig tjenester er, og hvor mye arbeid som er lagt Ã¥ gjÃ¸re lÃ¸sninger brukervennlige, sÃ¥ trenger de fleste i SSB en klar og tydelig veiledning for hvordan de skal brukes og i hvilken stÃ¸rre sammenheng tjenestene inngÃ¥r. Dapla-manualen er ment Ã¥ vÃ¦re en sÃ¥nn stÃ¸tte i statistikkernes hverdag. Uansett om man lurer pÃ¥ hvordan man logger seg inn pÃ¥ plattformen, eller om man Ã¸nsker informasjon om kjÃ¸remiljÃ¸et for mer kompliserte maskinlÃ¦ringsmodeller, sÃ¥ skal man finne veiledning i denne manualen. MÃ¥lgruppen er bÃ¥de nybegynneren og den mer erfarne.\n\n\n\n\n\n\nDenne boken er skrevet med Quarto og er publisert pÃ¥ https://manual.dapla.ssb.no. Alle ansatte i SSB kan bidra til boken ved klone dette repoet, gjÃ¸re endringer i en branch, og sende en pull request til administratorene av repoet (Team Statistikktjenester).\n\n\n\n\n\nDapla-manualen er initiert og skrevet av Team Statistikktjenester i SSB. Bidragsytere er Ã˜yvind Bruer-SkarsbÃ¸, Miles Winther, BjÃ¸rn Andre Skaar, Anders Lunde og Damir Medakovic. Ved behov for oppdateringer og nytt innhold hÃ¥per vi at alle i SSB kan bidra."
  },
  {
    "objectID": "jupyter-pa-bakken.html",
    "href": "jupyter-pa-bakken.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Jupyterlab pÃ¥ bakken"
  },
  {
    "objectID": "gjenopprette-data.html",
    "href": "gjenopprette-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Alle bÃ¸tter har automatisk versjonering. Dette gjÃ¸r det mulig Ã¥ tilbakefÃ¸re filer til en tidligere versjon eller gjenopprette filer som er slettet ved et uhell.\nLogg inn pÃ¥ Google Cloud Console og sÃ¸k opp â€œCloud Storageâ€ i sÃ¸kefeltet. Klikk pÃ¥ den bÃ¸tten hvor filen er lagret under â€œBucketsâ€.\n\n\nFra Cloud Storage skjermbildet kan man navigere seg frem til den mappen hvor filen tidligere er lagret og skru pÃ¥ radioknappen â€œShow deleted dataâ€ (FigurÂ 1)\n\n\n\nFigurÂ 1: Skru pÃ¥ visning av slettede filer\n\n\nNÃ¥ vil man kunne se slettede filer i kursiv med teksten (Deleted) pÃ¥ slutten. Kolonnen â€œVersion historyâ€ vil ogsÃ¥ vise hvor mange tidligere versjoner som finnes av denne filen. Trykk pÃ¥ filnavnet du Ã¸nsker Ã¥ gjenopprette og velg deretter fanen â€œVersion historyâ€. I listen av versjoner til denne filen har man mulighet til Ã¥ gjenopprette til en tidligere versjon ved Ã¥ klikke pÃ¥ â€œRestoreâ€ (FigurÂ 2).\n\n\n\nFigurÂ 2: Gjenoppretting av en slettet fil\n\n\n\n\n\nFra Cloud Storage skjermbildet kan man navigere seg frem til den mappen hvor filen er lagret, og trykke pÃ¥ filnavnet. Velg deretter fanen â€œVersion historyâ€. I listen av versjoner til denne filen har man mulighet til Ã¥ gjenopprette til en tidligere versjon ved Ã¥ klikke pÃ¥ â€œRestoreâ€ (FigurÂ 3).\n\n\n\nFigurÂ 3: Versjonshistorikk til en fil"
  },
  {
    "objectID": "kildedata.html",
    "href": "kildedata.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Kildedata\n\nKildedata er data lagret slik de ble levert til SSB fra dataeier, det vil si pÃ¥ dataeiers dataformat og med informasjon om tidspunkt og rekkefÃ¸lge for avlevering. Kildedata er en del av statistikkenes dokumentasjon, og kan vÃ¦re en nÃ¸dvendig kilde for forskning og nye statistikker. Uten kildedataene vil det ikke vÃ¦re mulig Ã¥ etterprÃ¸ve SSB sine statistikker. De originale kildedataene vil ofte komprimeres og krypteres etter at relevante deler er transformert til inndata.\n\n(Standardutvalget 2021, 7)\n\nStatistikkloven Â§ 9 Informasjonssikkerhet stiller krav om at direkte identifiserende opplysninger skal behandles og lagres adskilt fra Ã¸vrige opplysninger, med mindre det vil vÃ¦re uforenlig med formÃ¥let med behandlingen eller Ã¥penbart unÃ¸dvendig. I henhold til policy om Datatilstander er kildedata i utgangspunktet den eneste datatilstanden som kan inneholde denne type data. I Ã¸vrige tilstander skal direkteidentifiserende opplysninger som hovedregel vÃ¦re pseudonymisert. Avvik skal dokumenteres og godkjennes av seksjonsleder som er ansvarlig for avviket.\n\n(DirektÃ¸rmÃ¸tet 2022, 2)\nFordi Kildedata kan inneholde PII1 implementerer Dapla fÃ¸lgende tiltak:\n\nKildedata er lagret adskilt fra andre datatilstander.\nTilgang til dataene begrenses sÃ¥ langt som mulig, kun en begrenset gruppe personer2 har tilgang til kildedata.\nProsessering av kildedata utfÃ¸res automatisk for minske behov for tilgang til dataene.\n\n\n\n\n\n\n\nReferanser\n\nDirektÃ¸rmÃ¸tet. 2022. â€œKlassifisering Og Tilgangsstyring PÃ¥ DAPLA.â€ Statistisk sentralbyrÃ¥. https://ssbno.sharepoint.com/:w:/r/sites/Statistikktjenester/Shared%20Documents/General/2022-37_Vedlegg_Klassifisering%20og%20tilgangsstyring_220912%20(002).docx?d=w7f261943752f4705b640d77071edde4d&csf=1&web=1&e=drd8On.\n\n\nStandardutvalget. 2021. â€œDatatilstander i SSB.â€ Statistisk sentralbyrÃ¥. https://ssbno.sharepoint.com/sites/Internedokumenter/Delte%20dokumenter/Forms/AllItems.aspx?id=%2Fsites%2FInternedokumenter%2FDelte%20dokumenter%2FInterne%20dokumenter%202021%2F2021%2D17%20Datatilstander%20i%20SSB%20%2Epdf&parent=%2Fsites%2FInternedokumenter%2FDelte%20dokumenter%2FInterne%20dokumenter%202021.\n\nFotnoter\n\n\nPersonidentifiserende Informasjonâ†©ï¸\nData adminsâ†©ï¸"
  },
  {
    "objectID": "virtual-env.html",
    "href": "virtual-env.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Et python virtuelt miljÃ¸ inneholder en spesifikk versjon av python og et sett med pakker. Pakkene er kun tilgjengelige nÃ¥r det virtuelle miljÃ¸et er aktivert. Dette gjÃ¸r at man ungÃ¥r avhengighetskonflikter pÃ¥ tvers av prosjekter.\nSe her for mer informasjon om virtuelle miljÃ¸er.\n\n\nDet er anbefalt Ã¥ benytte verktÃ¸yet poetry for Ã¥ administrere prosjekter og deres virtuelle miljÃ¸.\nPoetry setter opp virtuelt miljÃ¸, gjÃ¸r det enkelt Ã¥ oppdatere avhengigheter, sette versjonsbegrensninger og reprodusere prosjektet.\nPoetry gjÃ¸r dette ved Ã¥ lagre avhengigheters eksakte versjon i prosjektets â€œpoetry.lockâ€. Og eventuelle begrensninger i â€œpyproject.tomlâ€. Dette gjÃ¸r det enkelt for andre Ã¥ bygge prosjektet med akkurat de samme pakkene og begrensningene."
  },
  {
    "objectID": "jupyter-kernel.html",
    "href": "jupyter-kernel.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Jupyter-kernels"
  },
  {
    "objectID": "introduksjon.html",
    "href": "introduksjon.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Introduksjon\nMÃ¥let med dette kapittelet er Ã¥ gi en grunnleggende innfÃ¸ring i hva som legges i ordet Dapla. I tillegg gis en forklaring pÃ¥ hvorfor disse valgene er tatt."
  },
  {
    "objectID": "innlogging.html",
    "href": "innlogging.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Innlogging pÃ¥ Dapla er veldig enkelt. Dapla er en nettadresse som alle SSB-ere kan gÃ¥ inn pÃ¥ hvis de er logget pÃ¥ SSB sitt nettverk. Ã… vÃ¦re logget pÃ¥ SSB sitt nettverk betyr i denne sammenhengen at man er logget pÃ¥ med VPN, enten man er pÃ¥ kontoret eller pÃ¥ hjemmekontor. For Ã¥ gjÃ¸re det enda enklere har vi laget en fast snarvei til denne nettadressen pÃ¥ vÃ¥rt intranett/ByrÃ¥nettet(se FigurÂ 1).\n\n\n\nFigurÂ 1: Snarvei til Dapla fra intranett\n\n\nMen samtidig som det er lett Ã¥ logge seg pÃ¥, sÃ¥ er det noen kompliserende ting som fortjener en forklaring. Noe skyldes at vi mangler et klart sprÃ¥k for Ã¥ definere bakkemiljÃ¸et og skymiljÃ¸et slik at alle skjÃ¸nner hva man snakker om. I denne boken definerer bakkemiljÃ¸et som stedet der man har drevet med statistikkproduksjon de siste tiÃ¥rene. SkymiljÃ¸et er den nye dataplattformen Dapla pÃ¥ Google Cloud.\nDet som gjÃ¸r ting litt komplisert er at vi har 2 Jupyter-miljÃ¸er pÃ¥ bÃ¥de bakke og sky. Ã…rsaken er at vi har ett test- og ett prod-omrÃ¥de for hver, og det blir i alt 4 Jupyter-miljÃ¸er. FigurÂ 2 viser dette.\n\n\n\nFigurÂ 2: De 4 Jupyter-miljÃ¸ene i SSB. Et test-miljÃ¸ og et prod-miljÃ¸ pÃ¥ bakke og sky/Dapla\n\n\nHver av disse miljÃ¸ene har sin egen nettadresse og sitt eget bruksomrÃ¥de.\n\n\nI de fleste tilfeller vil en statistikker eller forsker Ã¸nske Ã¥ logge seg inn i prod-miljÃ¸et. Det er her man skal kjÃ¸re koden sin i et produksjonslÃ¸p som skal publiseres eller utvikles. I noen tilfeller hvor man ber om Ã¥ fÃ¥ tilgjengliggjort en ny tjeneste sÃ¥ vil denne fÃ¸rst rulles ut i testomrÃ¥det som vi kaller staging-omrÃ¥det. Ã…rsaken er at vi Ã¸nsker Ã¥ beskytte prod-miljÃ¸et fra software som potensielt Ã¸delegger for eksisterende funksjonalitet. Derfor ruller vi ut nye ting i staging fÃ¸rst. Av den grunn vil de fleste oppleve Ã¥ bli bedt om Ã¥ logge seg inn der for testing en eller annen gang. Under forklarer vi hvordan man gÃ¥r frem for Ã¥ logge seg pÃ¥ de to ulike miljÃ¸ene pÃ¥ Dapla.\n\n\nFor Ã¥ logge seg inn inn i prod-miljÃ¸et pÃ¥ Dapla kan man gjÃ¸re fÃ¸lgende:\n\nGÃ¥ inn pÃ¥ lenken https://jupyter.dapla.ssb.no/ i en Chrome-nettleser eller klikk pÃ¥ lenken pÃ¥ ByrÃ¥nettet som vist i FigurÂ 1.\nAlle i SSB har en Google Cloud-konto som mÃ¥ brukes nÃ¥r man logger seg pÃ¥ Dapla. Brukernavnet i Google er det samme som din korte epost-adresse (f.eks. cth@ssb.no). Hvis du ikke allerede er logget inn i Google vil du fÃ¥ spÃ¸rsmÃ¥l om Ã¥ velge hvilken Google-konto som skal brukes (FigurÂ 3). Logg inn med din Google-konto (ssb.no) og ditt AD-passord.\n\n\n\n\nFigurÂ 3: Velg en Google-konto\n\n\n\nDeretter blir man spurt om man godtar at ssb.no (altsÃ¥ Dapla) kan bruke din Google Cloud-konto (FigurÂ 4). Trykk Allow.\n\n\n\n\nFigurÂ 4: Tillat at ssb.no fÃ¥r bruke din Google Cloud-konto\n\n\n\nDeretter lander man pÃ¥ en side som lar deg avgjÃ¸re hvor mye maskinkraft som skal holdes av til deg (FigurÂ 5). Det Ã¸verste alternativet er valgt som standard, og er tilstrekkelig for de fleste.\n\n\n\n\nFigurÂ 5: Velg hvor mye maskinkraft du trenger\n\n\n\nVent til maskinen din starter opp (FigurÂ 6). Oppstartstiden kan variere.\n\n\n\n\nFigurÂ 6: Starter opp Jupyter\n\n\nEtter dette er man logget inn i et Jupyter-miljÃ¸ som kjÃ¸rer pÃ¥ en minimal Ubuntu-maskin. Hvis man er del av et Dapla-team fÃ¥r man ogsÃ¥ tilgang til alt teamet har tilgang til.\n\n\n\nInnlogging til staging-miljÃ¸et er identisk med innloggingen til prod-miljÃ¸et, med ett viktig unntak: nettadressen er nÃ¥ https://jupyter.dapla-staging.ssb.no/.\nLitt mer om hva som er tilgjenglig her kommer.\n\n\n\n\nJupyter-miljÃ¸et pÃ¥ bakken bruker samme base-image1 for Ã¥ installere Jupyterlab, og er derfor identisk pÃ¥ mange mÃ¥ter. Men innloggingen er ganske forskjellig.\n\n\n\n\n\n\nMerk\n\n\n\nFom. 5. desember 2022 har vi byttet ut Jupyter-miljÃ¸et pÃ¥ bakken. Beskrivelsene under gjelder derfor det nye miljÃ¸et. Fram til 15. januar vil du kunne bruke det gamle miljÃ¸et ved Ã¥ gÃ¥ inn pÃ¥ lenken https://jupyter-prod.ssb.no/ manuelt i Google Chrome. Etter 15. januar blir det gamle Jupyter-miljÃ¸et avviklet.\n\n\n\n\nDu logger deg inn pÃ¥ prod i bakkemiljÃ¸et pÃ¥ fÃ¸lgende mÃ¥te:\n\nLogg deg inn pÃ¥ Citrix-Windows i bakkemiljÃ¸et. Det kan gjÃ¸res ved Ã¥ bruke lenken Citrix pÃ¥ ByrÃ¥nettet, som ogsÃ¥ vises i FigurÂ 1.\nTrykk pÃ¥ Jupyterlab-ikonet, som vist pÃ¥ (jupyter-icon?), og logg deg inn med vanlig brukernavn og passord.\n\n\n\n\nJupyterlab-ikon pÃ¥ Skrivebordet i Citrix-Windows.\n\n\nNÃ¥r du trykker pÃ¥ ikonet blir du tatt til nettadressen https://sl-jupyter-p.ssb.no/. Du kunne ogsÃ¥ Ã¥pnet Jupyterlab ved Ã¥pne Chrome-nettleseren og skrive inn adressen manuelt.\n\n\n\nInnlogging til staging-miljÃ¸et har ingen snarvei pÃ¥ Skrivebordet, og du mÃ¥ gjÃ¸re fÃ¸lgende for Ã¥ Ã¥pne miljÃ¸et:\n\nÃ…pne Chrome-nettleseren i Citrix-Windows.\nSkriv inn url-en https://sl-jupyter-t.ssb.no/"
  },
  {
    "objectID": "remote.html",
    "href": "remote.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Forklare situasjonen nÃ¥. Kun Jupyterlab. Kan kjÃ¸re remote session med Rstudio, Pycharm og VSCode."
  },
  {
    "objectID": "bakke-sky.html",
    "href": "bakke-sky.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Bakke vs.Â sky"
  },
  {
    "objectID": "opprette-dapla-team.html",
    "href": "opprette-dapla-team.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Opprette Dapla-team\nFor Ã¥ komme i gang med Ã¥ opprette et Dapla-team trengs det en oversikt over teamets medlemmer og hvilke tilgangsgrupper medlemmene skal vÃ¦re med i. Det trengs ogsÃ¥ informasjon om hvilke Dapla-tjenester som er aktuelle for teamet Ã¥ ta i bruk. Derfor har det blitt opprettet en egen veileder for dette kalt Dapla Start.\n\n\n\n\n\n\nGÃ¥ til Dapla Start for starte bestilling av et nytt Dapla-team.\n\n\n\nNÃ¥r teamet er opprettet fÃ¥r alle medlemmene tilgang til sitt eget prosjekt i Google Cloud Platform (GCP), som er SSBs leverandÃ¸r av skytjenester. Videre fÃ¥r hvert prosjekt et sett med tjenester og tilganger som knyttes til teamet. Det opprettes ogsÃ¥ datalagringsomrÃ¥der (kalt bÃ¸tter) som bare kan aksesseres av brukere som er med i teamets tilgangsgrupper.\nDapla-teamet vil ogsÃ¥ fÃ¥ sin egen gruppe i SSBs Active Directory slik at medlemskapet i gruppen kan administreres av Kundeservice."
  },
  {
    "objectID": "administrasjon.html",
    "href": "administrasjon.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "I dette kapitlet viser vi hvordan du kan gjÃ¸re endringer i et eksisterende team. Typiske endringer er Ã¥:\n\nLegge til eller fjerne medlemmer i et team\nListe ut medlemmer og tilgangsgrupper i et team\n\nMer kommer snart.\n\n\nFor Ã¥ legge til eller fjerne medlemmer i et team mÃ¥ du forelÃ¸pig opprette en Kundeservice-sak. Oppgi navnet pÃ¥ teamet du Ã¸nsker Ã¥ endre pÃ¥ og hvilke medlemmer du Ã¸nsker Ã¥ legge til eller fjerne. Oppgi ogsÃ¥ hvilken tilgangsgruppe medlemmene skal ha (data-admins, developers eller consumers).\nEndringer i team mÃ¥ godkjennes av seksjonsleder fÃ¸r de blir gjort.\n\n\n\n\n\n\nMidlertidig lÃ¸sning\n\n\n\nAt endringer i team mÃ¥ gjÃ¸res via Kundeservice er midlertidig. Det jobbes med Ã¥ lage et eget verktÃ¸y for dette.\n\n\n\n\n\nFor Ã¥ se hvem som har hvilke tilganger i et Dapla-team sÃ¥ kan du gÃ¥ inn pÃ¥ Azure Active directory. Her fÃ¥r du se en oversikt over alle Dapla-team, hvem som er medlemmer, og hvilken tilgangsrolle de har.\nAnta at vi Ã¸nsker Ã¥ se hvilke SSB-ansatte som har tilgang til teamet skatt-person. Da kan vi gjÃ¸re fÃ¸lgende:\n\nGÃ¥ inn pÃ¥ nettsiden til Azure Active directory.\nSkriv inn skatt-person i sÃ¸kefeltet slik som vist i FigurÂ 1.\n\n\n\n\nFigurÂ 1: Nettsiden til Azure Active directory.\n\n\nFigurÂ 1 viser at det finnes 5 tilgangsroller knyttet til et Dapla-team:\n1. managers (benyttes ikke enda)\n2. support (benyttes ikke enda)\n3. developers\n4. consumers\n5. data-admins\nI realiteten er det bare data-admin og developer som er aktuelle tilgangsroller for Ã¥ produsere statistikk i Dapla-teamet. consumers-rollen innehas av folk fra andre Dapla-team som skal ha tilgang til data i din delt-bÃ¸tte.\n\nHvis jeg Ã¸nsker Ã¥ se hvem som er data-admins i teamet skatt-person, sÃ¥ kan jeg trykke pÃ¥ skatt-person-data-admins, og derettes trykke pÃ¥ Members i menyen til venstre. Da fÃ¥r jeg opp en liste over alle som har tilgang til data-admins i Dapla-teamet skatt-person."
  },
  {
    "objectID": "lese-data.html",
    "href": "lese-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Skal man lese fra en bÃ¸tte mÃ¥ man autentisere seg. For Ã¥ gjÃ¸re dette kan man benytte pakken dapla-toolbelt.\n\n\n\n\n\n\n\n\nâ€œnavn-boetteâ€ eksisterer ikke og mÃ¥ byttes med en reel bÃ¸tte.\n\n\n\nLes json fil fra bÃ¸tte:\nimport dapla as dp\n\ndata_frame = dp.read_pandas(\"gs://ssb-staging-navn-boette/schema.json\",\n file_format=\"json\")\nList ut mapper i bÃ¸tta:\nfrom dapla import FileClient\n\nFileClient.ls(\"gs://ssb-staging-navn-boette/\")\n\n\n\n\n\nEn vanlig Ã¥rsak til feil er at man forsÃ¸ker Ã¥ lese data fra et annet miljÃ¸ enn det man befinner seg i. Sjekk at url feltet i nettleseren stemmer overens med bÃ¸ttene man forsÃ¸ker Ã¥ aksessere.\nStagingbÃ¸tter starter med: gs://ssb-staging-\nProduksjonsbÃ¸tter starter med: gs://ssb-prod-\n\n\n\n\n\n\nI https://jupyter.dapla-staging.ssb.no/ kan man ikke lese produksjonsbÃ¸tter.\n\n\n\n\n\n\n\n\n\nI https://jupyter.dapla.ssb.no/ kan man ikke lese stagingbÃ¸tter.\n\n\n\n\n\n\nNoen ganger kan en restart av Jupyter lÃ¸se problemet.\nI Jupyters filmeny velg: fil -> Hub Controll Panel.\nTrykk pÃ¥ knappen â€œStop My Serverâ€. Etter dette kan man trykke knappen â€œStart My Serverâ€.\n\n\n\nStop My Server\n\n\n\n\n\nHvis man fortsatt ikke har tilgang, kan man opprette en TMS sak. For at vi lettes mulig skal kunne hjelpe bÃ¸r saken inneholde full feilmelding & relevant kode."
  },
  {
    "objectID": "ordforklaringer.html",
    "href": "ordforklaringer.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Ordforklaringer\n\nbip\nbip er det tidligere navnet pÃ¥ den underliggende plattformen som SSB bygger i GCP, hovedsakelig ment for utviklere som bygger tjenester pÃ¥ Dapla. Plattformen skulle vÃ¦re selvbetjent for utviklere og basert pÃ¥ DevOps-prinsipper. bip eksisterer fortsatt, men er nÃ¥ blitt en del av det stÃ¸rre begrepet dapla.\n\n\nbucket\nbucket (eller bÃ¸tte pÃ¥ norsk) er en lagringsenhet pÃ¥ Dapla. Det ligner litt pÃ¥ en klassisk diskstasjon, for eksempel X-disken eller C-disken pÃ¥ en lokal maskin. I en bÃ¸tte kan det ligge undermapper slik som i et klassisk filsystem.\n\n\nconsumer\nconsumer er en AD-gruppe som gir tilgang til et Dapla-team sin delt-bÃ¸tte. En SSB-ansatt som skal bruke data fra et Dapla-team mÃ¥ vÃ¦re medlem av consumer-gruppen til det aktuelle Dapla-teamet.\n\n\ndapla\nDapla er et akronym for den nye dataplattformen til SSB, der Da stÃ¥r for Data og pla stÃ¥r for Plattform. Dapla er en plattform for lagring, prosessering og deling av SSB sine data. Den bestÃ¥r bÃ¥de av Jupyter-miljÃ¸et, som er et verktÃ¸y for Ã¥ utfÃ¸re beregninger og analysere data, og et eget omrÃ¥de for lagre data. I tillegg inkluderer begrepet Dapla ogsÃ¥ en rekke andre verktÃ¸y som er nÃ¸dvendige for Ã¥ kunne bruke plattformen.\n\n\ndapla-team\nKommer snart.\n\n\ndapla-toolbelt\nKommer snart.\n\n\ndata-admin\ndata-admin er en AD-gruppe som gir de videste tilgangene i et dapla-team. En SSB-ansatt som har data-admin-rollen i et Dapla-team har tilgang til alle bÃ¸tter for det teamet, inkludert kilde-bÃ¸tta som kan inneha sensitive data.\nKommer snart.\n\n\ndapla-start\n*dapla-start** er et brukergrensesnitt der SSB-ansatte kan sÃ¸ke om Ã¥ fÃ¥ opprettet et nytt dapla-team.\n\n\ndelt-bÃ¸tte\nKommer snart.\n\n\ndeveloper\nKommer snart.\n\n\nPersonidentifiserende Informasjon (PII)\nPII er variabler som kan identifisere en person i et datasett.\nMer informasjon finnes hos Datatilsynet.\n\n\ngoogle cloud platform (gcp)\nAllmenn skyplattform utviklet og levert av Google. Konkurrent med Amazon Web Services (AWS) og Microsoft Azure. Dapla primÃ¦rt benytter seg av tjenester pÃ¥ GCP.\nVideo som forklarer hva GCP er.\n\n\ngcp\nForkortelse for Google Cloud Platform. Se forklaring under google cloud platform (GCP).\n\n\nInfrastructure as Code (IaC)\nInfrastuktur som kode pÃ¥ norsk. Kode som defineres ressurser, typisk pÃ¥ en allmenn skyplatform som GCP. Eksempler av ressurser er bÃ¸tter, databaser, virtuelle maskiner, nettverk og sikkerhetsregler.\n\n\nkilde-bÃ¸tte\nKommer snart.\n\n\nprodukt-bÃ¸tte\nKommer snart.\n\n\nPull Request (PR)\nEn PR er en Github konsept, som gir et forum for kodegjennomgang, diskusjon og ikke minst dokumentasjon av kodeendringer.\nDette er anbefalt av KVAKK som mÃ¥ten Ã¥ endre kode pÃ¥ i SSB.\n\n\nssb-project\nKommer snart.\n\n\ntransfer service\nKommer snart.\n\n\nPyflakes\nPyflakes er et enkelt kodeanalyseverktÃ¸y som finner feil i Python kode. Les mer om Pyflakes pÃ¥ deres PyPi side"
  },
  {
    "objectID": "pakke-install-bakken.html",
    "href": "pakke-install-bakken.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Installering av pakker i Jupyter miljÃ¸er pÃ¥ bakken (f.eks https://sl-jupyter-p.ssb.no) foregÃ¥r stort sett helt lik som pÃ¥ Dapla. Det er Ã©n viktig forskjell, og det er at installasjon skjer via en proxy som heter Nexus.\n\n\nPip er ferdig konfigurert for bruk av Nexus og kan kjÃ¸res som beskrevet for Dapla\n\n\n\nHvis man bruker Poetry for hÃ¥ndtering av pakker i et prosjekt, sÃ¥ mÃ¥ man kjÃ¸re fÃ¸lgende kommando i prosjekt-mappe etter prosjektet er opprettet.\npoetry source add --default nexus `echo $PIP_INDEX_URL`\nDa fÃ¥r man installere pakker som vanlig f.eks\npoetry add matplotlib\n\n\n\n\n\n\nHvis man forsÃ¸ker Ã¥ installere prosjektet i et annet miljÃ¸ (f.eks Dapla), sÃ¥ mÃ¥ man fjerner nexus kilden ved Ã¥ kjÃ¸re\npoetry source remove nexus\n\n\n\n\n\n\n\nProsessen med Ã¥ installere pakker for R pÃ¥ bakken er det samme som pÃ¥ Dapla. Noen pakker (for eksempel arrow og devtools) kan forelÃ¸pig ikke installeres pÃ¥ bakken pÃ¥ egenhÃ¥nd pga 3. parti avhengigheter. Vi jobber med Ã¥ finne en lÃ¸sning til dette."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Referanser"
  },
  {
    "objectID": "datadoc.html",
    "href": "datadoc.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "For Ã¥ kunne gjenfinne data i SSB er man helt avhengig av at det finnes et enhetlig system for metadata knyttet til dataene. DataDoc er SSBs system for Ã¥ dokumentere datasett pÃ¥ den nye dataplattformen Dapla.\nDet er bygget et grensesnitt i Python for Ã¥ gjÃ¸re det enklest mulig Ã¥ dokumentere et datasett. ForelÃ¸pig stÃ¸tter lÃ¸sningen fÃ¸lgende filformater:\n\nparquet\nsas7bdat\n\nUnder finner du beskrivelse av hvordan du kan begynne Ã¥ bruke lÃ¸sningen til Ã¥ dokumentere datasett.\n\n\n\n\n\n\nAdvarsel\n\n\n\nVi Ã¸nsker at du skal teste DataDoc-applikasjonen. Den viktigste funksjonaliteten skal vÃ¦re tilgjengelig, og det er fullt mulig Ã¥ benytte DataDoc i SSBs Jupyter-miljÃ¸er. Det er imidlertid viktig Ã¥ vÃ¦re klar over at applikasjonen fortsatt er i en utviklings- og testfase (beta-lÃ¸sning) og kan inneholde feil og mangler.\nHar du spÃ¸rsmÃ¥l, eventuelt vil rapporterer om feil og mangler, sÃ¥ setter vi pris pÃ¥ om du gjÃ¸r dette i Yammer-gruppa Dapla.\n\n\n\n\nFÃ¸r du tar i bruk DataDoc-applikasjonen er det viktig Ã¥ forstÃ¥ hvilken informasjon som skal til for Ã¥ dokumentere et datasett. I DataDoc-applikasjonen skal du fylle ut flere felter om bÃ¥de datasettet og variablene som inngÃ¥r i datasettet, eksempelvis\n\nkortnavn\nnavn\ndatatilstand\npopulasjonsbeskrivelse\n++\n\nDet er utarbeidet en detaljert beskrivelse hva hvert felt betyr, og hvordan de skal fylles ut bÃ¥de for datasett og variabler: - DataDoc - hvordan dokumentere et datasett - DataDoc - hvordan dokumentere variablene (variabelforekomstene) som inngÃ¥r i datasettet\nDataDoc skal vÃ¦re installert i alle Jupyter-miljÃ¸ene i SSB, sÃ¥ du trenger ikke installere pakken selv.\n\n\n\n\n\n\nViktig informasjon\n\n\n\nDataDoc kan forelÃ¸pig ikke kjÃ¸res i Jupyter notebook med virtuelle miljÃ¸er (f.eks. et ssb-project), men mÃ¥ startes i den vanlige kernelen i en notebook.\n\n\n\n\n\nLa oss lage et test-datasett slik at vi kan leke oss litt med DataDoc:\nimport pandas as pd\nfrom datadoc import main\n  \n# Create fake data\ndata = {'id': ['9999999999', '8888888888', '7777777777', '6666666666'],\n        'fylke': [\"01\", \"02\", \"03\", \"03\"],\n        'inntekt': [500000, 250000, 400000, 440000],\n        'rente': [3.2, 4.1, 3.3, 3.4]}\n  \n# Creates a Pandas dataframe\ndf = pd.DataFrame(data)\n\n# Write a Parquet-file to current folder\ndf.to_parquet(\"./test.parquet\")\nNÃ¥ har vi en fil som heter test.parquet i mappen vi stÃ¥r. Da kan vi Ã¥pne DataDoc-grensesnittet for Ã¥ legge inn metadataene:\nmain(\"./test.parquet\")\nFigurÂ 1 viser hvordan DataDoc-grensesnittet ser ut.\n\n\n\nFigurÂ 1: Gif som viser hvordan DataDoc-grensesnittet ser ut.\n\n\n\n\n\nNÃ¥r du trykker pÃ¥ Lagre-knappen i DataDoc sÃ¥ skrives alle metadata til en fil i samme mappe (katalog) som datafilen. Dette er en JSON-fil med nesten samme navn som datafilen. Navnekonvensjonen for metadatafilen er\n<navn pÃ¥ datafil uten endelse>__DOC.json\nEksempelvis hvis datafilen har navnet skattedata_p2022_v1.parquet, sÃ¥ vil DataDoc lagre metadata i filen skattedata_p2022_v1__DOC.json.\nFordelen med Ã¥ benytte en JSON-fil til Ã¥ lagre metadata er at denne filen kan kopieres og flyttes like enkelt som selve datafilen. JSON-filer er strukturerte tekstfiler som kan leses av bÃ¥de maskiner (Python/R) og av mennesker (Ã¥pnes i en tekst-editor).\nSe et eksempel pÃ¥ JSON metadata-fil lagret av DataDoc.\n\n\n\n\n\n\nInformasjon\n\n\n\nI Dapla skal det bygges en felles datakatalog for SSB. Tanken er at alle metadata, eksempelvis datasett-dokumentasjon fra DataDoc (JSON-filene), skal inngÃ¥ i SSBs datakatalog. Datakatalogen gjÃ¸r det mulig Ã¥ finne (sÃ¸ke etter), forstÃ¥r og gjenbruke data bÃ¥de internt og ekstern."
  },
  {
    "objectID": "dapla-team.html",
    "href": "dapla-team.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Opprette Dapla-team\nI forrige del beskrev vi noen grunnleggende ting rundt Dapla. I denne delen tar vi for oss hvordan du kan begynne Ã¥ jobbe med skarpe data pÃ¥ plattformen.\nKapittelet som beskriver hvordan man logger seg inn pÃ¥ Dapla vil fungere uten at du mÃ¥ gjÃ¸re noen forberedelser. Er man koblet pÃ¥ SSB sitt nettverk sÃ¥ vil alle SSB-ansatte kunne gÃ¥ inn pÃ¥ plattformen og kode i Python og R. Men du fÃ¥r ikke tilgang til SSBs omrÃ¥de for datalagring pÃ¥ plattformen. I praksis vil det si at man kan generere data med kode, men man kan ikke jobbe med skarpe data.\nFor Ã¥ fÃ¥ muligheten til Ã¥ jobbe med skarpe data MÃ… du fÃ¸rst opprette et dapla-team. Dette er det fÃ¸rste naturlige steget Ã¥ ta nÃ¥r man skal begynne Ã¥ jobbe med statistikkproduksjon pÃ¥ Dapla. I dette kapittelet vil vi forklare det du trenger Ã¥ vite om det Ã¥ opprette og jobbe innenfor et team."
  },
  {
    "objectID": "jupyterlab.html",
    "href": "jupyterlab.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Mer kommer.\n\n\n\nMÃ¥ nevne operativsystemet og at noe programvare ligger installert her (git, jwsacruncher, quarto, ++)\n\n\n\nNoe er i base-image, noe bÃ¸r gjÃ¸res i virtuelle milÃ¸er. Hvordan liste ut pakker som er pre-installert?\n\n\n\nJupyterlab er en samling extension. Kan bare installeres av admin. Sikkerhet. Hvilke extension har vi tilgjengeliggjort?\n\n\n\nSane defaults for Jupyterlab."
  },
  {
    "objectID": "hva-er-dapla.html",
    "href": "hva-er-dapla.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "Hva er Dapla?\nDapla stÃ¥r for dataplattform, og er en skybasert lÃ¸sning for statistikkproduksjon og forskning."
  },
  {
    "objectID": "jobbe-med-data.html",
    "href": "jobbe-med-data.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "NÃ¥r vi oppretter et dapla-team sÃ¥ fÃ¥r vi tildelt et eget omrÃ¥det for lagring av data. For Ã¥ kunne lese og skrive data fra Jupyter til disse omrÃ¥dene mÃ¥ vi autentisere oss, siden Jupyter og lagringsomrÃ¥det er to separate sikkerhetsoner.\nFigurÂ 1 viser dette klarer skillet mellom hvor vi koder og hvor dataene ligger pÃ¥ Dapla1. I dette kapitlet beskriver vi nÃ¦rmere hvordan du kan jobbe med dataene dine pÃ¥ Dapla.\n\n\n\nFigurÂ 1: Tydelig skille mellom kodemiljÃ¸ og datalagring pÃ¥ Dapla.\n\n\n\n\nFor Ã¥ gjÃ¸re det enklere Ã¥ jobbe data pÃ¥ tvers av Jupyter og lagringsomrÃ¥det er det laget noen egne SSB-utviklede biblioteker for Ã¥ gjÃ¸re vanlige operasjoner mot lagringsomrÃ¥det. Siden bÃ¥de R og Python skal brukes pÃ¥ Dapla, sÃ¥ er det laget to biblioteker, en for hver av disse sprÃ¥kene. fellesr er biblioteket for R, og dapla-toolbelt er biblioteket for Python.\n\n\ndapla-toolbelt er en en pakke som lar deg enkelt lese og skrive til lagringsomrÃ¥det uten Ã¥ mÃ¥tte autentifisere deg manuelt. Den har en Pandas-aktig syntaks som forhÃ¥pentlig er gjenkjennbar for de fleste. Pakken er installert i alle Python-kernels pÃ¥ Dapla, sÃ¥ du trenger ikke Ã¥ installere den selv hvis du Ã¥pner en notebook med Python3 for eksempel. For Ã¥ importere hele biblioteket i en notebook skriver du bare\nimport dapla as dp\ndapla-toolbelt bruker en pakke som heter gcsfs for Ã¥ kommunisere med lagringsomrÃ¥det. gcsfs er en pakke som lar deg bruke Google Cloud Storage (GCS) som om det var en filsystem. Det betyr at du kan bruke samme syntaks som du bruker for Ã¥ lese og skrive til filer pÃ¥ din egen maskin. Du kan lese mulighetene i gcsfs her. Et eksempel pÃ¥ hvordan de to pakkene kan brukes sammen ser du her:\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Example of how you can use gcsfs and dapla-toolbelt together\nfs.mkdir(\"gs://my-bucket/my-folder\")\nI koden over brukte jeg kommandoen mkdir fra gcsfs og FileClient fra dapla-toolbelt for Ã¥ opprette en mappe i lagringsomrÃ¥det.\nI kapitlene under finner du konkrete eksempler pÃ¥ hvordan du kan bruke dapla-toolbelt til Ã¥ jobbe med data i SSBs lagringsomrÃ¥det.\n\n\n\nR-pakken fellesr er under utvikling og gir mye av den samme funksjonaliteten som dapla-toolbelt gir for Python. I tillegg til Ã¥ kunne lese og skrive til lagringsomrÃ¥det pÃ¥ Dapla, sÃ¥ har fellesr ogsÃ¥ funksjoner for Ã¥ jobbe med metadata pÃ¥ Dapla.\nfellesr er forelÃ¸pig ikke tilgjengeliggjort som en pakke som kan installeres. For Ã¥ bruke pakken kan du gjÃ¸re fÃ¸lgende:\n\nKopiere scriptet DAPLA_funcs.R og legg den i en fil sammen med Notebooken din\nI en R-notebook som ligger i samme mappe som filen DAPLA_funcs.R starter du med Ã¥ skrive\n\nsource(\"DAPLA_funcs.R\")\nDa er alle funksjonene tilgjengelig for deg i Notebooken din.\n\n\n\n\n\n\n\n\n\n\nEksempeldata\n\n\n\nDet finnes et omrÃ¥de som alle SSB-ansatte har lese- og skrivetilgang til. Det er\ngs://ssb-prod-dapla-felles-data-delt/ i prod-miljÃ¸et pÃ¥ Dapla, og\ngs://ssb-staging-dapla-felles-data-delt/ i staging-miljÃ¸et. Eksemplene under bruker fÃ¸rstnevnte i koden, slik at alle kan kjÃ¸re koden selv.\nKode-eksemplene finnes for bÃ¥de R og Python, og du kan velge hvilken du skal se ved Ã¥ trykke pÃ¥ den arkfanen du er interessert i.\n\n\nÃ… liste ut innhold i et gitt mappe pÃ¥ Dapla er ganske enkelt. Under ser du hvordan du kan liste ut innholdet i fÃ¸lgende mappe:\ngs://ssb-prod-dapla-felles-data-delt/felles/veiledning/python/eksempler/purchases\n\nPython \n\n\nVi bruker modulen FileClient fra dapla-toolbelt for Ã¥ liste ut innholdet i en mappe.\nfrom dapla import FileClient\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\nFileClient.ls(f\"{bucket}/{folder}\")\nMed kommandoen over fÃ¥r du listet ut alle filnavn i mappen. Hvis du vil ha mer informasjon om filene sÃ¥ kan du bruke ls-kommandoen med detail = True, som under:\nFileClient.ls(f\"{bucket}/{folder}\", detail = True)\nSyntaksen med ls er veldig lik det man kjenner fra en Linux-terminal. Men nÃ¥r vi bruker detail = True blir metadata om filene returnert som en Python-liste med dictionaries. Det kan vÃ¦re svÃ¦rt nyttig nÃ¥r du f.eks. trenger Ã¥ vite dato og tidspunkt for nÃ¥r en fil ble opprettet, eller nÃ¥r den sist ble oppdatert.\n\n\n# Loading functions into notebook\nsource(\"DAPLA_funcs.R\")\n\n# Path to folder\nbucket <- \"ssb-prod-dapla-felles-data-delt/\"\nfolder <- \"felles/veiledning/python/eksempler/purchases\"\n\n# List files in folder \nlist.files(paste0(bucket, folder))\n\n\n\n\n\n\nÃ… skrive filer til et lagringsomrÃ¥de pÃ¥ Dapla er ogsÃ¥ ganske enkelt. Det ligner mye pÃ¥ den syntaksen vi er kjent med fra vanlige R- og Python-pakker, med noen smÃ¥ unntak.\n\n\nUnder lager vi en dataframe i en notebook og skriver den ut til en parquet-fil. Stien vi skriver til er\ngs://ssb-prod-dapla-felles-data-delt/felles/veiledning/python/eksempler/purchases:\n\nPython \n\n\nNÃ¥r vi leser en Parquet-fil med dapla-toolbelt sÃ¥ bruker den pyarrow i bakgrunnen. Dette er en av de raskeste mÃ¥tene Ã¥ lese og skrive Parquet-filer pÃ¥.\n\nimport dapla as dp\nimport pandas as pd\nimport numpy as np\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Create pandas dataframe\npurchases = pd.DataFrame(np.random.randn(10, 5),\n                        columns=[\"A\", \"B\", \"C\", \"D\", \"E\"])\n\n# Write pandas dataframe as parquet to GCS bucket\ndp.write_pandas(df = purchases,\n                gcs_path = f\"{bucket}/{folder}/data.parquet\",\n                file_format = \"parquet\",)\nNÃ¥r vi kalte write_pandas over sÃ¥ spesifiserte vi at filformatet skulle vÃ¦re parquet. Dette er default, sÃ¥ vi kunne ogsÃ¥ ha skrevet det slik:\ndp.write_pandas(df = purchases,\n                gcs_path = f\"{bucket}/{folder}/data.parquet\")\nMen for de andre filformatene mÃ¥ vi altsÃ¥ spesifisere dette.\n\n\nKommer snart\n\n\n\n\n\n\nKommer snart eksempler pÃ¥ hvordan man kan skrive ut tekstfiler som CSV, JSON og XML.\n\nPython \n\n\ndapla-toolbelt kan skrive ut json, csv og posisjonsfiler (fixed-width-files/fwf) til lagringsomrÃ¥det. MÃ¥ten den gjÃ¸r det pÃ¥ er Ã¥ bruke Pandas sine funksjoner read_json, read_csv, read_fwf under panseret. Dette kan vÃ¦re nyttig Ã¥ vite for skjÃ¸nne hvordan dapla-toolbelt hÃ¥ndterer ulike strukturer i (spesielt hierarkiske) tekstfiler. Under ser du hvordan du kan skrive ut en dataframe til en json-fil.\nimport numpy as np\nimport pandas as pd\nfrom dapla import FileClient\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Create a dataframe with Pandas\ndf = pd.DataFrame(np.random.randn(10, 5), columns=[\"A\", \"B\", \"C\", \"D\", \"E\"])\n\n# Save dataframe as json with dapla-toolbelt\ndp.write_pandas(df = df,\n                gcs_path = f\"{bucket}/{folder}/test.json\",\n                file_format = \"json\")\nSom vi ser at syntaksen over sÃ¥ kunne vi skrevet ut til noe annet enn json ved Ã¥ endre verdien i argumentet file_format.\n\n\nKommer snart.\n\n\n\n\n\n\nDet er ikke anbefalt Ã¥ bruke xlsx-formatet, men her ser du hvordan det kan skrives ut. Mer kommer.\n\nPython \n\n\nimport pandas as pd\nfrom dapla import AuthClient\n\n# Henter token for Ã¥ kunne lese fra Dapla\ntoken = AuthClient.fetch_google_credentials()\n\n# Filsti\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\ndf.to_excel(f\"{bucket}/{folder}/test.xlsx\",\n           storage_options={\"token\": token})\n\n\nKommer snart\n\n\n\n\n\n\n\nÃ… lese inn filer pÃ¥ med dapla-toolbelt er nesten like rett frem som med Pandas. Under finner du eksempler pÃ¥ hvordan du kan lese inn data til en Jupyter Notebooks pÃ¥ Dapla.\n\n\n\nPython \n\n\nimport dapla as dp\n\n# Set path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Read path into pandas dataframe \ndp.read_pandas(gcs_path= f\"{bucket}/{folder}/data.parquet\",\n               file_format = \"parquet\",\n               columns = None,)\nSom vi sÃ¥ med write_pandas sÃ¥ er file_format default satt til parquet, og default for columns = None, sÃ¥ vi kunne ogsÃ¥ ha skrevet det slik:\ndp.read_pandas(gcs_path= f\"{bucket}/{folder}/data.parquet\")\ncolumns-argumentet er en liste med kolonnenavn som vi Ã¸nsker Ã¥ lese inn. Hvis vi ikke spesifiserer noen kolonner sÃ¥ vil alle kolonnene leses inn.\n\n\nKommer snart\n\n\n\n\n\n\nKommer mer snart. Python-koden under bygger pÃ¥ eksempelet over.\n\nPython \n\n\nimport dapla as dp\n\n# Path to write to\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\n# Read in json-file from dapla-storage\ndf = dp.read_pandas(gcs_path = f\"{bucket}/{folder}/test3.json\",\n               file_format = \"json\")\n\n\nKommer snart\n\n\n\n\n\n\n\nPython \n\n\nimport pandas as pd\nfrom dapla import AuthClient\n\n# Hent token\ntoken = AuthClient.fetch_google_credentials()\n\n# Les inn fil\ndf = pd.read_excel(\"gs://ssb-prod-arbmark-skjema-data-produkt/test_gcp.xlsx\",\n    storage_options={\"token\": token})\n\n\nKommer snart\n\n\n\n\n\n\n\nÃ… slette filer fra lagringsomrÃ¥det kan gjÃ¸res pÃ¥ flere mÃ¥ter. I kapitlet om sletting av data viste vi hvordan man gjÃ¸r det med pek-og-klikk i Google Cloud Console. Under ser du hvordan du kan slette filer med dapla-toolbelt og gcsfs.\n\nPython \n\n\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler/purchases\"\n\nfs.rm(f\"{bucket}/{from_folder}/df.json\")\n\n\nKommer snart\n\n\n\n\n\n\nÃ… kopiere filer mellom mapper pÃ¥ et Linux-filsystem innebÃ¦rer som regel bruke cp-kommandoen. PÃ¥ Dapla er det ikke sÃ¥ mye forskjell. Vi bruker en ligende tilnÃ¦rming nÃ¥ vi skal kopiere mellom bÃ¸tter eller mapper pÃ¥ lagringsomrÃ¥det til SSB. Under ser du hvordan du kan kopiere en fil fra en mappe til en annen.\n\nPython \n\n\nLa oss begynne med et eksempel der vi kopierer en fil fra en mappe til en annen i samme bÃ¸tte.\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Path to folders\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfrom_folder = \"felles/veiledning/python/eksempler/purchases\"\nto_folder = \"felles/veiledning/python/eksempler\"\n\n# Copy file\nfs.cp(f\"{bucket}/{from_folder}/data.parquet\",\n      f\"{bucket}/{to_folder}/data_copy.parquet\")\nDet ogsÃ¥ fungere for Ã¥ kopiere filer mellom bÃ¸tter.\nEt annet scenario vi ofte vil stÃ¸te pÃ¥ er at vi Ã¸nsker Ã¥ kopiere en fil fra vÃ¥r Jupyter-filsystem til en mappe pÃ¥ lagringsomrÃ¥det. Her kan vi bruke fs.put-metoden.\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Create a new file in your home directory called test.txt\nwith open('/home/jovyan/test.txt', 'w') as f:\n    f.write('Create a new text file!')\n\n#Path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler\"\n\n# Copy file from local to remote file system\nfs.put(lpath=f\"/home/jovyan/test.txt\", rpath=f\"{bucket}/{folder}/test.txt\")\nÃ˜nsker vi Ã¥ kopiere en hel mappe fra lagringsomrÃ¥det til Jupyter-filsystemet, kan vi bruke fs.get-metoden, med opsjonen recursive=True.\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n# Copy file\nfs.get(<from_bucket>,\n      \"/home/jovyan/sesongjustering/\",\n      recursive=True)\n\n\nKommer snart\n\n\n\n\n\n\n\nPython \n\n\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfrom_folder = \"felles/veiledning/python/eksempler/purchases\"\nto_folder = \"felles/veiledning/python/eksempler\"\n\nfs.mv(f\"{bucket}/{from_folder}/data.parquet\", f\"{bucket}/{to_folder}/data.parquet\")\n\n\nKommer snart\n\n\n\n\n\n\n\nPython \n\n\nfrom dapla import FileClient\nfs = FileClient.get_gcs_file_system()\n\n#Path to folder\nbucket = \"gs://ssb-prod-dapla-felles-data-delt\"\nfolder = \"felles/veiledning/python/eksempler\"\n\n# Create folder\nfs.mkdir(f\"{bucket}/{folder}/testmappe/\")\n\n\nKommer snart"
  },
  {
    "objectID": "pyspark-venv.html",
    "href": "pyspark-venv.html",
    "title": "Dapla-manual",
    "section": "",
    "text": "For Ã¥ kunne benytte det virtuelle miljÃ¸et i en notebook mÃ¥ man sette opp en kernel. Dette er beskrevet her. Denne kernelen er imidlertid ikke satt opp til Ã¥ bruke pyspark som standard, og for Ã¥ fÃ¥ til det mÃ¥ man gjÃ¸re noen manuelle steg.\n\n\nDenne kommandoen legger til pakken pyspark i prosjektet (med samme versjon som pÃ¥ jupyterlab).\npoetry add pyspark==$(pip show pyspark | grep Version | egrep -o \"([0-9]{1,}\\.)+[0-9]{1,}\")\n\n\n\nPyspark kan kjÃ¸res enten pÃ¥ lokal maskin eller pÃ¥ flere maskiner samtidig i en sÃ¥kalt klynge (cluster). Sistnevnte kan vÃ¦re mer effektivt Ã¥ bruke nÃ¥r man har stÃ¸rre mengder data, men det krever ogsÃ¥ mer konfigurasjon.\n\n\nOppsettet for Pyspark pÃ¥ lokal maskin er det enkleste Ã¥ sette opp siden Pyspark vil ha direkte tilgang til det lokale filsystemet. Man kan bruke miljÃ¸variabelen PYSPARK_PYTHON til Ã¥ peke pÃ¥ det virtuelle miljÃ¸et, og dermed vil Pyspark ogsÃ¥ ha tilgang til alle pakkene som er installert der. I en notebook vil dette kunne settes opp slik:\nimport os\nimport subprocess\n\n# Finner filstien til det virtuelle miljÃ¸et\npython_path = subprocess.run(['poetry', 'run', 'which', 'python'],\n                             capture_output=True, text=True).stdout.rstrip('\\n')\n\nos.environ[\"PYSPARK_PYTHON\"] = python_path\nos.environ[\"PYSPARK_SUBMIT_ARGS\"] = os.environ[\"PYSPARK_LOCAL_SUBMIT_ARGS\"]\nTil slutt mÃ¥ man kjÃ¸re et script for Ã¥ initialisere pyspark for lokal maskin:\n%run /usr/local/share/jupyter/kernels/pyspark_local/init.py\nDette scriptet vil sette et spark objekt som brukes for Ã¥ kalle APIâ€™et til pyspark.\n\n\n\nHvis man vil kjÃ¸re Pyspark i et cluster (dvs. pÃ¥ flere maskiner) sÃ¥ vil databehandlingen foregÃ¥ pÃ¥ andre maskiner som ikke har tilgang til det lokale filsystemet. Man mÃ¥ dermed lage en â€œpakkeâ€ av det virtuelle miljÃ¸et pÃ¥ lokal maskin og tilgjengeliggjÃ¸re dette for alle maskinene i clusteret. For Ã¥ lage en slik â€œpakkeâ€ kan man bruke et bibliotek som heter venv-pack. Dette kan kjÃ¸res fra et terminalvindu slik:\nvenv-pack -p .venv -o pyspark_venv.tar.gz\nMerk at kommandoen over mÃ¥ kjÃ¸res fra rot-mappen i prosjektet ditt. Her er pyspark_venv.tar.gz et tilfeldig valgt filnavn, men dette filnavnet skal brukes videre i notebooken.\nimport os\nimport subprocess\n\n# MiljÃ¸variabel som peker pÃ¥ en utpakket versjon av det virtuelle miljÃ¸et\nos.environ[\"PYSPARK_PYTHON\"] = \"./environment/bin/python\"\n\n# Legg til et flagg, --archives, som peker pÃ¥ \"pakken\" med det virtuelle miljÃ¸et\nconf = os.environ[\"PYSPARK_K8S_SUBMIT_ARGS\"].split(' ')\nlast_index = conf.index('pyspark-shell')\nconf[last_index:last_index] = ['--archives', 'pyspark_venv.tar.gz#environment']\nos.environ[\"PYSPARK_SUBMIT_ARGS\"] = ' '.join(conf)\nTil slutt mÃ¥ man kjÃ¸re et script for Ã¥ initialisere pyspark cluster:\n%run /usr/local/share/jupyter/kernels/pyspark_k8s/init.py\nDette scriptet vil sette et spark objekt som brukes for Ã¥ kalle APIâ€™et til pyspark."
  }
]