{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4e5c4f-6e00-4bad-8984-b5feb06d9524",
   "metadata": {},
   "source": [
    "# Tidsserier med Spark\n",
    "\n",
    "I denne notebooken vises noen enkle eksempler på hvordan du kan jobbe med tidsserier i PySpark. Denne notebooken er kjørt i prodmiljøet på **Dapla** med `Pyspark (local)`-kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3d798c-570d-4112-99ba-b3f4d694ca80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importer biblioteker\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import date_format, explode, expr, sequence\n",
    "from pyspark.sql.types import DateType, DoubleType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4c5e0d-1909-43ed-8911-43b02485e045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9d1e1d-8173-47b6-a70b-be84c38a7bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      Date|\n",
      "+----------+\n",
      "|2000-01-01|\n",
      "|2000-02-01|\n",
      "|2000-03-01|\n",
      "|2000-04-01|\n",
      "|2000-05-01|\n",
      "|2000-06-01|\n",
      "|2000-07-01|\n",
      "|2000-08-01|\n",
      "|2000-09-01|\n",
      "|2000-10-01|\n",
      "|2000-11-01|\n",
      "|2000-12-01|\n",
      "|2001-01-01|\n",
      "|2001-02-01|\n",
      "|2001-03-01|\n",
      "|2001-04-01|\n",
      "|2001-05-01|\n",
      "|2001-06-01|\n",
      "|2001-07-01|\n",
      "|2001-08-01|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequence of dates\n",
    "dates_df = spark.range(1).select(\n",
    "    explode(\n",
    "        sequence(\n",
    "            start=expr(\"date '2000-01-01'\"),\n",
    "            stop=expr(\"date '2023-08-01'\"),\n",
    "            step=expr(\"interval 1 month\"),\n",
    "        )\n",
    "    ).alias(\"Date\")\n",
    ")\n",
    "dates_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b292de78-6144-47a6-ba9e-0fc2947dd7b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|           serie00|           serie01|\n",
      "+------------------+------------------+\n",
      "| 10.28552497082796| 18.80213440932389|\n",
      "|   9.2989592234365| 19.29443190926363|\n",
      "| 9.641691011493942| 18.39265495089296|\n",
      "|10.095600235251702|19.210869145255476|\n",
      "|10.598149885398882| 21.04002768054827|\n",
      "| 9.589494891543382|19.444913286211904|\n",
      "| 8.949769940462296|17.256517957204697|\n",
      "|10.268826124760595|21.924880828385007|\n",
      "| 8.433705199373218| 18.27099790039972|\n",
      "| 9.591527268314453|18.644221035018294|\n",
      "| 9.285955387695676| 21.07566671691805|\n",
      "|10.513149406143489|21.896507412493104|\n",
      "|10.746275077506867| 19.94937133987704|\n",
      "|10.422822429410505| 21.00460601739491|\n",
      "| 9.855151113581227|19.900805138755697|\n",
      "| 9.907391678199144| 20.09316407526652|\n",
      "|   11.910837422526|20.458605571861405|\n",
      "|11.900773767457748|22.034612549696465|\n",
      "| 9.627286028962596| 19.28652948261321|\n",
      "|10.636674573465507|20.860349444400374|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Genererer random walk data\n",
    "schema = StructType(\n",
    "    [StructField(f\"serie{i:02d}\", DoubleType(), True) for i in range(100)]\n",
    ")\n",
    "\n",
    "data = [\n",
    "    tuple((10 + np.random.normal(0, 1, 100)).cumsum().tolist())\n",
    "    for _ in range(284)  # 284 months from 2000-01 to 2023-08\n",
    "]\n",
    "\n",
    "data_df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "data_df.select(\"serie00\", \"serie01\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aee8d1d-0cd5-4065-8b76-433df3a62085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-----+------------------+------------------+\n",
      "|      Date|Year|Quarter|Month|           serie00|           serie01|\n",
      "+----------+----+-------+-----+------------------+------------------+\n",
      "|2000-01-01|2000|      1|   01|10.704067839807966|19.806605259386576|\n",
      "|2000-02-01|2000|      1|   02| 9.993509489905344| 21.02908289357401|\n",
      "|2000-03-01|2000|      1|   03|10.844481778491335|21.594184969233666|\n",
      "|2000-04-01|2000|      2|   04| 9.983524978212996| 20.77975958435706|\n",
      "|2000-05-01|2000|      2|   05|10.662027203131691|21.298218459469076|\n",
      "|2000-06-01|2000|      2|   06|11.306200406865427| 22.21276903169298|\n",
      "|2000-07-01|2000|      3|   07|10.273584558625396|19.559994622897797|\n",
      "|2000-08-01|2000|      3|   08|10.992524143589362| 20.45220088288665|\n",
      "|2000-09-01|2000|      3|   09|10.282296888132114|20.861802251700826|\n",
      "|2000-10-01|2000|      4|   10|10.902266221974365| 22.48748166939777|\n",
      "|2000-11-01|2000|      4|   11| 8.266550146677737|16.863204651845365|\n",
      "|2000-12-01|2000|      4|   12| 9.237088445481582| 19.26904214842979|\n",
      "|2001-01-01|2001|      1|   01|11.726643478429851|21.561609108404078|\n",
      "|2001-02-01|2001|      1|   02| 10.90211843894425| 21.82958346090264|\n",
      "|2001-03-01|2001|      1|   03|  9.45763266226521|19.619683788368224|\n",
      "|2001-04-01|2001|      2|   04|10.099360702188173|19.159841785747737|\n",
      "|2001-05-01|2001|      2|   05| 12.12908433159167|20.813306808213298|\n",
      "|2001-06-01|2001|      2|   06|  8.98981102798096|21.046785143421218|\n",
      "|2001-07-01|2001|      3|   07|10.183740564710039|19.928482759490905|\n",
      "|2001-08-01|2001|      3|   08| 11.23208844317083| 21.31037435192478|\n",
      "+----------+----+-------+-----+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Legger til row index til DataFrame før join med dates_df\n",
    "data_df = data_df.withColumn(\"row_index\", expr(\"monotonically_increasing_id()\"))\n",
    "\n",
    "# Joiner de to datasettene\n",
    "df = (\n",
    "    dates_df.withColumn(\"row_index\", expr(\"monotonically_increasing_id()\"))\n",
    "    .join(data_df, \"row_index\")\n",
    "    .drop(\"row_index\")\n",
    ")\n",
    "\n",
    "# Legger til år, kvartal og mnd\n",
    "df = df.withColumn(\"Year\", date_format(df.Date, \"yyyy\"))\n",
    "df = df.withColumn(\"Quarter\", expr(\"quarter(Date)\"))\n",
    "df = df.withColumn(\"Month\", date_format(df.Date, \"MM\"))\n",
    "\n",
    "df.select(\"Date\",  \"Year\", \"Quarter\", \"Month\", \"serie00\", \"serie01\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark (local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
