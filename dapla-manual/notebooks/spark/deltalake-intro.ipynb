{
 "cells": [
  {
   "cell_type": "raw",
   "id": "84bacee7-211b-4b0a-b6eb-5ab3da52cf16",
   "metadata": {},
   "source": [
    "---\n",
    "freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3421b-ac03-453e-8c98-d05c1ba97922",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduksjon til Delta Lake\n",
    "\n",
    "Delta Lake er et databaselag som kan *legges over* parquet-filer i bøtter. Det kan gi oss mye av den funksjonaliteten vi har vært vant til i relasjonelle databaser og datavarehus. I denne notebooken vises hvordan man kan ta det i bruk på Dapla. \n",
    "\n",
    "## Oppsett\n",
    "\n",
    "Hvis du logger deg inn på <https://jupyter.dapla.ssb.no/> kan du ta i bruk Delta Lake via Spark. Men for å gjøre det må du installere [delta-spark](https://pypi.org/project/delta-spark/). For å installere pakken må du jobbe i et [ssb-project](https://manual.dapla.ssb.no/jobbe-med-kode.html#ssb-project). I tillegg må du installere `delta-spark`-versjon som er kompatibel med Spark-versjonen som er installert på Dapla. Gjør derfor følgende:\n",
    "\n",
    "1. [Opprett et ssb-project](https://manual.dapla.ssb.no/jobbe-med-kode.html#ssb-project) med kommandoen:  \n",
    "`ssb-project create test-delta-lake`\n",
    "2. I terminalen skriver du følgende for å sjekke Spark-versjonen som er installert:  \n",
    "`spark-shell --version`\n",
    "3. [Sjekk hvilken **delta-spark**-versjon](https://docs.delta.io/latest/releases.html) som er kompatibel med din Spark-versjon og installer den med kommandoen^[I eksempelet er det Spark V3.3.1 som er installert og jeg installerer derfor delta-spark v2.3]:   \n",
    "`poetry add delta-spark@2.3`\n",
    "4. Åpne en ny notebook og velg kernel `test-delta-lake`. \n",
    "\n",
    "Nå har du satt opp et virtuelt miljø med en PySpark-kernel som kjører en maskin (såkalt Pyspark local kernel), der du har installert delta-spark. Vi kan nå importere de bibliotekene vi trenger og sette igang en Spark-session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7398549f-f7cf-4298-8254-ece4a08fa5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importerer biblioteker\n",
    "import pyspark\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ed22e-d8d0-4777-9c8a-fdefd654f98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Deretter initialiserer jeg en Spark-session. `%%capture_output` er med for å forhindre at det ikke blir printet ut sensitiv informasjon i en notebook som skal inn i Dapla-manualen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e037f70d-e6f8-4fd3-8a18-8b358ca9613f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "%run /usr/local/share/jupyter/kernels/pyspark_local/init.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5bdfb3-618c-4147-817a-756516975571",
   "metadata": {},
   "source": [
    "## Genererer noe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5dd7d8-b1de-477b-8521-637698cc0f48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Genererer noe data med Spark\n",
    "data = spark.range(10, 15)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdeb07a-5593-430f-819d-9e80501946d9",
   "metadata": {},
   "source": [
    "## Skriver ut en Delta Lake Table\n",
    "\n",
    "La oss skrive ut Spark DataFrame som en Delta Lake Table og bli kjent med strukturen i objektet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e9dc42-599f-414b-ab95-c7a6e94780c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.52 ms, sys: 5.12 ms, total: 10.6 ms\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data.write.format(\"delta\").mode(\"overwrite\").save(\n",
    "    \"gs://ssb-prod-dapla-felles-data-delt/temp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9fa65-6b14-43ad-a488-18c0028f9d3d",
   "metadata": {},
   "source": [
    "Vi kan deretter printe ut hva som ble opprettet når vi skrev ut en Delta Lake Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0a2616-f5cb-4648-ae6a-f11b6d0e6093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ssb-prod-dapla-felles-data-delt/temp4/_delta_log',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000000.json',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-a3d60508-b229-46a3-969b-795a4072a6e3-c000.snappy.parquet',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/part-00001-18df7610-8ca0-4906-97b0-2b64a4a7a710-c000.snappy.parquet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dapla import FileClient\n",
    "\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "\n",
    "fs.glob(\"gs://ssb-prod-dapla-felles-data-delt/temp4/**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240cc2f-8747-4390-b991-f61fa72fdfd6",
   "metadata": {},
   "source": [
    "### Delta Lake Tabellstruktur\n",
    "\n",
    "Mappenstrukturen du ser over er typisk for en Delta Lake-tabell. La oss bryte ned komponentene:\n",
    "\n",
    "1. **`_delta_log/`**:\n",
    "   - Dette er transaksjonsloggmappen for Delta Lake-tabellen. Den inneholder en serie med JSON-filer som registrerer alle transaksjoner gjort på tabellen.\n",
    "   - Transaksjonsloggen er avgjørende for Delta Lakes ACID-transaksjonsegenskaper, som muliggjør funksjoner som atomiske forpliktelser, tilbakerullinger og tid-reise-forespørsler.\n",
    "\n",
    "2. **`_delta_log/00000000000000000000.json`**:\n",
    "   - Dette er en JSON-fil innenfor transaksjonsloggkatalogen. Hver JSON-fil i denne mappen tilsvarer en transaksjon (eller en batch av transaksjoner) gjort på tabellen.\n",
    "   - Filnavnet er null-fylt og representerer transaksjonsversjonen. I dette tilfellet representerer `00000000000000000000.json` den aller første versjonen (versjon 0) av tabellen. Etter hvert som flere transaksjoner blir gjort, vil nye filer bli lagt til med økende versjonsnumre.\n",
    "\n",
    "3. **`part-00000-450715bd-6b0c-4827-bb8a-b0265505ca72-c000.snappy.parquet`** og **`part-00001-977ed55f-5ce5-469f-8a1d-9eafb143c215-c000.snappy.parquet`**:\n",
    "   - Dette er de faktiske datafilene til Delta Lake-tabellen, lagret i Parquet-format.\n",
    "   - `.snappy.parquet`-utvidelsen indikerer at dataene er komprimert ved hjelp av Snappy-komprimeringsalgoritmen.\n",
    "   - Filnavnene er typiske for Sparks navngivningskonvensjon for datadeler. Prefiksene `part-00000` og `part-00001` indikerer partisjonsnumre. De lange UUID-lignende strengene er unike identifikatorer for datafilene. Suffikset `c000` indikerer Spark-oppgaven som skrev filen.\n",
    "\n",
    "Mappen representerer en Delta Lake-tabell med data lagret i Parquet-format og en transaksjonslogg som sporer endringer i tabellen. Tilstedeværelsen av `_delta_log`-mappen og innholdet er det som skiller en Delta Lake-tabell fra et vanlig Parquet-datasett.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5345de5-f48e-450c-8c16-d7f765566424",
   "metadata": {},
   "source": [
    "## Lese inn tabell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc78bc00-1ef9-49d9-b8a0-87b3a7ec74ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 10|\n",
      "| 11|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"gs://ssb-prod-dapla-felles-data-delt/temp4\")\n",
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df1c88-6648-486f-95f7-89b20cba2de0",
   "metadata": {},
   "source": [
    "## Modifisere datasettet\n",
    "\n",
    "La oss modifisere datasettet ved å bytte ut verdien `13` med `15` i `id`-kolonnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42699f66-ed3a-4fbb-ab54-a5f6874b0a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# Update the cell with value 13 to 15\n",
    "deltaTable.update(condition=(col(\"id\") == 13), set={\"id\": lit(15)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69de71a-39b5-423a-9219-f68acd326320",
   "metadata": {},
   "source": [
    "Et viktig poeng å få med seg her er at vi nå oppdaterte Delta Lake Table objektet både i minnet og på disk. La oss bevise det ved å lese inn fra disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b10a295-843b-41e8-b407-f8fe1daf275b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 12|\n",
      "| 15|\n",
      "| 14|\n",
      "| 10|\n",
      "| 11|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable2 = DeltaTable.forPath(spark, \"gs://ssb-prod-dapla-felles-data-delt/temp4\")\n",
    "deltaTable2.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9c5d1-afa8-4fd9-9c83-43c3ccaf6d2d",
   "metadata": {},
   "source": [
    "Og deretter ved å printe ut det opprinnelige objektet vi leste inn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4258ccf3-6701-496c-baea-1bbff4274e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 12|\n",
      "| 15|\n",
      "| 14|\n",
      "| 10|\n",
      "| 11|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38884c83-5ffa-4f79-b428-8b4e6fe6f46e",
   "metadata": {},
   "source": [
    "## Append data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389af127-b5ce-4c79-a389-8732287c08a8",
   "metadata": {},
   "source": [
    "La oss legge til verdiene `20` og `21` til datasettet. Først lager vi en Spark dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c64e127-54ed-4a2b-8d35-a052faf985d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 20|\n",
      "| 21|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = [(20,), (21,)]\n",
    "new_df = spark.createDataFrame(new_data, [\"id\"])\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a1905-0529-4f37-9f99-41b914130b32",
   "metadata": {},
   "source": [
    "Deretter kan vi appendere det til vår opprinnelige dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e6b418-3cb7-4360-bbd0-e09d7f82faf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df.write.format(\"delta\").mode(\"append\").save(\n",
    "    \"gs://ssb-prod-dapla-felles-data-delt/temp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1182c79-36a5-4d4d-beb0-a72b3d377caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 12|\n",
      "| 15|\n",
      "| 14|\n",
      "| 10|\n",
      "| 11|\n",
      "| 20|\n",
      "| 21|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606705e-5efb-4ae3-be09-1ac693d3740e",
   "metadata": {},
   "source": [
    "## Historien og metadata til filen\n",
    "\n",
    "Nå som vi har gjort noen endringer kan vi se på historien til filen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f805cfdb-9081-4d6a-8840-48898aaa3956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ssb-prod-dapla-felles-data-delt/temp4/_delta_log',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000000.json',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000001.json',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000002.json',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-023ea382-3202-4374-ad64-8c7bcbae4b21-c000.snappy.parquet',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-1a4de6d3-c550-4871-ac9b-cfcfd3d1a7f5-c000.snappy.parquet',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-a3d60508-b229-46a3-969b-795a4072a6e3-c000.snappy.parquet',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/part-00001-18df7610-8ca0-4906-97b0-2b64a4a7a710-c000.snappy.parquet',\n",
       " 'ssb-prod-dapla-felles-data-delt/temp4/part-00001-2a8ec036-543e-4518-9b63-fe16626a6a0e-c000.snappy.parquet']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lister ut filene i bøtta\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "fs.glob(\"gs://ssb-prod-dapla-felles-data-delt/temp4/**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacbeb6f-e80c-4d7a-9c81-405887983e12",
   "metadata": {},
   "source": [
    "Vi ser av transaksjonsloggen i `_delta_log`-mappen at det nå har vært 3 transaksjoner på datasettet. vi ser også av navnene på parquet-filene, `part-00000` og `part-00001`, at det finnes to versjoner av filen. Hvis vi ønsker å bli bedre kjent med hva slags informasjon som blir lagret fra transaksjonene, så kan vi printe ut den siste transaksjonen som heter `00000000000000000002.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9e687c-b0f3-4c5b-9327-6619196e5348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"commitInfo\": {\n",
      "        \"timestamp\": 1696941560514,\n",
      "        \"operation\": \"WRITE\",\n",
      "        \"operationParameters\": {\n",
      "            \"mode\": \"Append\",\n",
      "            \"partitionBy\": \"[]\"\n",
      "        },\n",
      "        \"readVersion\": 1,\n",
      "        \"isolationLevel\": \"Serializable\",\n",
      "        \"isBlindAppend\": true,\n",
      "        \"operationMetrics\": {\n",
      "            \"numFiles\": \"2\",\n",
      "            \"numOutputRows\": \"2\",\n",
      "            \"numOutputBytes\": \"956\"\n",
      "        },\n",
      "        \"engineInfo\": \"Apache-Spark/3.3.1 Delta-Lake/2.3.0\",\n",
      "        \"txnId\": \"bfa65762-5c38-4d2c-a4d8-49e86e5e300c\"\n",
      "    }\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"add\": {\n",
      "        \"path\": \"part-00000-023ea382-3202-4374-ad64-8c7bcbae4b21-c000.snappy.parquet\",\n",
      "        \"partitionValues\": {},\n",
      "        \"size\": 478,\n",
      "        \"modificationTime\": 1696941560298,\n",
      "        \"dataChange\": true,\n",
      "        \"stats\": \"{\\\"numRecords\\\":1,\\\"minValues\\\":{\\\"id\\\":20},\\\"maxValues\\\":{\\\"id\\\":20},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n",
      "    }\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"add\": {\n",
      "        \"path\": \"part-00001-2a8ec036-543e-4518-9b63-fe16626a6a0e-c000.snappy.parquet\",\n",
      "        \"partitionValues\": {},\n",
      "        \"size\": 478,\n",
      "        \"modificationTime\": 1696941560464,\n",
      "        \"dataChange\": true,\n",
      "        \"stats\": \"{\\\"numRecords\\\":1,\\\"minValues\\\":{\\\"id\\\":21},\\\"maxValues\\\":{\\\"id\\\":21},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n",
      "    }\n",
      "}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from dapla import FileClient\n",
    "\n",
    "# Kobler oss på bøttene\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "\n",
    "# Filsti\n",
    "path = \"gs://ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000002.json\"\n",
    "\n",
    "with fs.open(path, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        pretty_content = json.dumps(data, indent=4)\n",
    "        print(pretty_content)\n",
    "        print(\"-\" * 50)  # Print separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c37fde-12e8-4485-bd0d-1098681f75fc",
   "metadata": {},
   "source": [
    "Her ser vi at vi får masse informasjon om endringen, både metadata om transaksjonen i `commitInfo`, og informasjon om nye data-filer i  `add`-delen. Vi ser at det er en veldig rik beskrivelse av endringer, men det kan være vanskeig å lese innholdet direkte. La oss heller bruke `history()`-funksjonen som kommer med `delta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71ff024b-ebee-409e-943f-7625b7d78a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      2|2023-10-10 12:39:...|  null|    null|    WRITE|{mode -> Append, ...|null|    null|     null|          1|  Serializable|         true|{numFiles -> 2, n...|        null|Apache-Spark/3.3....|\n",
      "|      1|2023-10-10 12:39:...|  null|    null|   UPDATE|{predicate -> (id...|null|    null|     null|          0|  Serializable|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n",
      "|      0|2023-10-10 12:38:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 2, n...|        null|Apache-Spark/3.3....|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = deltaTable.history()\n",
    "history.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f816dfa-4c37-40f5-b5dd-ca70613de8c0",
   "metadata": {},
   "source": [
    "Siden det blit trangt i tabellen over så kan vi velge hvilke variabler vi ønsker å se på:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a596ee4f-5773-4f24-a1fb-621574f4e1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['version',\n",
       " 'timestamp',\n",
       " 'userId',\n",
       " 'userName',\n",
       " 'operation',\n",
       " 'operationParameters',\n",
       " 'job',\n",
       " 'notebook',\n",
       " 'clusterId',\n",
       " 'readVersion',\n",
       " 'isolationLevel',\n",
       " 'isBlindAppend',\n",
       " 'operationMetrics',\n",
       " 'userMetadata',\n",
       " 'engineInfo']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversikt over alle kolonner som finnes i historien\n",
    "history.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1baa4548-8ab3-406b-a76e-ea9b4191bf71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Velger de kolonnene jeg er interessert i\n",
    "selected_history = deltaTable.history().select(\n",
    "    \"version\", \"timestamp\", \"operation\", \"operationParameters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5178957e-f735-4434-8b1b-d94a9d77ee93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+---------+--------------------------------------+\n",
      "|version|              timestamp|operation|                   operationParameters|\n",
      "+-------+-----------------------+---------+--------------------------------------+\n",
      "|      2|2023-10-10 12:39:20.668|    WRITE|   {mode -> Append, partitionBy -> []}|\n",
      "|      1|2023-10-10 12:39:10.421|   UPDATE|         {predicate -> (id#683L = 13)}|\n",
      "|      0|2023-10-10 12:38:56.778|    WRITE|{mode -> Overwrite, partitionBy -> []}|\n",
      "+-------+-----------------------+---------+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the selected columns\n",
    "selected_history.show(truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48fced-793b-4c27-b8c5-321f9f7372d0",
   "metadata": {},
   "source": [
    "## Egendefinert metadata\n",
    "\n",
    "Delta Lake støtter også egendefinert metadata. Det kan for eksempel være nyttig hvis man ønsker å bruke Delta Lake som en backend for et GUI som lar brukeren oppdatere en tabell fra GUI-et. Da ønsker man typisk å lagre hvem som gjorde endringer og når det ble gjort. La oss legge på noe slik metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80128e45-f7a3-4050-b34e-539b814e4f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leser inn filen\n",
    "df = spark.read.format(\"delta\").load(\"gs://ssb-prod-dapla-felles-data-delt/temp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ec5ce9-87d2-41c0-ac51-5cf425b95be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lagrer egendefinert metadata i en json-fil\n",
    "import json\n",
    "\n",
    "metadata = {\n",
    "    \"comment\": \"Kontaktet oppgavegiver og kranglet!\",\n",
    "    \"manueltEditert\": \"True\",\n",
    "    \"maskineltEditert\": \"False\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c8b51-0a29-48ed-8c99-de279d2a7949",
   "metadata": {},
   "source": [
    "Vi kan deretter appende dette til den siste versjonen av fila. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f5ae1c3-64b8-4864-b174-443481aa5364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df.write.format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"userMetadata\", json.dumps(metadata))  # Serialize metadata to a string\n",
    "    .save(\"gs://ssb-prod-dapla-felles-data-delt/temp4\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e15b79-7bd1-44ec-a278-e5f758122ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Laster inn tabellen\n",
    "deltaTable = DeltaTable.forPath(spark, \"gs://ssb-prod-dapla-felles-data-delt/temp4\")\n",
    "\n",
    "# Henter ut historien\n",
    "history_df = deltaTable.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da236532-cacb-4e23-8669-f323944a2326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+-------------------+------------+\n",
      "|version| timestamp|operation|operationParameters|userMetadata|\n",
      "+-------+----------+---------+-------------------+------------+\n",
      "|      3|2023-10...|    WRITE|         {mode -...|  {\"comme...|\n",
      "|      2|2023-10...|    WRITE|         {mode -...|        null|\n",
      "|      1|2023-10...|   UPDATE|         {predic...|        null|\n",
      "|      0|2023-10...|    WRITE|         {mode -...|        null|\n",
      "+-------+----------+---------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the operation details, including metadata\n",
    "history_df.select(\n",
    "    \"version\", \"timestamp\", \"operation\", \"operationParameters\", \"userMetadata\"\n",
    ").show(truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8004531b-c729-4f63-9495-1bd45adce7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------+\n",
      "|version|                                      userMetadata|\n",
      "+-------+--------------------------------------------------+\n",
      "|      3|{\"comment\": \"Kontaktet oppgavegiver og kranglet...|\n",
      "|      2|                                              null|\n",
      "|      1|                                              null|\n",
      "|      0|                                              null|\n",
      "+-------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| label: show-meta\n",
    "#| code-fold: true\n",
    "history_df.select(\"version\", \"userMetadata\").show(truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1db1b5-cfd9-41fb-a86a-8ef5968aa04f",
   "metadata": {},
   "source": [
    "Vi ser at vi la til vår egen metadata i versjon 3 av fila. Vi kan printe ut den rå transaksjonsloggen som tidligere, men nå er vi på transaksjon 3 `00000000000000000003.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5099b8b-408b-420d-828d-6689c746160f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"commitInfo\": {\n",
      "        \"timestamp\": 1696941570838,\n",
      "        \"operation\": \"WRITE\",\n",
      "        \"operationParameters\": {\n",
      "            \"mode\": \"Append\",\n",
      "            \"partitionBy\": \"[]\"\n",
      "        },\n",
      "        \"readVersion\": 2,\n",
      "        \"isolationLevel\": \"Serializable\",\n",
      "        \"isBlindAppend\": false,\n",
      "        \"operationMetrics\": {\n",
      "            \"numFiles\": \"2\",\n",
      "            \"numOutputRows\": \"7\",\n",
      "            \"numOutputBytes\": \"988\"\n",
      "        },\n",
      "        \"userMetadata\": \"{\\\"comment\\\": \\\"Kontaktet oppgavegiver og kranglet!\\\", \\\"manueltEditert\\\": \\\"True\\\", \\\"maskineltEditert\\\": \\\"False\\\"}\",\n",
      "        \"engineInfo\": \"Apache-Spark/3.3.1 Delta-Lake/2.3.0\",\n",
      "        \"txnId\": \"9839492c-2061-4d06-9f1b-e6ceac37c720\"\n",
      "    }\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"add\": {\n",
      "        \"path\": \"part-00000-ae57ef22-dddc-4743-a726-1d9dd53cfe8e-c000.snappy.parquet\",\n",
      "        \"partitionValues\": {},\n",
      "        \"size\": 503,\n",
      "        \"modificationTime\": 1696941570791,\n",
      "        \"dataChange\": true,\n",
      "        \"stats\": \"{\\\"numRecords\\\":5,\\\"minValues\\\":{\\\"id\\\":10},\\\"maxValues\\\":{\\\"id\\\":15},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n",
      "    }\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"add\": {\n",
      "        \"path\": \"part-00001-4b508fee-beef-4f31-9618-88cf74dd3b85-c000.snappy.parquet\",\n",
      "        \"partitionValues\": {},\n",
      "        \"size\": 485,\n",
      "        \"modificationTime\": 1696941570763,\n",
      "        \"dataChange\": true,\n",
      "        \"stats\": \"{\\\"numRecords\\\":2,\\\"minValues\\\":{\\\"id\\\":20},\\\"maxValues\\\":{\\\"id\\\":21},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n",
      "    }\n",
      "}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from dapla import FileClient\n",
    "\n",
    "# Kobler oss på bøttene\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "\n",
    "# Filsti\n",
    "path = \"gs://ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000003.json\"\n",
    "\n",
    "with fs.open(path, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        pretty_content = json.dumps(data, indent=4)\n",
    "        print(pretty_content)\n",
    "        print(\"-\" * 50)  # Print separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cbbd4a-ea13-425e-a65e-0e2f4acc777d",
   "metadata": {},
   "source": [
    "Vi er da at metadataene ligger som forventet i metadata-delen. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta-lake-manual",
   "language": "python",
   "name": "delta-lake-manual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
