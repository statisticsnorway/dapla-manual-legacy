# Jobbe med data

Når vi oppretter et **dapla-team** så får vi tildelt et eget området for lagring av data. For å kunne lese og skrive data fra Jupyter til disse områdene må vi autentisere oss, siden Jupyter og lagringsområdet er to separate sikkerhetsoner. 

@fig-storage viser dette klarer skillet mellom hvor vi koder og hvor dataene ligger på Dapla^[I de tidligere systemene på bakken så var det ikke nødvendig med autentisering mellom kodemiljø og datalagringen]. I dette kapitlet beskriver vi nærmere hvordan du kan jobbe med dataene dine på Dapla. 

![Tydelig skille mellom kodemiljø og datalagring på Dapla.](images/data-storage-image.png){ fig-alt="Bilde som viser forskjellen mellom kodemiljø og hvor data lagres." #fig-storage }

## SSB-biblioteker

For å gjøre det enklere å jobbe data på tvers av Jupyter og lagringsområdet er det laget noen egne SSB-utviklede biblioteker for å gjøre vanlige operasjoner mot lagringsområdet. Siden både R og Python skal brukes på Dapla, så er det laget to biblioteker, en for hver av disse språkene. [fellesr](https://statisticsnorway.github.io/fellesr/articles/vignette__DAPLA_jukseark.html) er biblioteket for R, og [dapla-toolbelt](https://github.com/statisticsnorway/dapla-toolbelt) er biblioteket for Python.

### dapla-toolbelt

[dapla-toolbelt](https://github.com/statisticsnorway/dapla-toolbelt) er en en pakke som lar deg enkelt lese og skrive til lagringsområdet uten å måtte autentifisere deg manuelt. Den har en **Pandas**-aktig syntaks som forhåpentlig er gjenkjennbar for de fleste. Pakken er installert i alle Python-kernels på Dapla, så du trenger ikke å installere den selv hvis du åpner en notebook med Python3 for eksempel. For å importere hele biblioteket i en notebook skriver du bare

```python
import dapla as dp
```

**dapla-toolbelt** bruker en pakke som heter **gcsfs** for å kommunisere med lagringsområdet. **gcsfs** er en pakke som lar deg bruke Google Cloud Storage (GCS) som om det var en filsystem. Det betyr at du kan bruke samme syntaks som du bruker for å lese og skrive til filer på din egen maskin. Du kan lese mulighetene i gcsfs [her](https://gcsfs.readthedocs.io/en/latest/api.html). Et eksempel på hvordan de to pakkene kan brukes sammen ser du her:

```python
from dapla import FileClient
fs = FileClient.get_gcs_file_system()

# Example of how you can use gcsfs and dapla-toolbelt together
fs.touch("gs://my-bucket/my-folder/")
```
I koden over brukte jeg kommandoen `touch` fra [gcsfs](https://gcsfs.readthedocs.io/en/latest/api.html) og `FileClient` fra dapla-toolbelt for å opprette en mappe i lagringsområdet.

I kapitlene under finner du konkrete eksempler på hvordan du kan bruke **dapla-toolbelt** til å jobbe med data i SSBs lagringsområdet.

### fellesr

R-pakken [fellesr](https://statisticsnorway.github.io/fellesr/articles/vignette__DAPLA_jukseark.html) er under utvikling og gir mye av den samme funksjonaliteten som **dapla-toolbelt** gir for Python. I tillegg til å kunne lese og skrive til lagringsområdet på Dapla, så har **fellesr** også funksjoner for å jobbe med metadata på Dapla.

**fellesr** er installert på Dapla og funksjoner kan benyttes ved: 

```r
library(fellesr)
```
Hvis du benytte en renv miljø, må pakken installeres en gang. Dette kan gjøres ved:
```r
renv::install("statisticsnorway/fellesr")
```

## Liste ut innhold i mappe

::: {.callout-tip}
## Eksempeldata

Det finnes et område som alle SSB-ansatte har lese- og skrivetilgang til. Det er  
**gs://ssb-prod-dapla-felles-data-delt/** i prod-miljøet på Dapla, og  
**gs://ssb-staging-dapla-felles-data-delt/** i staging-miljøet. Eksemplene under bruker førstnevnte i koden, slik at alle kan kjøre koden selv. 

Kode-eksemplene finnes for både R og Python, og du kan velge hvilken du skal se ved å trykke på den arkfanen du er interessert i.
:::

Å liste ut innhold i et gitt mappe på Dapla er ganske enkelt. Under ser du hvordan du kan liste ut innholdet i følgende mappe:

`gs://ssb-prod-dapla-felles-data-delt/felles/veiledning/python/eksempler/purchases`


::: {.panel-tabset}

## Python {{< fa brands python >}}

Vi bruker modulen `FileClient` fra **dapla-toolbelt** for å liste ut innholdet i en mappe.

```python
from dapla import FileClient

# Set path to folder
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler/purchases"

FileClient.ls(f"{bucket}/{folder}")
```

Med kommandoen over får du listet ut alle filnavn i mappen. Hvis du vil ha mer informasjon om filene så kan du bruke `ls`-kommandoen med `detail = True`, som under:

```python
FileClient.ls(f"{bucket}/{folder}", detail = True)
```
Syntaksen med `ls` er veldig lik det man kjenner fra en Linux-terminal. Men når vi bruker `detail = True` blir metadata om filene returnert som en Python-liste med dictionaries. Det kan være svært nyttig når du f.eks. trenger å vite dato og tidspunkt for når en fil ble opprettet, eller når den sist ble oppdatert.

## {{< fa brands r-project >}}

```r
# Loading functions into notebook
library(fellesr)

# Path to folder
bucket <- "ssb-prod-dapla-felles-data-delt/"
folder <- "felles/veiledning/python/eksempler/purchases"

# List files in folder 
list.files(paste0(bucket, folder))
```
Merknad: Når du spesifisere bøtter i R, trenger du ikke "gs://" foran. 

:::
 

## Skrive ut filer

Å skrive filer til et lagringsområde på Dapla er også ganske enkelt. Det ligner mye på den syntaksen vi er kjent med fra vanlige R- og Python-pakker, med noen små unntak.

### Parquet

Under lager vi en dataframe i en notebook og skriver den ut til en parquet-fil.

::: {.panel-tabset}

## Python {{< fa brands python >}}

Når vi leser en Parquet-fil med **dapla-toolbelt** så bruker den [pyarrow](https://arrow.apache.org/docs/python/index.html) i bakgrunnen. Dette er en av de raskeste måtene å lese og skrive Parquet-filer på.

```python

import dapla as dp
import pandas as pd
import numpy as np

# Set path to folder
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler/purchases"

# Create pandas dataframe
purchases = pd.DataFrame(np.random.randn(10, 5),
                        columns=["A", "B", "C", "D", "E"])

# Write pandas dataframe as parquet to GCS bucket
dp.write_pandas(df = purchases,
                gcs_path = f"{bucket}/{folder}/data.parquet",
                file_format = "parquet",)
```
Når vi kalte `write_pandas` over så spesifiserte vi at filformatet skulle være `parquet`. Dette er default, så vi kunne også ha skrevet det slik:

```python
dp.write_pandas(df = purchases,
                gcs_path = f"{bucket}/{folder}/data.parquet")
```
Men for de andre filformatene må vi altså spesifisere dette.

## {{< fa brands r-project >}}

Når vi jobber med Parquet-fil i R, bruker vi pakken [arrow](https://arrow.apache.org/docs/r/). Dette er en del av [fellesr](https://statisticsnorway.github.io/fellesr/) pakken så du trenger kun å kalle inn dette. Pakken inneholder funksjonen `write_SSB` som kan brukes til å skrive data til bøtte på Dapla.

```r
library(fellesr)

# Set stien til hvor data skal lagres
bucket <- "ssb-prod-dapla-felles-data-delt"
folder <- "felles/veiledning/r/eksempler/purchases"

# Lage en eksempel dataframe
purchases = data.frame(A = runif(10), B= runif(10), C=runif(10))

# Skrive data til bøttet som en parquet
write_SSB(purchases, file.path(bucket, folder, "purchases.parquet"))
```
Merknad: Når du spesifisere bøtter i R, trenger du ikke "gs://" foran. 

:::



### Tekstfiler

Noen ganger ønsker vi å lagre data i andre formatter slik som CSV, JSON og XML. 

::: {.panel-tabset}

## Python {{< fa brands python >}}

dapla-toolbelt kan skrive ut json, csv og posisjonsfiler (fixed-width-files/fwf) til lagringsområdet. Måten den gjør det på er å bruke Pandas sine funksjoner `read_json`, `read_csv`, `read_fwf` under panseret. Dette kan være nyttig å vite for skjønne hvordan dapla-toolbelt håndterer ulike strukturer i (spesielt hierarkiske) tekstfiler. Under ser du hvordan du kan skrive ut en dataframe til en json-fil.

```python
import numpy as np
import pandas as pd
from dapla import FileClient

# Set path to folder
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler/purchases"

# Create a dataframe with Pandas
df = pd.DataFrame(np.random.randn(10, 5), columns=["A", "B", "C", "D", "E"])

# Save dataframe as json with dapla-toolbelt
dp.write_pandas(df = df,
                gcs_path = f"{bucket}/{folder}/test.json",
                file_format = "json")
```	

Som vi ser at syntaksen over så kunne vi skrevet ut til noe annet enn json ved å endre verdien i argumentet `file_format`.

## {{< fa brands r-project >}}

Pakken [fellesr](https://statisticsnorway.github.io/fellesr/) kan også brukes til å skrive andre type filer, for eksempel csv, til bøtter. Dette gjøres med funksjonen `write_SSB` og spesifisere ønsket filtype i filnavn.

Først kaller vi biblioteket og lage noe test data ved:

```r
library(fellesr)

# Set stien til hvor data skal lagres
bucket <- "ssb-prod-dapla-felles-data-delt"
folder <- "felles/veiledning/r/eksempler/purchases"

# Lage en eksempel dataframe
purchases = data.frame(A = runif(10), B= runif(10), C=runif(10))

# Skrive til csv
write_SSB(purchases, file.path(bucket, folder, "purchases.csv")
```

:::

### xlsx

Det er ikke anbefalt å bruke xlsx-formatet, men her ser du hvordan det kan skrives ut. Mer kommer. 

::: {.panel-tabset}

## Python {{< fa brands python >}}

```python
import pandas as pd
from dapla import AuthClient

# Henter token for å kunne lese fra Dapla
token = AuthClient.fetch_google_credentials()

# Filsti
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler/purchases"

df.to_excel(f"{bucket}/{folder}/test.xlsx",
           storage_options={"token": token})
```

## {{< fa brands r-project >}}

Kommer snart

:::



## Lese inn filer

Under finner du eksempler på hvordan du kan lese inn data til en Jupyter Notebooks på Dapla.

### Parquet

::: {.panel-tabset}

## Python {{< fa brands python >}}

```python
import dapla as dp

# Set path to folder
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler/purchases"

# Read path into pandas dataframe 
dp.read_pandas(gcs_path= f"{bucket}/{folder}/data.parquet",
               file_format = "parquet",
               columns = None,)
```

Som vi så med `write_pandas` så er `file_format` default satt til `parquet`, og default for `columns = None`, så vi kunne også ha skrevet det slik:

```python
dp.read_pandas(gcs_path= f"{bucket}/{folder}/data.parquet")
```
`columns`-argumentet er en liste med kolonnenavn som vi ønsker å lese inn. Hvis vi ikke spesifiserer noen kolonner så vil alle kolonnene leses inn.

## {{< fa brands r-project >}}
Pakken [fellesr](https://statisticsnorway.github.io/fellesr/index.html) kan brukes til å lese inn data. Funksjonen `read_SSB()` kan lese inn filer i flere format inkluderende parquet. 

Her er et eksempel av å lese inn parquet fil "1987".

```r
library(fellesr)

bucket <- "ssb-prod-dapla-felles-data-delt"
folder <- "R_smoke_test"

dt_1987 <- read_SSB(file.path(bucket, folder, "1987.parquet"))

```

Vi kan også filtrere hvilke variabel vi ønsker å lese inn ved å spesifisere parameter `col_select`. For eksempel:

```r
dt_1987 <- read_SSB(file.path(bucket, folder, "1987.parquet"),
                    col_select = c("Year", "Month"))

```

Innlesning av parquet som er kartdata finner du her: [Lese kartdata](https://statisticsnorway.github.io/fellesr/articles/vignette__DAPLA_jukseark.html#lese-inn-kartdata-lagret-som--parquet-filer)


:::

### Tekstfiler

Kommer mer snart. Python-koden under bygger på eksempelet over. 

::: {.panel-tabset}

## Python {{< fa brands python >}}


```python
import dapla as dp

# Path to write to
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler/purchases"

# Read in json-file from dapla-storage
df = dp.read_pandas(gcs_path = f"{bucket}/{folder}/test3.json",
               file_format = "json")
```


## {{< fa brands r-project >}}

Funksjonen `read_SSB()` kan lese inn flere type av fil-format, slik som csv og json. Du trenger ikke å endre koden, kun spesifisere hele filnavn.  

Først kaller vi inn biblioteket [fellesr](https://statisticsnorway.github.io/fellesr/index.html) og spesifisere bøtte/mappen:

```r
library(fellesr)

# Filsti
bucket <- "ssb-prod-dapla-felles-data-delt"
folder <- "R_smoke_test"

# Lese inn CSV-fil
dt_1987 <- read_SSB(file.path(bucket, folder, "1987.csv"))

```

For å lese inn en json-fil kan skrive følgende:

```r
dt_1987 <- read_SSB(file.path(bucket, folder, "1987.json"))
```

:::

### xlsx

::: {.panel-tabset}

## Python {{< fa brands python >}}

```python
import pandas as pd
from dapla import AuthClient

# Hent token
token = AuthClient.fetch_google_credentials()

# Les inn fil
df = pd.read_excel("gs://ssb-prod-arbmark-skjema-data-produkt/test_gcp.xlsx",
    storage_options={"token": token})

```

## {{< fa brands r-project >}}

Kommer snart

:::

### SAS

Her er et eksempel på hvordan man leser inn en sas7bdat-fil på Dapla som har blitt generert i prodsonen. 

::: {.panel-tabset}

## Python {{< fa brands python >}}

```python
import pandas as pd
from dapla import FileClient

fs = FileClient.get_gcs_file_system()

sti = "gs://ssb-prod-dapla-felles-data-delt/felles/veiledning/sas/statbank_ledstill.sas7bdat"

with fs.open(sti) as sas:
    df = pd.read_sas(sas, format="sas7bdat", encoding="latin1")
```

## {{< fa brands r-project >}}

I produksjon sone (på bakken) kan R-pakken [haven](http://uribo.github.io/rpkg_showcase/utility/haven.html) benyttes for å lese inn .sas7bdat filer. Dette er ikke implementert i fellesr enda for lesing fra Dapla bøtte.

Mer om dette kommer. 


:::

## Slette filer

Å slette filer fra lagringsområdet kan gjøres på flere måter. I kapitlet om [sletting av data](./slette-data.html) viste vi hvordan man gjør det med pek-og-klikk i [Google Cloud Console](https://console.cloud.google.com/). Under ser du hvordan du kan slette filer med **dapla-toolbelt** og **gcsfs** eller [fellesr](https://statisticsnorway.github.io/fellesr/index.html). 

::: {.panel-tabset}

## Python {{< fa brands python >}}

```python	
from dapla import FileClient
fs = FileClient.get_gcs_file_system()

bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler/purchases"

fs.rm(f"{bucket}/{from_folder}/df.json")

```

## {{< fa brands r-project >}}
Funksjonen `gc_delete_object` kan brukes til å slette data på lagringsområdet.

```r
library(fellesr)

bucket <- "ssb-prod-dapla-felles-data-delt"
folder <- "felles/veiledning/r/eksempler/purchases"

gcs_delete_object(file.path(bucket, folder, "purchases.parquet"))
```

:::

## Kopiere filer

Å kopiere filer mellom mapper på et Linux-filsystem innebærer som regel bruke `cp`-kommandoen. På Dapla er det ikke så mye forskjell. Vi bruker en ligende tilnærming nå vi skal kopiere mellom bøtter eller mapper på lagringsområdet til SSB. Under ser du hvordan du kan kopiere en fil fra en mappe til en annen.

::: {.panel-tabset}

## Python {{< fa brands python >}}

La oss begynne med et eksempel der vi kopierer en fil fra en mappe til en annen i samme bøtte.

```python	
from dapla import FileClient
fs = FileClient.get_gcs_file_system()

# Path to folders
bucket = "gs://ssb-prod-dapla-felles-data-delt"
from_folder = "felles/veiledning/python/eksempler/purchases"
to_folder = "felles/veiledning/python/eksempler"

# Copy file
fs.cp(f"{bucket}/{from_folder}/data.parquet",
      f"{bucket}/{to_folder}/data_copy.parquet")

```
Det også fungere for å kopiere filer mellom bøtter. 

Et annet scenario vi ofte vil støte på er at vi ønsker å kopiere en fil fra vårt Jupyter-filsystem til en mappe på lagringsområdet. Her kan vi bruke `fs.put`-metoden. 

```python
from dapla import FileClient
fs = FileClient.get_gcs_file_system()

# Create a new file in your home directory called test.txt
with open('/home/jovyan/test.txt', 'w') as f:
    f.write('Create a new text file!')

#Path to folder
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler"

# Copy file from local to remote file system
fs.put(lpath=f"/home/jovyan/test.txt", rpath=f"{bucket}/{folder}/test.txt")

```
Ønsker vi å kopiere en hel mappe fra lagringsområdet til Jupyter-filsystemet, kan vi bruke `fs.get`-metoden, med opsjonen `recursive=True.` 

```python
from dapla import FileClient
fs = FileClient.get_gcs_file_system()

# Copy file
fs.get(<from_bucket>,
      "/home/jovyan/sesongjustering/",
      recursive=True)

```

## {{< fa brands r-project >}}

Kommer snart

:::

## Flytte filer

::: {.panel-tabset}

## Python {{< fa brands python >}}

```python	
from dapla import FileClient
fs = FileClient.get_gcs_file_system()

bucket = "gs://ssb-prod-dapla-felles-data-delt"
from_folder = "felles/veiledning/python/eksempler/purchases"
to_folder = "felles/veiledning/python/eksempler"

fs.mv(f"{bucket}/{from_folder}/data.parquet", f"{bucket}/{to_folder}/data.parquet")

```

## {{< fa brands r-project >}}

Kommer snart

:::

## Opprette mapper

Selv om bøtter ikke har mapper med en hierarkisk struktur slik man er kjent med fra klassike filsystemer, så kan man opprette det som ser ut som mapper i objektnavnet. I realiteten blir bare `/` oppfattet som en del av navnet på objektet. Skulle du likevel ønske å opprette dette så kan du gjøre det følgende måte:

::: {.panel-tabset}

## Python {{< fa brands python >}}

```python
from dapla import FileClient
fs = FileClient.get_gcs_file_system()

#Path to folder
bucket = "gs://ssb-prod-dapla-felles-data-delt"
folder = "felles/veiledning/python/eksempler"

# Create folder
fs.touch(f"{bucket}/{folder}/testmappe/")
```

## {{< fa brands r-project >}}

Kommer snart

:::


