{
  "hash": "89de061cc3ee5705edb74731c16bbb98",
  "result": {
    "markdown": "---\nfreeze: true\ntitle: Introduksjon til Delta Lake\n---\n\n\n\n\n\nDelta Lake er et databaselag som kan *legges over* parquet-filer i bøtter. Det kan gi oss mye av den funksjonaliteten vi har vært vant til i relasjonelle databaser og datavarehus. I denne notebooken vises hvordan man kan ta det i bruk på Dapla. \n\n## Oppsett\n\nHvis du logger deg inn på <https://jupyter.dapla.ssb.no/> kan du ta i bruk Delta Lake via Spark. Men for å gjøre det må du installere [delta-spark](https://pypi.org/project/delta-spark/). For å installere pakken må du jobbe i et [ssb-project](https://manual.dapla.ssb.no/jobbe-med-kode.html#ssb-project). I tillegg må du installere `delta-spark`-versjon som er kompatibel med Spark-versjonen som er installert på Dapla. Gjør derfor følgende:\n\n1. [Opprett et ssb-project](https://manual.dapla.ssb.no/jobbe-med-kode.html#ssb-project) med kommandoen:  \n`ssb-project create test-delta-lake`\n2. I terminalen skriver du følgende for å sjekke Spark-versjonen som er installert:  \n`spark-shell --version`\n3. [Sjekk hvilken **delta-spark**-versjon](https://docs.delta.io/latest/releases.html) som er kompatibel med din Spark-versjon og installer den med kommandoen^[I eksempelet er det Spark V3.3.1 som er installert og jeg installerer derfor delta-spark v2.3]:   \n`poetry add delta-spark@2.3`\n4. Åpne en ny notebook og velg kernel `test-delta-lake`. \n\nNå har du satt opp et virtuelt miljø med en PySpark-kernel som kjører en maskin (såkalt Pyspark local kernel), der du har installert delta-spark. Vi kan nå importere de bibliotekene vi trenger og sette igang en Spark-session. \n\n\n::: {.cell tags='[]' execution_count=1}\n``` {.python .cell-code}\n# Importerer biblioteker\nimport pyspark\nfrom delta import *\n```\n:::\n\n\nDeretter initialiserer jeg en Spark-session. `%%capture_output` er med for å forhindre at det ikke blir printet ut sensitiv informasjon i en notebook som skal inn i Dapla-manualen. \n\n::: {.cell tags='[]' execution_count=2}\n``` {.python .cell-code}\n%%capture captured_output\n%run /usr/local/share/jupyter/kernels/pyspark_local/init.py\n```\n:::\n\n\n## Genererer noe data\n\n::: {.cell tags='[]' execution_count=3}\n``` {.python .cell-code}\n# Genererer noe data med Spark\ndata = spark.range(10, 15)\ndata.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+---+\n| id|\n+---+\n| 10|\n| 11|\n| 12|\n| 13|\n| 14|\n+---+\n\n```\n:::\n:::\n\n\n## Skriver ut en Delta Lake Table\n\nLa oss skrive ut Spark DataFrame som en Delta Lake Table og bli kjent med strukturen i objektet:\n\n::: {.cell tags='[]' execution_count=4}\n``` {.python .cell-code}\n%%time\ndata.write.format(\"delta\").mode(\"overwrite\").save(\n    \"gs://ssb-prod-dapla-felles-data-delt/temp4\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCPU times: user 3.38 ms, sys: 1.7 ms, total: 5.08 ms\nWall time: 5.59 s\n```\n:::\n:::\n\n\nVi kan deretter printe ut hva som ble opprettet når vi skrev ut en Delta Lake Table:\n\n::: {.cell tags='[]' execution_count=5}\n``` {.python .cell-code}\nfrom dapla import FileClient\n\nfs = FileClient.get_gcs_file_system()\n\nfs.glob(\"gs://ssb-prod-dapla-felles-data-delt/temp4/**\")\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n['ssb-prod-dapla-felles-data-delt/temp4/_delta_log',\n 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/',\n 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000000.json',\n 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-9b3b81a9-2771-4fb4-9f0f-659fd160d643-c000.snappy.parquet',\n 'ssb-prod-dapla-felles-data-delt/temp4/part-00001-0f2f8ba5-3161-41e8-b5d1-2084128a5bed-c000.snappy.parquet']\n```\n:::\n:::\n\n\n### Delta Lake Tabellstruktur\n\nMappenstrukturen du ser over er typisk for en Delta Lake-tabell. La oss bryte ned komponentene:\n\n1. **`_delta_log/`**:\n   - Dette er transaksjonsloggmappen for Delta Lake-tabellen. Den inneholder en serie med JSON-filer som registrerer alle transaksjoner gjort på tabellen.\n   - Transaksjonsloggen er avgjørende for Delta Lakes ACID-transaksjonsegenskaper, som muliggjør funksjoner som atomiske forpliktelser, tilbakerullinger og tid-reise-forespørsler.\n\n2. **`_delta_log/00000000000000000000.json`**:\n   - Dette er en JSON-fil innenfor transaksjonsloggkatalogen. Hver JSON-fil i denne mappen tilsvarer en transaksjon (eller en batch av transaksjoner) gjort på tabellen.\n   - Filnavnet er null-fylt og representerer transaksjonsversjonen. I dette tilfellet representerer `00000000000000000000.json` den aller første versjonen (versjon 0) av tabellen. Etter hvert som flere transaksjoner blir gjort, vil nye filer bli lagt til med økende versjonsnumre.\n\n3. **`part-00000-450715bd-6b0c-4827-bb8a-b0265505ca72-c000.snappy.parquet`** og **`part-00001-977ed55f-5ce5-469f-8a1d-9eafb143c215-c000.snappy.parquet`**:\n   - Dette er de faktiske datafilene til Delta Lake-tabellen, lagret i Parquet-format.\n   - `.snappy.parquet`-utvidelsen indikerer at dataene er komprimert ved hjelp av Snappy-komprimeringsalgoritmen.\n   - Filnavnene er typiske for Sparks navngivningskonvensjon for datadeler. Prefiksene `part-00000` og `part-00001` indikerer partisjonsnumre. De lange UUID-lignende strengene er unike identifikatorer for datafilene. Suffikset `c000` indikerer Spark-oppgaven som skrev filen.\n\nMappen representerer en Delta Lake-tabell med data lagret i Parquet-format og en transaksjonslogg som sporer endringer i tabellen. Tilstedeværelsen av `_delta_log`-mappen og innholdet er det som skiller en Delta Lake-tabell fra et vanlig Parquet-datasett.\n\n## Lese inn tabell\n\n\n::: {.cell tags='[]' execution_count=6}\n``` {.python .cell-code}\ndeltaTable = DeltaTable.forPath(spark, \"gs://ssb-prod-dapla-felles-data-delt/temp4\")\ndeltaTable.toDF().show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+---+\n| id|\n+---+\n| 12|\n| 13|\n| 14|\n| 10|\n| 11|\n+---+\n\n```\n:::\n:::\n\n\n## Modifisere datasettet\n\nLa oss modifisere datasettet ved å bytte ut verdien `13` med `15` i `id`-kolonnen:\n\n::: {.cell tags='[]' execution_count=7}\n``` {.python .cell-code}\nfrom pyspark.sql.functions import col, lit\n\n# Update the cell with value 13 to 15\ndeltaTable.update(condition=(col(\"id\") == 13), set={\"id\": lit(15)})\n```\n:::\n\n\nEt viktig poeng å få med seg her er at vi nå oppdaterte Delta Lake Table objektet både i minnet og på disk. La oss bevise det ved å lese inn fra disk:\n\n::: {.cell tags='[]' execution_count=8}\n``` {.python .cell-code}\ndeltaTable2 = DeltaTable.forPath(spark, \"gs://ssb-prod-dapla-felles-data-delt/temp4\")\ndeltaTable2.toDF().show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+---+\n| id|\n+---+\n| 12|\n| 15|\n| 14|\n| 10|\n| 11|\n+---+\n\n```\n:::\n:::\n\n\nOg deretter ved å printe ut det opprinnelige objektet vi leste inn:\n\n::: {.cell tags='[]' execution_count=9}\n``` {.python .cell-code}\ndeltaTable.toDF().show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+---+\n| id|\n+---+\n| 12|\n| 15|\n| 14|\n| 10|\n| 11|\n+---+\n\n```\n:::\n:::\n\n\n## Append data\n\nLa oss legge til verdiene `20` og `21` til datasettet. Først lager vi en Spark dataframe:\n\n::: {.cell tags='[]' execution_count=10}\n``` {.python .cell-code}\nnew_data = [(20,), (21,)]\nnew_df = spark.createDataFrame(new_data, [\"id\"])\nnew_df.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+---+\n| id|\n+---+\n| 20|\n| 21|\n+---+\n\n```\n:::\n:::\n\n\nDeretter kan vi appendere det til vår opprinnelige dataframe:\n\n::: {.cell tags='[]' execution_count=11}\n``` {.python .cell-code}\nnew_df.write.format(\"delta\").mode(\"append\").save(\n    \"gs://ssb-prod-dapla-felles-data-delt/temp4\"\n)\n```\n:::\n\n\n::: {.cell tags='[]' execution_count=12}\n``` {.python .cell-code}\ndeltaTable.toDF().show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+---+\n| id|\n+---+\n| 12|\n| 15|\n| 14|\n| 10|\n| 11|\n| 21|\n| 20|\n+---+\n\n```\n:::\n:::\n\n\n## Historien og metadata til filen\n\nNå som vi har gjort noen endringer kan vi se på historien til filen:\n\n::: {.cell tags='[]' execution_count=13}\n``` {.python .cell-code}\n# Lister ut filene i bøtta\nfs = FileClient.get_gcs_file_system()\nfs.glob(\"gs://ssb-prod-dapla-felles-data-delt/temp4/**\")\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\n['ssb-prod-dapla-felles-data-delt/temp4/_delta_log',\n 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/',\n 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000000.json',\n 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000001.json',\n 'ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000002.json',\n 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-73e5052f-1b82-48da-ab37-2cbc01bb46c1-c000.snappy.parquet',\n 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-9b3b81a9-2771-4fb4-9f0f-659fd160d643-c000.snappy.parquet',\n 'ssb-prod-dapla-felles-data-delt/temp4/part-00000-d04d0ca2-8e8b-42e9-a8a3-0fed9a0e4e41-c000.snappy.parquet',\n 'ssb-prod-dapla-felles-data-delt/temp4/part-00001-0f2f8ba5-3161-41e8-b5d1-2084128a5bed-c000.snappy.parquet',\n 'ssb-prod-dapla-felles-data-delt/temp4/part-00001-30d707e4-dd9a-4bfd-a4c7-7fbb1933e9ae-c000.snappy.parquet']\n```\n:::\n:::\n\n\nVi ser av transaksjonsloggen i `_delta_log`-mappen at det nå har vært 3 transaksjoner på datasettet. vi ser også av navnene på parquet-filene, `part-00000` og `part-00001`, at det finnes to versjoner av filen. Hvis vi ønsker å bli bedre kjent med hva slags informasjon som blir lagret fra transaksjonene, så kan vi printe ut den siste transaksjonen som heter `00000000000000000002.json`:\n\n::: {.cell tags='[]' execution_count=14}\n``` {.python .cell-code}\nimport json\n\nfrom dapla import FileClient\n\n# Kobler oss på bøttene\nfs = FileClient.get_gcs_file_system()\n\n# Filsti\npath = \"gs://ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000002.json\"\n\nwith fs.open(path, \"r\") as f:\n    for line in f:\n        data = json.loads(line)\n        pretty_content = json.dumps(data, indent=4)\n        print(pretty_content)\n        print(\"-\" * 50)  # Print separator for clarity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{\n    \"commitInfo\": {\n        \"timestamp\": 1696942544879,\n        \"operation\": \"WRITE\",\n        \"operationParameters\": {\n            \"mode\": \"Append\",\n            \"partitionBy\": \"[]\"\n        },\n        \"readVersion\": 1,\n        \"isolationLevel\": \"Serializable\",\n        \"isBlindAppend\": true,\n        \"operationMetrics\": {\n            \"numFiles\": \"2\",\n            \"numOutputRows\": \"2\",\n            \"numOutputBytes\": \"956\"\n        },\n        \"engineInfo\": \"Apache-Spark/3.3.1 Delta-Lake/2.3.0\",\n        \"txnId\": \"a3dcd582-8362-4fc2-a8ce-57613d2eb2b8\"\n    }\n}\n--------------------------------------------------\n{\n    \"add\": {\n        \"path\": \"part-00000-73e5052f-1b82-48da-ab37-2cbc01bb46c1-c000.snappy.parquet\",\n        \"partitionValues\": {},\n        \"size\": 478,\n        \"modificationTime\": 1696942544755,\n        \"dataChange\": true,\n        \"stats\": \"{\\\"numRecords\\\":1,\\\"minValues\\\":{\\\"id\\\":20},\\\"maxValues\\\":{\\\"id\\\":20},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n    }\n}\n--------------------------------------------------\n{\n    \"add\": {\n        \"path\": \"part-00001-30d707e4-dd9a-4bfd-a4c7-7fbb1933e9ae-c000.snappy.parquet\",\n        \"partitionValues\": {},\n        \"size\": 478,\n        \"modificationTime\": 1696942544833,\n        \"dataChange\": true,\n        \"stats\": \"{\\\"numRecords\\\":1,\\\"minValues\\\":{\\\"id\\\":21},\\\"maxValues\\\":{\\\"id\\\":21},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n    }\n}\n--------------------------------------------------\n```\n:::\n:::\n\n\nHer ser vi at vi får masse informasjon om endringen, både metadata om transaksjonen i `commitInfo`, og informasjon om nye data-filer i  `add`-delen. Vi ser at det er en veldig rik beskrivelse av endringer, men det kan være vanskeig å lese innholdet direkte. La oss heller bruke `history()`-funksjonen som kommer med `delta`:\n\n::: {.cell tags='[]' execution_count=15}\n``` {.python .cell-code}\nhistory = deltaTable.history()\nhistory.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|      2|2023-10-10 12:55:...|  null|    null|    WRITE|{mode -> Append, ...|null|    null|     null|          1|  Serializable|         true|{numFiles -> 2, n...|        null|Apache-Spark/3.3....|\n|      1|2023-10-10 12:55:...|  null|    null|   UPDATE|{predicate -> (id...|null|    null|     null|          0|  Serializable|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n|      0|2023-10-10 12:55:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 2, n...|        null|Apache-Spark/3.3....|\n+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n\n```\n:::\n:::\n\n\nSiden det blit trangt i tabellen over så kan vi velge hvilke variabler vi ønsker å se på:\n\n::: {.cell tags='[]' execution_count=16}\n``` {.python .cell-code}\n# Oversikt over alle kolonner som finnes i historien\nhistory.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\n['version',\n 'timestamp',\n 'userId',\n 'userName',\n 'operation',\n 'operationParameters',\n 'job',\n 'notebook',\n 'clusterId',\n 'readVersion',\n 'isolationLevel',\n 'isBlindAppend',\n 'operationMetrics',\n 'userMetadata',\n 'engineInfo']\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=17}\n``` {.python .cell-code}\n# Velger de kolonnene jeg er interessert i\nselected_history = deltaTable.history().select(\n    \"version\", \"timestamp\", \"operation\", \"operationParameters\"\n)\n```\n:::\n\n\n::: {.cell tags='[]' execution_count=18}\n``` {.python .cell-code}\n# Display the selected columns\nselected_history.show(truncate=50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+-------+-----------------------+---------+--------------------------------------+\n|version|              timestamp|operation|                   operationParameters|\n+-------+-----------------------+---------+--------------------------------------+\n|      2|2023-10-10 12:55:45.014|    WRITE|   {mode -> Append, partitionBy -> []}|\n|      1|2023-10-10 12:55:37.054|   UPDATE|        {predicate -> (id#4452L = 13)}|\n|      0|2023-10-10 12:55:29.048|    WRITE|{mode -> Overwrite, partitionBy -> []}|\n+-------+-----------------------+---------+--------------------------------------+\n\n```\n:::\n:::\n\n\n## Egendefinert metadata\n\nDelta Lake støtter også egendefinert metadata. Det kan for eksempel være nyttig hvis man ønsker å bruke Delta Lake som en backend for et GUI som lar brukeren oppdatere en tabell fra GUI-et. Da ønsker man typisk å lagre hvem som gjorde endringer og når det ble gjort. La oss legge på noe slik metadata:\n\n::: {.cell tags='[]' execution_count=19}\n``` {.python .cell-code}\n# Leser inn filen\ndf = spark.read.format(\"delta\").load(\"gs://ssb-prod-dapla-felles-data-delt/temp4\")\n```\n:::\n\n\n::: {.cell tags='[]' execution_count=20}\n``` {.python .cell-code code-fold=\"true\"}\n# Lagrer egendefinert metadata i en json-fil\nimport json\n\nmetadata = {\n    \"comment\": \"Kontaktet oppgavegiver og kranglet!\",\n    \"manueltEditert\": \"True\",\n    \"maskineltEditert\": \"False\",\n}\nmetadata\n```\n\n::: {#show-meta .cell-output .cell-output-display execution_count=45}\n```\n{'comment': 'Kontaktet oppgavegiver og kranglet!',\n 'manueltEditert': 'True',\n 'maskineltEditert': 'False'}\n```\n:::\n:::\n\n\nVi kan deretter appende dette til den siste versjonen av fila. \n\n::: {.cell tags='[]' execution_count=21}\n``` {.python .cell-code}\n(\n    df.write.format(\"delta\")\n    .mode(\"append\")\n    .option(\"userMetadata\", json.dumps(metadata))  # Serialize metadata to a string\n    .save(\"gs://ssb-prod-dapla-felles-data-delt/temp4\")\n)\n```\n:::\n\n\n::: {.cell tags='[]' execution_count=22}\n``` {.python .cell-code}\n# Laster inn tabellen\ndeltaTable = DeltaTable.forPath(spark, \"gs://ssb-prod-dapla-felles-data-delt/temp4\")\n\n# Henter ut historien\nhistory_df = deltaTable.history()\n```\n:::\n\n\n::: {.cell tags='[]' execution_count=23}\n``` {.python .cell-code}\n# Show the operation details, including metadata\nhistory_df.select(\n    \"version\", \"timestamp\", \"operation\", \"operationParameters\", \"userMetadata\"\n).show(truncate=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+-------+----------+---------+-------------------+------------+\n|version| timestamp|operation|operationParameters|userMetadata|\n+-------+----------+---------+-------------------+------------+\n|      3|2023-10...|    WRITE|         {mode -...|  {\"comme...|\n|      2|2023-10...|    WRITE|         {mode -...|        null|\n|      1|2023-10...|   UPDATE|         {predic...|        null|\n|      0|2023-10...|    WRITE|         {mode -...|        null|\n+-------+----------+---------+-------------------+------------+\n\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=24}\n``` {.python .cell-code}\nhistory_df.select(\"version\", \"userMetadata\").show(truncate=50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+-------+--------------------------------------------------+\n|version|                                      userMetadata|\n+-------+--------------------------------------------------+\n|      3|{\"comment\": \"Kontaktet oppgavegiver og kranglet...|\n|      2|                                              null|\n|      1|                                              null|\n|      0|                                              null|\n+-------+--------------------------------------------------+\n\n```\n:::\n:::\n\n\nVi ser at vi la til vår egen metadata i versjon 3 av fila. Vi kan printe ut den rå transaksjonsloggen som tidligere, men nå er vi på transaksjon 3 `00000000000000000003.json`:\n\n::: {.cell tags='[]' execution_count=25}\n``` {.python .cell-code}\nfrom dapla import FileClient\n\n# Kobler oss på bøttene\nfs = FileClient.get_gcs_file_system()\n\n# Filsti\npath = \"gs://ssb-prod-dapla-felles-data-delt/temp4/_delta_log/00000000000000000003.json\"\n\nwith fs.open(path, \"r\") as f:\n    for line in f:\n        data = json.loads(line)\n        pretty_content = json.dumps(data, indent=4)\n        print(pretty_content)\n        print(\"-\" * 50)  # Print separator for clarity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{\n    \"commitInfo\": {\n        \"timestamp\": 1696942553907,\n        \"operation\": \"WRITE\",\n        \"operationParameters\": {\n            \"mode\": \"Append\",\n            \"partitionBy\": \"[]\"\n        },\n        \"readVersion\": 2,\n        \"isolationLevel\": \"Serializable\",\n        \"isBlindAppend\": false,\n        \"operationMetrics\": {\n            \"numFiles\": \"2\",\n            \"numOutputRows\": \"7\",\n            \"numOutputBytes\": \"989\"\n        },\n        \"userMetadata\": \"{\\\"comment\\\": \\\"Kontaktet oppgavegiver og kranglet!\\\", \\\"manueltEditert\\\": \\\"True\\\", \\\"maskineltEditert\\\": \\\"False\\\"}\",\n        \"engineInfo\": \"Apache-Spark/3.3.1 Delta-Lake/2.3.0\",\n        \"txnId\": \"e7de92bf-b0f9-4341-8bbb-9b382f2f3eb6\"\n    }\n}\n--------------------------------------------------\n{\n    \"add\": {\n        \"path\": \"part-00000-96369f3d-fe4a-4365-a0df-00c813027399-c000.snappy.parquet\",\n        \"partitionValues\": {},\n        \"size\": 503,\n        \"modificationTime\": 1696942553856,\n        \"dataChange\": true,\n        \"stats\": \"{\\\"numRecords\\\":5,\\\"minValues\\\":{\\\"id\\\":10},\\\"maxValues\\\":{\\\"id\\\":15},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n    }\n}\n--------------------------------------------------\n{\n    \"add\": {\n        \"path\": \"part-00001-0f1bc8e6-093b-49a9-ad0b-78d5a148cfb6-c000.snappy.parquet\",\n        \"partitionValues\": {},\n        \"size\": 486,\n        \"modificationTime\": 1696942553853,\n        \"dataChange\": true,\n        \"stats\": \"{\\\"numRecords\\\":2,\\\"minValues\\\":{\\\"id\\\":20},\\\"maxValues\\\":{\\\"id\\\":21},\\\"nullCount\\\":{\\\"id\\\":0}}\"\n    }\n}\n--------------------------------------------------\n```\n:::\n:::\n\n\nVi er da at metadataene ligger som forventet i metadata-delen. \n\n",
    "supporting": [
      "deltalake-intro_files"
    ],
    "filters": [],
    "includes": {}
  }
}